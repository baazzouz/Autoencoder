{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for Consumer perception on price prmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import  Dense, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from  sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "input_data=pd.read_csv(\"https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/data/Sales_Product_Price_by_Store.csv\",delimiter=\",\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data=pd.read_csv(\"C:/Users/AMINE/Documents/PhD/AI Phd/Pricing and Golden ratio/Data_Amazon.csv\",delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InitialPrice</th>\n",
       "      <th>PromotionPrice</th>\n",
       "      <th>rating</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.99</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Literature and fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.99</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Literature and fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.99</td>\n",
       "      <td>27.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Literature and fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.99</td>\n",
       "      <td>17.00</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Literature and fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.99</td>\n",
       "      <td>28.99</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Literature and fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InitialPrice  PromotionPrice  rating                category\n",
       "0         14.99           30.00     4.4  Literature and fiction\n",
       "1         15.99           30.00     4.5  Literature and fiction\n",
       "2         13.99           27.00     4.3  Literature and fiction\n",
       "3         14.99           17.00     4.6  Literature and fiction\n",
       "4         14.99           28.99     4.4  Literature and fiction"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InitialPrice      float64\n",
       "PromotionPrice    float64\n",
       "rating            float64\n",
       "category           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=price_data[['discountedPrice','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data[\"category\"]=price_data[\"category\"].astype('category')\n",
    "price_data[\"category\"]=price_data[\"category\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=price_data[[\"InitialPrice\",\"PromotionPrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7479396"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.618033988749895"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sqrt(5)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(X,test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09152414e-01,  8.77552554e-02],\n",
       "       [-1.76353380e-02,  8.77552554e-02],\n",
       "       [-2.00669467e-01, -8.37869123e-02],\n",
       "       [-1.09152414e-01, -6.55594110e-01],\n",
       "       [-1.09152414e-01,  3.00027113e-02],\n",
       "       [-3.83703619e-01, -6.56165957e-01],\n",
       "       [-1.09152414e-01, -2.71780118e-02],\n",
       "       [-5.66737771e-01, -7.12774873e-01],\n",
       "       [-2.00669467e-01, -2.66061909e-02],\n",
       "       [-2.92186528e-01, -2.66061909e-02],\n",
       "       [-2.00669467e-01, -8.66459012e-02],\n",
       "       [ 9.89052415e-01,  1.21535921e+00],\n",
       "       [-3.83703619e-01, -4.26871270e-01],\n",
       "       [ 9.52445567e-01,  1.22851074e+00],\n",
       "       [ 2.56915867e-01,  3.73658866e-01],\n",
       "       [-2.92186528e-01, -6.56165957e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [-6.58254802e-01, -4.84051943e-01],\n",
       "       [-9.32806075e-01,  2.30707064e-01],\n",
       "       [-5.66737771e-01, -5.98413408e-01],\n",
       "       [ 7.11361617e-02,  8.77552554e-02],\n",
       "       [-5.66737771e-01, -7.15633869e-01],\n",
       "       [ 4.53533840e+00,  2.94621944e+00],\n",
       "       [ 1.44663775e+00,  4.87448633e-01],\n",
       "       [-1.02432311e+00, -1.05643106e+00],\n",
       "       [-2.92186528e-01,  8.77552554e-02],\n",
       "       [-5.51179826e-01, -4.84623760e-01],\n",
       "       [-1.76353380e-02,  8.71834382e-02],\n",
       "       [ 1.17849267e+00,  2.37441206e+00],\n",
       "       [ 1.64797533e+00,  5.44629335e-01],\n",
       "       [-2.92186528e-01, -8.37869123e-02],\n",
       "       [-5.66737771e-01, -7.70527363e-01],\n",
       "       [ 7.38817304e-02, -1.40967637e-01],\n",
       "       [-2.00669467e-01, -8.37869123e-02],\n",
       "       [-1.09152414e-01, -2.66061909e-02],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [ 1.58333685e-03,  8.71834382e-02],\n",
       "       [-2.92186528e-01, -6.55594110e-01],\n",
       "       [-3.83703619e-01, -5.98985195e-01],\n",
       "       [-2.92186528e-01, -2.66061909e-02],\n",
       "       [-1.76353380e-02, -2.94651836e-02],\n",
       "       [-7.72651196e-01, -1.17079246e+00],\n",
       "       [-1.09152414e-01,  3.05745304e-02],\n",
       "       [-5.66737771e-01, -5.41804492e-01],\n",
       "       [-3.83703619e-01, -6.56165957e-01],\n",
       "       [-1.76353380e-02, -2.66061909e-02],\n",
       "       [-3.83703619e-01, -5.41804492e-01],\n",
       "       [-2.00669467e-01, -1.40967637e-01],\n",
       "       [-2.92186528e-01, -8.66459012e-02],\n",
       "       [-2.92186528e-01, -5.41804492e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [ 7.38817304e-02, -3.69690537e-01],\n",
       "       [ 1.06867230e+00,  2.03132796e+00],\n",
       "       [-2.00669467e-01,  8.77552554e-02],\n",
       "       [-1.20735717e+00, -5.41232705e-01],\n",
       "       [ 1.32400489e+00,  1.80260527e+00],\n",
       "       [ 9.52445567e-01,  1.28797877e+00],\n",
       "       [-2.92186528e-01, -4.84051943e-01],\n",
       "       [ 5.77225626e-01, -1.46685734e-01],\n",
       "       [ 5.31467080e-01,  6.58990800e-01],\n",
       "       [-3.83703619e-01, -4.84051943e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [-5.66737771e-01, -9.42069530e-01],\n",
       "       [ 1.65398791e-01,  9.45466101e-01],\n",
       "       [-5.66737771e-01, -5.41804492e-01],\n",
       "       [-2.92186528e-01, -5.98413408e-01],\n",
       "       [ 3.48432958e-01, -8.37869123e-02],\n",
       "       [-2.00669467e-01, -3.12509805e-01],\n",
       "       [-1.76353380e-02,  8.77552554e-02],\n",
       "       [-4.75220680e-01, -5.98985195e-01],\n",
       "       [-5.66737771e-01, -9.42069530e-01],\n",
       "       [-3.83703619e-01, -6.55594110e-01],\n",
       "       [-5.66737771e-01, -6.56165957e-01],\n",
       "       [-1.09152414e-01, -1.40967637e-01],\n",
       "       [-2.18972862e-01, -3.13081622e-01],\n",
       "       [-1.76353380e-02, -3.72549534e-01],\n",
       "       [-7.49771953e-01, -1.05643106e+00],\n",
       "       [-5.66737771e-01, -5.98985195e-01],\n",
       "       [-2.92186528e-01, -7.72814631e-01],\n",
       "       [-4.37698692e-01, -7.13346660e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [-2.92186528e-01, -1.98720187e-01],\n",
       "       [-6.58254802e-01, -8.37869123e-02],\n",
       "       [-2.00669467e-01, -7.70527363e-01],\n",
       "       [ 7.38817304e-02,  2.30707064e-01],\n",
       "       [-1.29887426e+00, -1.34462190e+00],\n",
       "       [-6.33938685e-02, -2.55900919e-01],\n",
       "       [-2.92186528e-01, -7.12774873e-01],\n",
       "       [-1.09152414e-01, -4.85195607e-01],\n",
       "       [-2.92186528e-01, -2.66061909e-02],\n",
       "       [ 7.38817304e-02,  3.73658866e-01],\n",
       "       [-6.40866518e-01, -1.27816096e-01],\n",
       "       [-2.00669467e-01, -5.98413408e-01],\n",
       "       [-5.96938372e-01, -4.89066392e-02],\n",
       "       [-5.33791542e-01, -6.58453107e-01],\n",
       "       [ 4.30746126e+00,  3.91600442e+00],\n",
       "       [ 5.74793959e+00,  4.37630939e+00],\n",
       "       [ 4.39950019e-01,  4.03322506e+00],\n",
       "       [-1.33861974e-01, -2.01007351e-01],\n",
       "       [-1.09152414e-01, -5.98985195e-01]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Autoencoder: Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      " z (Dense)                   (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder SIR \n",
    "\n",
    "latent_dim = 1\n",
    "\n",
    "encoder_inputs =  keras.Input(shape=(2,))\n",
    "x = layers.Dense(10, activation='linear')(encoder_inputs)\n",
    "x = layers.Dense(5, activation='linear')(x)\n",
    "x = layers.Dense(3, activation='linear')(x)\n",
    "\n",
    "z = layers.Dense(latent_dim, activation='relu',name=\"z\")(x)\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 6         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder SIR\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(3, activation='linear')(latent_inputs)\n",
    "x = layers.Dense(5, activation='linear')(x)\n",
    "x = layers.Dense(10, activation='linear')(x)\n",
    "decoder_outputs = layers.Dense(2, activation='linear')(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(AE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\")\n",
    "        self.golden_loss_tracker = keras.metrics.Mean( name=\"golden_loss\")\n",
    "       \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.golden_loss_tracker,\n",
    "          \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_sum(tf.reduce_sum((data-reconstruction)**2, axis=1 ))\n",
    "            \n",
    "            phi=(np.sqrt(5)+1)/2\n",
    "            golden_loss=(z-phi)**2\n",
    "            golden_loss = tf.reduce_sum(tf.reduce_sum(golden_loss,axis=1))\n",
    "            \n",
    "            \n",
    "            total_loss = reconstruction_loss+ golden_loss\n",
    "            \n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.golden_loss_tracker.update_state(golden_loss)\n",
    "       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"golden_loss\": self.golden_loss_tracker.result(),\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. AutoEncoder Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 446.4436 - reconstruction_loss: 199.7588 - golden_loss: 246.6849\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 443.4052 - reconstruction_loss: 199.4929 - golden_loss: 243.9123\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 440.1576 - reconstruction_loss: 199.1574 - golden_loss: 241.0002\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 436.7606 - reconstruction_loss: 198.7566 - golden_loss: 238.0039\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 433.1622 - reconstruction_loss: 198.2978 - golden_loss: 234.8643\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 429.4345 - reconstruction_loss: 197.7802 - golden_loss: 231.6543\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 425.6693 - reconstruction_loss: 197.2109 - golden_loss: 228.4584\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 421.8735 - reconstruction_loss: 196.5905 - golden_loss: 225.2829\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 418.0482 - reconstruction_loss: 195.9189 - golden_loss: 222.1293\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 414.1942 - reconstruction_loss: 195.1958 - golden_loss: 218.9984\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 410.3089 - reconstruction_loss: 194.4211 - golden_loss: 215.8878\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 406.3422 - reconstruction_loss: 193.5819 - golden_loss: 212.7602\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 402.3412 - reconstruction_loss: 192.6894 - golden_loss: 209.6519\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 398.3096 - reconstruction_loss: 191.7445 - golden_loss: 206.5651\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 394.2469 - reconstruction_loss: 190.7470 - golden_loss: 203.4999\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 390.1532 - reconstruction_loss: 189.6971 - golden_loss: 200.4561\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 386.0280 - reconstruction_loss: 188.5946 - golden_loss: 197.4334\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 381.8709 - reconstruction_loss: 187.4398 - golden_loss: 194.4311\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 377.6819 - reconstruction_loss: 186.2331 - golden_loss: 191.4488\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 373.4612 - reconstruction_loss: 184.9751 - golden_loss: 188.4860\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 369.2093 - reconstruction_loss: 183.6670 - golden_loss: 185.5423\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 364.9273 - reconstruction_loss: 182.3099 - golden_loss: 182.6174\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 360.6168 - reconstruction_loss: 180.9055 - golden_loss: 179.7113\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 356.2800 - reconstruction_loss: 179.4561 - golden_loss: 176.8239\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 351.9196 - reconstruction_loss: 177.9641 - golden_loss: 173.9555\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 347.5390 - reconstruction_loss: 176.4324 - golden_loss: 171.1066\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 343.1392 - reconstruction_loss: 174.8647 - golden_loss: 168.2745\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 338.7209 - reconstruction_loss: 173.2648 - golden_loss: 165.4561\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 334.2965 - reconstruction_loss: 171.6376 - golden_loss: 162.6590\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 329.8723 - reconstruction_loss: 169.9881 - golden_loss: 159.8842\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 325.4556 - reconstruction_loss: 168.3222 - golden_loss: 157.1334\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 321.0544 - reconstruction_loss: 166.6464 - golden_loss: 154.4081\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 316.6758 - reconstruction_loss: 164.9678 - golden_loss: 151.7081\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 312.3252 - reconstruction_loss: 163.2943 - golden_loss: 149.0308\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 308.0177 - reconstruction_loss: 161.6336 - golden_loss: 146.3841\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 303.7642 - reconstruction_loss: 159.9940 - golden_loss: 143.7702\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 299.5756 - reconstruction_loss: 158.3842 - golden_loss: 141.1914\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 295.4630 - reconstruction_loss: 156.8128 - golden_loss: 138.6502\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 291.4373 - reconstruction_loss: 155.2882 - golden_loss: 136.1492\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 287.5094 - reconstruction_loss: 153.8184 - golden_loss: 133.6910\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 283.6888 - reconstruction_loss: 152.4104 - golden_loss: 131.2784\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 279.9842 - reconstruction_loss: 151.0701 - golden_loss: 128.9141\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 276.4024 - reconstruction_loss: 149.8016 - golden_loss: 126.6008\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 272.9482 - reconstruction_loss: 148.6070 - golden_loss: 124.3412\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 269.6238 - reconstruction_loss: 147.4859 - golden_loss: 122.1379\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 266.4287 - reconstruction_loss: 146.4354 - golden_loss: 119.9933\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 263.3597 - reconstruction_loss: 145.4502 - golden_loss: 117.9095\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 260.4108 - reconstruction_loss: 144.5223 - golden_loss: 115.8885\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 257.5737 - reconstruction_loss: 143.6421 - golden_loss: 113.9316\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 254.8386 - reconstruction_loss: 142.7987 - golden_loss: 112.0399\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 252.1947 - reconstruction_loss: 141.9807 - golden_loss: 110.2140\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 249.6310 - reconstruction_loss: 141.1772 - golden_loss: 108.4538\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 247.1372 - reconstruction_loss: 140.3784 - golden_loss: 106.7588\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 244.7038 - reconstruction_loss: 139.5760 - golden_loss: 105.1277\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 242.3231 - reconstruction_loss: 138.7641 - golden_loss: 103.5590\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 239.9891 - reconstruction_loss: 137.9388 - golden_loss: 102.0503\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 237.6976 - reconstruction_loss: 137.0985 - golden_loss: 100.5991\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 235.4461 - reconstruction_loss: 136.2437 - golden_loss: 99.2023\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 233.2333 - reconstruction_loss: 135.3765 - golden_loss: 97.8567\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 231.0593 - reconstruction_loss: 134.5005 - golden_loss: 96.5588\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 228.9247 - reconstruction_loss: 133.6197 - golden_loss: 95.3050\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 226.8304 - reconstruction_loss: 132.7387 - golden_loss: 94.0917\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 224.7776 - reconstruction_loss: 131.8621 - golden_loss: 92.9155\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 222.7667 - reconstruction_loss: 130.9937 - golden_loss: 91.7730\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 220.7980 - reconstruction_loss: 130.1369 - golden_loss: 90.6611\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 218.8713 - reconstruction_loss: 129.2942 - golden_loss: 89.5771\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 216.9855 - reconstruction_loss: 128.4671 - golden_loss: 88.5184\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 215.1395 - reconstruction_loss: 127.6567 - golden_loss: 87.4828\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 213.3318 - reconstruction_loss: 126.8631 - golden_loss: 86.4687\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 211.5608 - reconstruction_loss: 126.0862 - golden_loss: 85.4745\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 209.8249 - reconstruction_loss: 125.3255 - golden_loss: 84.4994\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 208.1230 - reconstruction_loss: 124.5804 - golden_loss: 83.5426\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 206.4540 - reconstruction_loss: 123.8502 - golden_loss: 82.6038\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 204.8173 - reconstruction_loss: 123.1344 - golden_loss: 81.6829\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 203.2126 - reconstruction_loss: 122.4327 - golden_loss: 80.7800\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 201.6399 - reconstruction_loss: 121.7444 - golden_loss: 79.8955\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 200.0990 - reconstruction_loss: 121.0692 - golden_loss: 79.0298\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 198.5901 - reconstruction_loss: 120.4067 - golden_loss: 78.1835\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 197.1131 - reconstruction_loss: 119.7560 - golden_loss: 77.3571\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 195.6674 - reconstruction_loss: 119.1163 - golden_loss: 76.5512\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 194.2525 - reconstruction_loss: 118.4863 - golden_loss: 75.7662\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 192.8669 - reconstruction_loss: 117.8644 - golden_loss: 75.0025\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 191.5092 - reconstruction_loss: 117.2490 - golden_loss: 74.2602\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 190.1774 - reconstruction_loss: 116.6380 - golden_loss: 73.5394\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 188.8694 - reconstruction_loss: 116.0295 - golden_loss: 72.8398\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 187.5830 - reconstruction_loss: 115.4218 - golden_loss: 72.1612\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 186.3161 - reconstruction_loss: 114.8131 - golden_loss: 71.5029\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 185.0669 - reconstruction_loss: 114.2026 - golden_loss: 70.8643\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 183.8340 - reconstruction_loss: 113.5896 - golden_loss: 70.2444\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 182.6163 - reconstruction_loss: 112.9740 - golden_loss: 69.6423\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 181.4130 - reconstruction_loss: 112.3560 - golden_loss: 69.0570\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 180.2238 - reconstruction_loss: 111.7365 - golden_loss: 68.4873\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 179.0482 - reconstruction_loss: 111.1161 - golden_loss: 67.9321\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 177.8862 - reconstruction_loss: 110.4959 - golden_loss: 67.3903\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 176.7373 - reconstruction_loss: 109.8764 - golden_loss: 66.8608\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 175.6010 - reconstruction_loss: 109.2584 - golden_loss: 66.3427\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 174.4767 - reconstruction_loss: 108.6419 - golden_loss: 65.8349\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 173.3635 - reconstruction_loss: 108.0270 - golden_loss: 65.3365\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 172.2601 - reconstruction_loss: 107.4133 - golden_loss: 64.8469\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 171.1656 - reconstruction_loss: 106.8004 - golden_loss: 64.3653\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 170.0787 - reconstruction_loss: 106.1877 - golden_loss: 63.8910\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 168.9984 - reconstruction_loss: 105.5748 - golden_loss: 63.4236\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 167.9238 - reconstruction_loss: 104.9612 - golden_loss: 62.9626\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 166.8542 - reconstruction_loss: 104.3468 - golden_loss: 62.5075\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 165.7536 - reconstruction_loss: 103.7262 - golden_loss: 62.0275\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 164.6463 - reconstruction_loss: 103.1023 - golden_loss: 61.5439\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 163.5379 - reconstruction_loss: 102.4762 - golden_loss: 61.0617\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 162.4290 - reconstruction_loss: 101.8480 - golden_loss: 60.5810\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 161.3198 - reconstruction_loss: 101.2180 - golden_loss: 60.1018\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 160.2109 - reconstruction_loss: 100.5865 - golden_loss: 59.6245\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 159.1026 - reconstruction_loss: 99.9536 - golden_loss: 59.1490\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 157.9953 - reconstruction_loss: 99.3196 - golden_loss: 58.6757\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 156.8610 - reconstruction_loss: 98.6782 - golden_loss: 58.1828\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 155.6789 - reconstruction_loss: 98.0238 - golden_loss: 57.6551\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 154.4909 - reconstruction_loss: 97.3658 - golden_loss: 57.1250\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 153.2984 - reconstruction_loss: 96.7047 - golden_loss: 56.5937\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 152.1027 - reconstruction_loss: 96.0408 - golden_loss: 56.0619\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 150.9051 - reconstruction_loss: 95.3746 - golden_loss: 55.5304\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 149.7066 - reconstruction_loss: 94.7066 - golden_loss: 55.0001\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 148.5085 - reconstruction_loss: 94.0370 - golden_loss: 54.4716\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 147.3118 - reconstruction_loss: 93.3662 - golden_loss: 53.9455\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 146.1173 - reconstruction_loss: 92.6948 - golden_loss: 53.4226\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 144.9260 - reconstruction_loss: 92.0229 - golden_loss: 52.9031\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 143.7388 - reconstruction_loss: 91.3511 - golden_loss: 52.3878\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 142.5382 - reconstruction_loss: 90.6794 - golden_loss: 51.8588\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 141.3129 - reconstruction_loss: 90.0077 - golden_loss: 51.3052\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 140.0886 - reconstruction_loss: 89.3364 - golden_loss: 50.7522\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 138.8668 - reconstruction_loss: 88.6660 - golden_loss: 50.2008\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 137.6487 - reconstruction_loss: 87.9968 - golden_loss: 49.6519\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 136.4357 - reconstruction_loss: 87.3293 - golden_loss: 49.1064\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 135.2289 - reconstruction_loss: 86.6639 - golden_loss: 48.5650\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 134.0294 - reconstruction_loss: 86.0009 - golden_loss: 48.0285\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 132.8306 - reconstruction_loss: 85.3409 - golden_loss: 47.4897\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 131.5847 - reconstruction_loss: 84.6853 - golden_loss: 46.8995\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 130.3423 - reconstruction_loss: 84.0328 - golden_loss: 46.3094\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 129.1053 - reconstruction_loss: 83.3840 - golden_loss: 45.7213\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 127.8760 - reconstruction_loss: 82.7393 - golden_loss: 45.1367\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 126.6561 - reconstruction_loss: 82.0991 - golden_loss: 44.5569\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 125.3255 - reconstruction_loss: 81.4590 - golden_loss: 43.8665\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 123.8781 - reconstruction_loss: 80.8197 - golden_loss: 43.0584\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 122.3808 - reconstruction_loss: 80.1854 - golden_loss: 42.1954\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 120.8836 - reconstruction_loss: 79.5599 - golden_loss: 41.3238\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 119.3951 - reconstruction_loss: 78.9452 - golden_loss: 40.4500\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 117.9228 - reconstruction_loss: 78.3430 - golden_loss: 39.5798\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 116.4727 - reconstruction_loss: 77.7543 - golden_loss: 38.7184\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 115.0501 - reconstruction_loss: 77.1797 - golden_loss: 37.8704\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 113.6589 - reconstruction_loss: 76.6192 - golden_loss: 37.0397\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 112.3024 - reconstruction_loss: 76.0725 - golden_loss: 36.2299\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 110.9826 - reconstruction_loss: 75.5386 - golden_loss: 35.4440\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 109.7010 - reconstruction_loss: 75.0162 - golden_loss: 34.6848\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 108.3947 - reconstruction_loss: 74.5392 - golden_loss: 33.8555\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 107.0275 - reconstruction_loss: 74.1371 - golden_loss: 32.8904\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 105.7068 - reconstruction_loss: 73.7530 - golden_loss: 31.9538\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 104.4345 - reconstruction_loss: 73.3815 - golden_loss: 31.0530\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 103.2018 - reconstruction_loss: 73.0288 - golden_loss: 30.1730\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 101.9708 - reconstruction_loss: 72.7503 - golden_loss: 29.2205\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 100.7897 - reconstruction_loss: 72.4682 - golden_loss: 28.3215\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 99.6527 - reconstruction_loss: 72.1700 - golden_loss: 27.4827\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 98.5515 - reconstruction_loss: 71.8422 - golden_loss: 26.7092\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 97.4763 - reconstruction_loss: 71.4718 - golden_loss: 26.0045\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 96.4173 - reconstruction_loss: 71.0467 - golden_loss: 25.3706\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 95.3654 - reconstruction_loss: 70.5574 - golden_loss: 24.8080\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 94.3135 - reconstruction_loss: 69.9974 - golden_loss: 24.3162\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 93.2570 - reconstruction_loss: 69.3638 - golden_loss: 23.8933\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 92.1939 - reconstruction_loss: 68.6574 - golden_loss: 23.5365\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 91.1257 - reconstruction_loss: 67.9075 - golden_loss: 23.2183\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 90.0525 - reconstruction_loss: 67.0842 - golden_loss: 22.9683\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 88.9789 - reconstruction_loss: 66.1949 - golden_loss: 22.7840\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 87.9114 - reconstruction_loss: 65.2566 - golden_loss: 22.6547\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 86.8559 - reconstruction_loss: 64.2873 - golden_loss: 22.5686\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 85.8172 - reconstruction_loss: 63.3044 - golden_loss: 22.5128\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 84.7967 - reconstruction_loss: 62.3345 - golden_loss: 22.4622\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 83.7955 - reconstruction_loss: 61.3739 - golden_loss: 22.4216\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 82.8144 - reconstruction_loss: 60.4269 - golden_loss: 22.3875\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 81.8523 - reconstruction_loss: 59.4997 - golden_loss: 22.3525\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 80.9070 - reconstruction_loss: 58.5969 - golden_loss: 22.3100\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 79.9758 - reconstruction_loss: 57.7215 - golden_loss: 22.2543\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 79.0556 - reconstruction_loss: 56.8751 - golden_loss: 22.1805\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 78.1436 - reconstruction_loss: 56.0583 - golden_loss: 22.0853\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 77.2361 - reconstruction_loss: 55.2738 - golden_loss: 21.9623\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 76.3123 - reconstruction_loss: 54.5579 - golden_loss: 21.7543\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 75.3822 - reconstruction_loss: 53.8897 - golden_loss: 21.4925\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 74.4500 - reconstruction_loss: 53.2632 - golden_loss: 21.1868\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 73.5210 - reconstruction_loss: 52.6714 - golden_loss: 20.8496\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 72.6007 - reconstruction_loss: 52.1062 - golden_loss: 20.4946\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 71.6935 - reconstruction_loss: 51.5579 - golden_loss: 20.1356\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 70.8015 - reconstruction_loss: 51.0158 - golden_loss: 19.7857\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 69.9249 - reconstruction_loss: 50.4689 - golden_loss: 19.4560\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 69.0618 - reconstruction_loss: 49.9061 - golden_loss: 19.1557\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 68.2089 - reconstruction_loss: 49.3178 - golden_loss: 18.8912\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 67.3628 - reconstruction_loss: 48.6967 - golden_loss: 18.6661\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 66.5205 - reconstruction_loss: 48.0390 - golden_loss: 18.4815\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 65.6805 - reconstruction_loss: 47.3446 - golden_loss: 18.3359\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 64.8429 - reconstruction_loss: 46.6174 - golden_loss: 18.2255\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64.0095 - reconstruction_loss: 45.8648 - golden_loss: 18.1448\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 63.1828 - reconstruction_loss: 45.0963 - golden_loss: 18.0866\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 62.3654 - reconstruction_loss: 44.3225 - golden_loss: 18.0429\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 61.5590 - reconstruction_loss: 43.5538 - golden_loss: 18.0052\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 60.7642 - reconstruction_loss: 42.7991 - golden_loss: 17.9651\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 59.9804 - reconstruction_loss: 42.0656 - golden_loss: 17.9148\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 59.2063 - reconstruction_loss: 41.3582 - golden_loss: 17.8481\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 58.4403 - reconstruction_loss: 40.6800 - golden_loss: 17.7603\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 57.6809 - reconstruction_loss: 40.0320 - golden_loss: 17.6489\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 56.9278 - reconstruction_loss: 39.4136 - golden_loss: 17.5142\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 56.1812 - reconstruction_loss: 38.8229 - golden_loss: 17.3584\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 55.4423 - reconstruction_loss: 38.2563 - golden_loss: 17.1860\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 54.7124 - reconstruction_loss: 37.7095 - golden_loss: 17.0029\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 53.9929 - reconstruction_loss: 37.1769 - golden_loss: 16.8160\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 53.2845 - reconstruction_loss: 36.6526 - golden_loss: 16.6319\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 52.5872 - reconstruction_loss: 36.1306 - golden_loss: 16.4567\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 51.9007 - reconstruction_loss: 35.6055 - golden_loss: 16.2952\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 51.2240 - reconstruction_loss: 35.0735 - golden_loss: 16.1505\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 50.5567 - reconstruction_loss: 34.5329 - golden_loss: 16.0238\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 49.8985 - reconstruction_loss: 33.9841 - golden_loss: 15.9144\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 49.2498 - reconstruction_loss: 33.4296 - golden_loss: 15.8202\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 48.6114 - reconstruction_loss: 32.8737 - golden_loss: 15.7376\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 47.9838 - reconstruction_loss: 32.3213 - golden_loss: 15.6625\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 47.3677 - reconstruction_loss: 31.7776 - golden_loss: 15.5902\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 46.7633 - reconstruction_loss: 31.2468 - golden_loss: 15.5165\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 46.1702 - reconstruction_loss: 30.7324 - golden_loss: 15.4378\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 45.5881 - reconstruction_loss: 30.2365 - golden_loss: 15.3516\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 45.0166 - reconstruction_loss: 29.7599 - golden_loss: 15.2567\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 44.4557 - reconstruction_loss: 29.3024 - golden_loss: 15.1533\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 43.9056 - reconstruction_loss: 28.8627 - golden_loss: 15.0429\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 43.3667 - reconstruction_loss: 28.4386 - golden_loss: 14.9281\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 42.8394 - reconstruction_loss: 28.0274 - golden_loss: 14.8120\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 42.3240 - reconstruction_loss: 27.6258 - golden_loss: 14.6982\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 41.8204 - reconstruction_loss: 27.2304 - golden_loss: 14.5900\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 41.3285 - reconstruction_loss: 26.8387 - golden_loss: 14.4897\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 40.8479 - reconstruction_loss: 26.4491 - golden_loss: 14.3989\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 40.3788 - reconstruction_loss: 26.0613 - golden_loss: 14.3175\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 39.9210 - reconstruction_loss: 25.6765 - golden_loss: 14.2445\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 39.4748 - reconstruction_loss: 25.2970 - golden_loss: 14.1778\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 39.0405 - reconstruction_loss: 24.9257 - golden_loss: 14.1148\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 38.6181 - reconstruction_loss: 24.5653 - golden_loss: 14.0527\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 38.2074 - reconstruction_loss: 24.2184 - golden_loss: 13.9890\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 37.8084 - reconstruction_loss: 23.8863 - golden_loss: 13.9221\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 37.4209 - reconstruction_loss: 23.5696 - golden_loss: 13.8513\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 37.0447 - reconstruction_loss: 23.2681 - golden_loss: 13.7767\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 36.6800 - reconstruction_loss: 22.9805 - golden_loss: 13.6994\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 36.3266 - reconstruction_loss: 22.7053 - golden_loss: 13.6213\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 35.9824 - reconstruction_loss: 22.4596 - golden_loss: 13.5227\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 35.6463 - reconstruction_loss: 22.2378 - golden_loss: 13.4085\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 35.3194 - reconstruction_loss: 22.0239 - golden_loss: 13.2955\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 496us/step - loss: 35.0014 - reconstruction_loss: 21.8124 - golden_loss: 13.1890\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 34.6919 - reconstruction_loss: 21.5994 - golden_loss: 13.0925\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 34.3907 - reconstruction_loss: 21.3837 - golden_loss: 13.0070\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 34.0976 - reconstruction_loss: 21.1664 - golden_loss: 12.9312\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 33.8128 - reconstruction_loss: 20.9511 - golden_loss: 12.8618\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 33.5363 - reconstruction_loss: 20.7418 - golden_loss: 12.7946\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 33.2679 - reconstruction_loss: 20.5421 - golden_loss: 12.7258\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 33.0072 - reconstruction_loss: 20.3541 - golden_loss: 12.6531\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 32.7540 - reconstruction_loss: 20.1781 - golden_loss: 12.5759\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 32.5083 - reconstruction_loss: 20.0130 - golden_loss: 12.4952\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 32.2699 - reconstruction_loss: 19.8565 - golden_loss: 12.4134\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 32.0389 - reconstruction_loss: 19.7056 - golden_loss: 12.3333\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 31.8151 - reconstruction_loss: 19.5609 - golden_loss: 12.2542\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 31.5972 - reconstruction_loss: 19.4387 - golden_loss: 12.1585\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 31.3845 - reconstruction_loss: 19.3132 - golden_loss: 12.0714\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.1769 - reconstruction_loss: 19.1853 - golden_loss: 11.9917\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 30.9743 - reconstruction_loss: 19.0583 - golden_loss: 11.9160\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 30.7765 - reconstruction_loss: 18.9361 - golden_loss: 11.8404\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 30.5832 - reconstruction_loss: 18.8217 - golden_loss: 11.7615\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 30.3944 - reconstruction_loss: 18.7159 - golden_loss: 11.6784\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 30.2098 - reconstruction_loss: 18.6174 - golden_loss: 11.5924\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 30.0295 - reconstruction_loss: 18.5229 - golden_loss: 11.5066\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 29.8533 - reconstruction_loss: 18.4290 - golden_loss: 11.4243\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 29.6812 - reconstruction_loss: 18.3333 - golden_loss: 11.3479\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 29.5129 - reconstruction_loss: 18.2355 - golden_loss: 11.2774\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 29.3484 - reconstruction_loss: 18.1377 - golden_loss: 11.2107\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 29.1878 - reconstruction_loss: 18.0427 - golden_loss: 11.1450\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 29.0308 - reconstruction_loss: 17.9529 - golden_loss: 11.0779\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 28.8774 - reconstruction_loss: 17.8691 - golden_loss: 11.0083\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 28.7275 - reconstruction_loss: 17.7904 - golden_loss: 10.9371\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 28.5811 - reconstruction_loss: 17.7147 - golden_loss: 10.8664\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 28.4380 - reconstruction_loss: 17.6398 - golden_loss: 10.7983\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 28.2983 - reconstruction_loss: 17.5642 - golden_loss: 10.7342\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 28.1619 - reconstruction_loss: 17.4880 - golden_loss: 10.6739\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 28.0287 - reconstruction_loss: 17.4125 - golden_loss: 10.6162\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.8987 - reconstruction_loss: 17.3394 - golden_loss: 10.5592\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 27.7718 - reconstruction_loss: 17.2703 - golden_loss: 10.5015\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 27.6479 - reconstruction_loss: 17.2054 - golden_loss: 10.4425\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 27.5270 - reconstruction_loss: 17.1442 - golden_loss: 10.3829\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.4092 - reconstruction_loss: 17.0853 - golden_loss: 10.3239\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 27.2942 - reconstruction_loss: 17.0272 - golden_loss: 10.2670\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.1821 - reconstruction_loss: 16.9692 - golden_loss: 10.2128\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 27.0728 - reconstruction_loss: 16.9116 - golden_loss: 10.1612\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.9663 - reconstruction_loss: 16.8552 - golden_loss: 10.1111\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26.8625 - reconstruction_loss: 16.8014 - golden_loss: 10.0611\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 26.7614 - reconstruction_loss: 16.7509 - golden_loss: 10.0105\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.6629 - reconstruction_loss: 16.7036 - golden_loss: 9.9593\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 26.5670 - reconstruction_loss: 16.6587 - golden_loss: 9.9084\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.4737 - reconstruction_loss: 16.6148 - golden_loss: 9.8590\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 26.3829 - reconstruction_loss: 16.5711 - golden_loss: 9.8118\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.2946 - reconstruction_loss: 16.5277 - golden_loss: 9.7668\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.2086 - reconstruction_loss: 16.4854 - golden_loss: 9.7232\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 26.1251 - reconstruction_loss: 16.4453 - golden_loss: 9.6798\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 26.0438 - reconstruction_loss: 16.4078 - golden_loss: 9.6361\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 25.9649 - reconstruction_loss: 16.3728 - golden_loss: 9.5922\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 25.8882 - reconstruction_loss: 16.3395 - golden_loss: 9.5487\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 25.8138 - reconstruction_loss: 16.3071 - golden_loss: 9.5066\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.7415 - reconstruction_loss: 16.2753 - golden_loss: 9.4661\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.6713 - reconstruction_loss: 16.2442 - golden_loss: 9.4271\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 25.6032 - reconstruction_loss: 16.2142 - golden_loss: 9.3889\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25.5371 - reconstruction_loss: 16.1861 - golden_loss: 9.3510\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 25.4730 - reconstruction_loss: 16.1600 - golden_loss: 9.3130\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25.4109 - reconstruction_loss: 16.1357 - golden_loss: 9.2752\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 25.3507 - reconstruction_loss: 16.1126 - golden_loss: 9.2381\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.2924 - reconstruction_loss: 16.0904 - golden_loss: 9.2021\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.2359 - reconstruction_loss: 16.0686 - golden_loss: 9.1673\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 25.1812 - reconstruction_loss: 16.0475 - golden_loss: 9.1337\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25.1283 - reconstruction_loss: 16.0276 - golden_loss: 9.1007\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.0770 - reconstruction_loss: 16.0123 - golden_loss: 9.0647\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25.0268 - reconstruction_loss: 16.0100 - golden_loss: 9.0168\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.9776 - reconstruction_loss: 16.0079 - golden_loss: 8.9697\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.9292 - reconstruction_loss: 16.0035 - golden_loss: 8.9257\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.8816 - reconstruction_loss: 15.9968 - golden_loss: 8.8848\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.8347 - reconstruction_loss: 15.9902 - golden_loss: 8.8445\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24.7886 - reconstruction_loss: 15.9857 - golden_loss: 8.8028\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.7431 - reconstruction_loss: 15.9831 - golden_loss: 8.7600\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.6982 - reconstruction_loss: 15.9805 - golden_loss: 8.7177\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 24.6539 - reconstruction_loss: 15.9765 - golden_loss: 8.6775\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 24.6102 - reconstruction_loss: 15.9712 - golden_loss: 8.6390\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 24.5670 - reconstruction_loss: 15.9660 - golden_loss: 8.6010\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.5243 - reconstruction_loss: 15.9620 - golden_loss: 8.5623\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 24.4821 - reconstruction_loss: 15.9590 - golden_loss: 8.5231\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 24.4403 - reconstruction_loss: 15.9559 - golden_loss: 8.4844\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.3990 - reconstruction_loss: 15.9522 - golden_loss: 8.4468\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 24.3581 - reconstruction_loss: 15.9480 - golden_loss: 8.4100\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 24.3176 - reconstruction_loss: 15.9438 - golden_loss: 8.3737\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.2774 - reconstruction_loss: 15.9400 - golden_loss: 8.3374\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 24.2377 - reconstruction_loss: 15.9367 - golden_loss: 8.3010\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 24.1983 - reconstruction_loss: 15.9336 - golden_loss: 8.2647\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 24.1593 - reconstruction_loss: 15.9304 - golden_loss: 8.2289\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.1206 - reconstruction_loss: 15.9269 - golden_loss: 8.1937\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.0822 - reconstruction_loss: 15.9231 - golden_loss: 8.1591\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.0442 - reconstruction_loss: 15.9193 - golden_loss: 8.1249\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.0065 - reconstruction_loss: 15.9161 - golden_loss: 8.0904\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 23.9690 - reconstruction_loss: 15.9133 - golden_loss: 8.0557\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.9319 - reconstruction_loss: 15.9105 - golden_loss: 8.0214\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.8951 - reconstruction_loss: 15.9072 - golden_loss: 7.9879\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 23.8585 - reconstruction_loss: 15.9034 - golden_loss: 7.9551\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.8223 - reconstruction_loss: 15.9000 - golden_loss: 7.9223\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.7863 - reconstruction_loss: 15.8972 - golden_loss: 7.8891\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.7506 - reconstruction_loss: 15.8947 - golden_loss: 7.8558\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.7151 - reconstruction_loss: 15.8919 - golden_loss: 7.8232\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 23.6799 - reconstruction_loss: 15.8884 - golden_loss: 7.7915\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.6450 - reconstruction_loss: 15.8850 - golden_loss: 7.7599\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.6103 - reconstruction_loss: 15.8821 - golden_loss: 7.7281\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 23.5758 - reconstruction_loss: 15.8797 - golden_loss: 7.6961\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.5416 - reconstruction_loss: 15.8772 - golden_loss: 7.6645\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.5077 - reconstruction_loss: 15.8742 - golden_loss: 7.6335\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.4739 - reconstruction_loss: 15.8710 - golden_loss: 7.6030\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 23.4404 - reconstruction_loss: 15.8681 - golden_loss: 7.5724\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.4072 - reconstruction_loss: 15.8656 - golden_loss: 7.5416\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 502us/step - loss: 23.3742 - reconstruction_loss: 15.8632 - golden_loss: 7.5110\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.3414 - reconstruction_loss: 15.8605 - golden_loss: 7.4809\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.3088 - reconstruction_loss: 15.8576 - golden_loss: 7.4512\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 23.2764 - reconstruction_loss: 15.8548 - golden_loss: 7.4216\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.2443 - reconstruction_loss: 15.8523 - golden_loss: 7.3920\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.2123 - reconstruction_loss: 15.8499 - golden_loss: 7.3624\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.1806 - reconstruction_loss: 15.8474 - golden_loss: 7.3332\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.1491 - reconstruction_loss: 15.8448 - golden_loss: 7.3043\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.1178 - reconstruction_loss: 15.8422 - golden_loss: 7.2756\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.0867 - reconstruction_loss: 15.8397 - golden_loss: 7.2470\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.0559 - reconstruction_loss: 15.8374 - golden_loss: 7.2185\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.0252 - reconstruction_loss: 15.8350 - golden_loss: 7.1901\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.9947 - reconstruction_loss: 15.8326 - golden_loss: 7.1621\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.9644 - reconstruction_loss: 15.8302 - golden_loss: 7.1342\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.9343 - reconstruction_loss: 15.8278 - golden_loss: 7.1065\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 22.9045 - reconstruction_loss: 15.8255 - golden_loss: 7.0789\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.8748 - reconstruction_loss: 15.8233 - golden_loss: 7.0515\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.8453 - reconstruction_loss: 15.8211 - golden_loss: 7.0242\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.8159 - reconstruction_loss: 15.8187 - golden_loss: 6.9972\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.7868 - reconstruction_loss: 15.8164 - golden_loss: 6.9704\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.7579 - reconstruction_loss: 15.8143 - golden_loss: 6.9436\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.7291 - reconstruction_loss: 15.8122 - golden_loss: 6.9170\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.7005 - reconstruction_loss: 15.8100 - golden_loss: 6.8905\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.6722 - reconstruction_loss: 15.8078 - golden_loss: 6.8643\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.6439 - reconstruction_loss: 15.8056 - golden_loss: 6.8383\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.6159 - reconstruction_loss: 15.8036 - golden_loss: 6.8123\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 22.5880 - reconstruction_loss: 15.8016 - golden_loss: 6.7865\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.5604 - reconstruction_loss: 15.7995 - golden_loss: 6.7608\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.5329 - reconstruction_loss: 15.7974 - golden_loss: 6.7354\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.5055 - reconstruction_loss: 15.7954 - golden_loss: 6.7102\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 22.4784 - reconstruction_loss: 15.7934 - golden_loss: 6.6850\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 22.4514 - reconstruction_loss: 15.7915 - golden_loss: 6.6599\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 22.4245 - reconstruction_loss: 15.7895 - golden_loss: 6.6350\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.3979 - reconstruction_loss: 15.7875 - golden_loss: 6.6103\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.3714 - reconstruction_loss: 15.7856 - golden_loss: 6.5858\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.3450 - reconstruction_loss: 15.7837 - golden_loss: 6.5613\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.3189 - reconstruction_loss: 15.7819 - golden_loss: 6.5370\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.2929 - reconstruction_loss: 15.7800 - golden_loss: 6.5129\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.2670 - reconstruction_loss: 15.7781 - golden_loss: 6.4889\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.2413 - reconstruction_loss: 15.7763 - golden_loss: 6.4650\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.2158 - reconstruction_loss: 15.7745 - golden_loss: 6.4413\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.1904 - reconstruction_loss: 15.7727 - golden_loss: 6.4177\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 22.1652 - reconstruction_loss: 15.7709 - golden_loss: 6.3942\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.1401 - reconstruction_loss: 15.7692 - golden_loss: 6.3709\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.1152 - reconstruction_loss: 15.7674 - golden_loss: 6.3478\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 22.0904 - reconstruction_loss: 15.7657 - golden_loss: 6.3247\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.0658 - reconstruction_loss: 15.7640 - golden_loss: 6.3018\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 22.0413 - reconstruction_loss: 15.7623 - golden_loss: 6.2790\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.0170 - reconstruction_loss: 15.7606 - golden_loss: 6.2564\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.9928 - reconstruction_loss: 15.7589 - golden_loss: 6.2338\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.9687 - reconstruction_loss: 15.7573 - golden_loss: 6.2114\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.9448 - reconstruction_loss: 15.7557 - golden_loss: 6.1892\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 21.9211 - reconstruction_loss: 15.7540 - golden_loss: 6.1670\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.8975 - reconstruction_loss: 15.7524 - golden_loss: 6.1450\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.8740 - reconstruction_loss: 15.7509 - golden_loss: 6.1232\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.8507 - reconstruction_loss: 15.7493 - golden_loss: 6.1014\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.8275 - reconstruction_loss: 15.7477 - golden_loss: 6.0798\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 21.8044 - reconstruction_loss: 15.7462 - golden_loss: 6.0582\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.7815 - reconstruction_loss: 15.7446 - golden_loss: 6.0369\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.7587 - reconstruction_loss: 15.7431 - golden_loss: 6.0156\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.7361 - reconstruction_loss: 15.7417 - golden_loss: 5.9944\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.7135 - reconstruction_loss: 15.7402 - golden_loss: 5.9734\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.6911 - reconstruction_loss: 15.7387 - golden_loss: 5.9525\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 21.6689 - reconstruction_loss: 15.7372 - golden_loss: 5.9317\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.6468 - reconstruction_loss: 15.7358 - golden_loss: 5.9110\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.6248 - reconstruction_loss: 15.7343 - golden_loss: 5.8904\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 21.6029 - reconstruction_loss: 15.7329 - golden_loss: 5.8700\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.5811 - reconstruction_loss: 15.7315 - golden_loss: 5.8496\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.5595 - reconstruction_loss: 15.7301 - golden_loss: 5.8294\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.5380 - reconstruction_loss: 15.7287 - golden_loss: 5.8093\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.5166 - reconstruction_loss: 15.7274 - golden_loss: 5.7893\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.4954 - reconstruction_loss: 15.7260 - golden_loss: 5.7694\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 21.4742 - reconstruction_loss: 15.7247 - golden_loss: 5.7496\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.4532 - reconstruction_loss: 15.7233 - golden_loss: 5.7299\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.4323 - reconstruction_loss: 15.7220 - golden_loss: 5.7103\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 21.4116 - reconstruction_loss: 15.7207 - golden_loss: 5.6908\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.3909 - reconstruction_loss: 15.7194 - golden_loss: 5.6715\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.3704 - reconstruction_loss: 15.7181 - golden_loss: 5.6522\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 21.3499 - reconstruction_loss: 15.7169 - golden_loss: 5.6331\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.3296 - reconstruction_loss: 15.7156 - golden_loss: 5.6140\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.3094 - reconstruction_loss: 15.7143 - golden_loss: 5.5951\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.2894 - reconstruction_loss: 15.7131 - golden_loss: 5.5763\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.2694 - reconstruction_loss: 15.7119 - golden_loss: 5.5575\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.2495 - reconstruction_loss: 15.7107 - golden_loss: 5.5389\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 21.2298 - reconstruction_loss: 15.7094 - golden_loss: 5.5203\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.2101 - reconstruction_loss: 15.7082 - golden_loss: 5.5019\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.1906 - reconstruction_loss: 15.7071 - golden_loss: 5.4836\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.1712 - reconstruction_loss: 15.7059 - golden_loss: 5.4653\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.1519 - reconstruction_loss: 15.7047 - golden_loss: 5.4472\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.1327 - reconstruction_loss: 15.7036 - golden_loss: 5.4291\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.1136 - reconstruction_loss: 15.7024 - golden_loss: 5.4111\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.0946 - reconstruction_loss: 15.7013 - golden_loss: 5.3933\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21.0757 - reconstruction_loss: 15.7001 - golden_loss: 5.3756\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 21.0569 - reconstruction_loss: 15.6990 - golden_loss: 5.3579\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.0382 - reconstruction_loss: 15.6980 - golden_loss: 5.3403\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.0196 - reconstruction_loss: 15.6968 - golden_loss: 5.3228\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.0012 - reconstruction_loss: 15.6957 - golden_loss: 5.3054\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.9828 - reconstruction_loss: 15.6947 - golden_loss: 5.2881\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.9645 - reconstruction_loss: 15.6936 - golden_loss: 5.2709\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.9463 - reconstruction_loss: 15.6925 - golden_loss: 5.2538\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.9283 - reconstruction_loss: 15.6915 - golden_loss: 5.2367\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.9103 - reconstruction_loss: 15.6905 - golden_loss: 5.2198\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.8924 - reconstruction_loss: 15.6894 - golden_loss: 5.2030\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.8746 - reconstruction_loss: 15.6884 - golden_loss: 5.1862\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.8569 - reconstruction_loss: 15.6874 - golden_loss: 5.1695\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.8393 - reconstruction_loss: 15.6864 - golden_loss: 5.1529\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.8218 - reconstruction_loss: 15.6854 - golden_loss: 5.1364\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.8044 - reconstruction_loss: 15.6844 - golden_loss: 5.1200\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.7870 - reconstruction_loss: 15.6834 - golden_loss: 5.1036\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.7698 - reconstruction_loss: 15.6824 - golden_loss: 5.0874\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.7527 - reconstruction_loss: 15.6815 - golden_loss: 5.0712\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.7356 - reconstruction_loss: 15.6805 - golden_loss: 5.0551\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.7187 - reconstruction_loss: 15.6796 - golden_loss: 5.0391\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.7018 - reconstruction_loss: 15.6786 - golden_loss: 5.0232\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.6850 - reconstruction_loss: 15.6777 - golden_loss: 5.0073\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.6683 - reconstruction_loss: 15.6768 - golden_loss: 4.9916\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.6517 - reconstruction_loss: 15.6758 - golden_loss: 4.9759\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.6352 - reconstruction_loss: 15.6749 - golden_loss: 4.9603\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.6188 - reconstruction_loss: 15.6740 - golden_loss: 4.9447\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.6024 - reconstruction_loss: 15.6732 - golden_loss: 4.9293\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5862 - reconstruction_loss: 15.6723 - golden_loss: 4.9139\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.5700 - reconstruction_loss: 15.6714 - golden_loss: 4.8986\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5539 - reconstruction_loss: 15.6705 - golden_loss: 4.8834\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 20.5379 - reconstruction_loss: 15.6696 - golden_loss: 4.8683\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5220 - reconstruction_loss: 15.6688 - golden_loss: 4.8532\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5061 - reconstruction_loss: 15.6679 - golden_loss: 4.8382\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.4904 - reconstruction_loss: 15.6671 - golden_loss: 4.8233\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.4747 - reconstruction_loss: 15.6663 - golden_loss: 4.8084\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.4591 - reconstruction_loss: 15.6654 - golden_loss: 4.7937\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.4436 - reconstruction_loss: 15.6646 - golden_loss: 4.7790\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.4281 - reconstruction_loss: 15.6638 - golden_loss: 4.7644\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.4128 - reconstruction_loss: 15.6630 - golden_loss: 4.7498\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.3975 - reconstruction_loss: 15.6621 - golden_loss: 4.7353\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.3823 - reconstruction_loss: 15.6614 - golden_loss: 4.7209\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.3672 - reconstruction_loss: 15.6606 - golden_loss: 4.7066\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.3521 - reconstruction_loss: 15.6598 - golden_loss: 4.6923\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.3371 - reconstruction_loss: 15.6590 - golden_loss: 4.6781\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 20.3222 - reconstruction_loss: 15.6582 - golden_loss: 4.6640\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.3074 - reconstruction_loss: 15.6575 - golden_loss: 4.6499\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.2926 - reconstruction_loss: 15.6567 - golden_loss: 4.6359\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.2780 - reconstruction_loss: 15.6560 - golden_loss: 4.6220\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.2634 - reconstruction_loss: 15.6552 - golden_loss: 4.6082\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.2488 - reconstruction_loss: 15.6545 - golden_loss: 4.5944\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.2344 - reconstruction_loss: 15.6537 - golden_loss: 4.5806\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.2200 - reconstruction_loss: 15.6530 - golden_loss: 4.5670\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 20.2057 - reconstruction_loss: 15.6523 - golden_loss: 4.5534\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.1914 - reconstruction_loss: 15.6516 - golden_loss: 4.5398\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.1772 - reconstruction_loss: 15.6508 - golden_loss: 4.5264\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.1631 - reconstruction_loss: 15.6501 - golden_loss: 4.5130\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.1491 - reconstruction_loss: 15.6494 - golden_loss: 4.4997\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 20.1351 - reconstruction_loss: 15.6487 - golden_loss: 4.4864\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.1212 - reconstruction_loss: 15.6481 - golden_loss: 4.4732\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.1074 - reconstruction_loss: 15.6474 - golden_loss: 4.4600\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.0936 - reconstruction_loss: 15.6467 - golden_loss: 4.4470\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.0800 - reconstruction_loss: 15.6460 - golden_loss: 4.4339\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.0663 - reconstruction_loss: 15.6454 - golden_loss: 4.4210\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.0528 - reconstruction_loss: 15.6446 - golden_loss: 4.4081\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.0393 - reconstruction_loss: 15.6440 - golden_loss: 4.3953\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.0258 - reconstruction_loss: 15.6434 - golden_loss: 4.3825\n",
      "Epoch 515/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.0125 - reconstruction_loss: 15.6427 - golden_loss: 4.3698\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9992 - reconstruction_loss: 15.6421 - golden_loss: 4.3571\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9859 - reconstruction_loss: 15.6414 - golden_loss: 4.3445\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.9728 - reconstruction_loss: 15.6408 - golden_loss: 4.3320\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.9597 - reconstruction_loss: 15.6401 - golden_loss: 4.3195\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9466 - reconstruction_loss: 15.6395 - golden_loss: 4.3071\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.9336 - reconstruction_loss: 15.6389 - golden_loss: 4.2947\n",
      "Epoch 522/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9207 - reconstruction_loss: 15.6383 - golden_loss: 4.2824\n",
      "Epoch 523/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19.9078 - reconstruction_loss: 15.6377 - golden_loss: 4.2702\n",
      "Epoch 524/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.8950 - reconstruction_loss: 15.6371 - golden_loss: 4.2579\n",
      "Epoch 525/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8823 - reconstruction_loss: 15.6365 - golden_loss: 4.2458\n",
      "Epoch 526/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.8696 - reconstruction_loss: 15.6359 - golden_loss: 4.2338\n",
      "Epoch 527/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19.8570 - reconstruction_loss: 15.6353 - golden_loss: 4.2217\n",
      "Epoch 528/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.8444 - reconstruction_loss: 15.6347 - golden_loss: 4.2098\n",
      "Epoch 529/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.8320 - reconstruction_loss: 15.6341 - golden_loss: 4.1978\n",
      "Epoch 530/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.8195 - reconstruction_loss: 15.6335 - golden_loss: 4.1860\n",
      "Epoch 531/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.8071 - reconstruction_loss: 15.6330 - golden_loss: 4.1742\n",
      "Epoch 532/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.7948 - reconstruction_loss: 15.6324 - golden_loss: 4.1624\n",
      "Epoch 533/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.7825 - reconstruction_loss: 15.6318 - golden_loss: 4.1507\n",
      "Epoch 534/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.7703 - reconstruction_loss: 15.6312 - golden_loss: 4.1391\n",
      "Epoch 535/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.7582 - reconstruction_loss: 15.6307 - golden_loss: 4.1275\n",
      "Epoch 536/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.7461 - reconstruction_loss: 15.6302 - golden_loss: 4.1159\n",
      "Epoch 537/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7340 - reconstruction_loss: 15.6296 - golden_loss: 4.1045\n",
      "Epoch 538/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.7221 - reconstruction_loss: 15.6291 - golden_loss: 4.0930\n",
      "Epoch 539/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.7101 - reconstruction_loss: 15.6285 - golden_loss: 4.0816\n",
      "Epoch 540/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.6983 - reconstruction_loss: 15.6280 - golden_loss: 4.0703\n",
      "Epoch 541/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.6865 - reconstruction_loss: 15.6275 - golden_loss: 4.0590\n",
      "Epoch 542/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.6747 - reconstruction_loss: 15.6269 - golden_loss: 4.0478\n",
      "Epoch 543/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.6630 - reconstruction_loss: 15.6264 - golden_loss: 4.0366\n",
      "Epoch 544/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.6513 - reconstruction_loss: 15.6259 - golden_loss: 4.0255\n",
      "Epoch 545/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6397 - reconstruction_loss: 15.6253 - golden_loss: 4.0144\n",
      "Epoch 546/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.6282 - reconstruction_loss: 15.6248 - golden_loss: 4.0033\n",
      "Epoch 547/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.6167 - reconstruction_loss: 15.6243 - golden_loss: 3.9924\n",
      "Epoch 548/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6052 - reconstruction_loss: 15.6238 - golden_loss: 3.9814\n",
      "Epoch 549/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.5939 - reconstruction_loss: 15.6234 - golden_loss: 3.9705\n",
      "Epoch 550/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5825 - reconstruction_loss: 15.6228 - golden_loss: 3.9597\n",
      "Epoch 551/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19.5712 - reconstruction_loss: 15.6223 - golden_loss: 3.9489\n",
      "Epoch 552/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.5600 - reconstruction_loss: 15.6218 - golden_loss: 3.9382\n",
      "Epoch 553/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.5488 - reconstruction_loss: 15.6213 - golden_loss: 3.9275\n",
      "Epoch 554/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.5377 - reconstruction_loss: 15.6209 - golden_loss: 3.9168\n",
      "Epoch 555/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5266 - reconstruction_loss: 15.6203 - golden_loss: 3.9063\n",
      "Epoch 556/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.5156 - reconstruction_loss: 15.6199 - golden_loss: 3.8957\n",
      "Epoch 557/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5046 - reconstruction_loss: 15.6194 - golden_loss: 3.8852\n",
      "Epoch 558/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.4936 - reconstruction_loss: 15.6190 - golden_loss: 3.8747\n",
      "Epoch 559/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.4828 - reconstruction_loss: 15.6185 - golden_loss: 3.8643\n",
      "Epoch 560/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.4719 - reconstruction_loss: 15.6180 - golden_loss: 3.8540\n",
      "Epoch 561/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.4611 - reconstruction_loss: 15.6176 - golden_loss: 3.8435\n",
      "Epoch 562/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4504 - reconstruction_loss: 15.6170 - golden_loss: 3.8334\n",
      "Epoch 563/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.4397 - reconstruction_loss: 15.6167 - golden_loss: 3.8230\n",
      "Epoch 564/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.4291 - reconstruction_loss: 15.6161 - golden_loss: 3.8129\n",
      "Epoch 565/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.4185 - reconstruction_loss: 15.6157 - golden_loss: 3.8027\n",
      "Epoch 566/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4079 - reconstruction_loss: 15.6153 - golden_loss: 3.7926\n",
      "Epoch 567/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.3974 - reconstruction_loss: 15.6148 - golden_loss: 3.7826\n",
      "Epoch 568/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.3869 - reconstruction_loss: 15.6144 - golden_loss: 3.7725\n",
      "Epoch 569/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.3765 - reconstruction_loss: 15.6139 - golden_loss: 3.7626\n",
      "Epoch 570/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3662 - reconstruction_loss: 15.6136 - golden_loss: 3.7526\n",
      "Epoch 571/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.3558 - reconstruction_loss: 15.6130 - golden_loss: 3.7428\n",
      "Epoch 572/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.3456 - reconstruction_loss: 15.6128 - golden_loss: 3.7328\n",
      "Epoch 573/2000\n",
      "1/1 [==============================] - 0s 673us/step - loss: 19.3353 - reconstruction_loss: 15.6121 - golden_loss: 3.7232\n",
      "Epoch 574/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.3252 - reconstruction_loss: 15.6120 - golden_loss: 3.7132\n",
      "Epoch 575/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.3150 - reconstruction_loss: 15.6112 - golden_loss: 3.7038\n",
      "Epoch 576/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3049 - reconstruction_loss: 15.6112 - golden_loss: 3.6937\n",
      "Epoch 577/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.2949 - reconstruction_loss: 15.6104 - golden_loss: 3.6845\n",
      "Epoch 578/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.2849 - reconstruction_loss: 15.6105 - golden_loss: 3.6744\n",
      "Epoch 579/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.2749 - reconstruction_loss: 15.6093 - golden_loss: 3.6656\n",
      "Epoch 580/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.2650 - reconstruction_loss: 15.6100 - golden_loss: 3.6550\n",
      "Epoch 581/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19.2551 - reconstruction_loss: 15.6082 - golden_loss: 3.6469\n",
      "Epoch 582/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.2453 - reconstruction_loss: 15.6097 - golden_loss: 3.6356\n",
      "Epoch 583/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.2355 - reconstruction_loss: 15.6067 - golden_loss: 3.6288\n",
      "Epoch 584/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.2257 - reconstruction_loss: 15.6099 - golden_loss: 3.6158\n",
      "Epoch 585/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.2160 - reconstruction_loss: 15.6043 - golden_loss: 3.6117\n",
      "Epoch 586/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.2064 - reconstruction_loss: 15.6117 - golden_loss: 3.5947\n",
      "Epoch 587/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.1970 - reconstruction_loss: 15.5999 - golden_loss: 3.5970\n",
      "Epoch 588/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.1878 - reconstruction_loss: 15.6176 - golden_loss: 3.5702\n",
      "Epoch 589/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.1793 - reconstruction_loss: 15.5909 - golden_loss: 3.5884\n",
      "Epoch 590/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1723 - reconstruction_loss: 15.6359 - golden_loss: 3.5364\n",
      "Epoch 591/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.1692 - reconstruction_loss: 15.5741 - golden_loss: 3.5951\n",
      "Epoch 592/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1753 - reconstruction_loss: 15.6961 - golden_loss: 3.4792\n",
      "Epoch 593/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.1994 - reconstruction_loss: 15.5626 - golden_loss: 3.6368\n",
      "Epoch 594/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.2449 - reconstruction_loss: 15.8602 - golden_loss: 3.3847\n",
      "Epoch 595/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.2765 - reconstruction_loss: 15.5822 - golden_loss: 3.6943\n",
      "Epoch 596/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.2332 - reconstruction_loss: 15.8831 - golden_loss: 3.3501\n",
      "Epoch 597/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.1334 - reconstruction_loss: 15.5474 - golden_loss: 3.5860\n",
      "Epoch 598/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.0991 - reconstruction_loss: 15.5825 - golden_loss: 3.5165\n",
      "Epoch 599/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1473 - reconstruction_loss: 15.7772 - golden_loss: 3.3701\n",
      "Epoch 600/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.1627 - reconstruction_loss: 15.5490 - golden_loss: 3.6137\n",
      "Epoch 601/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.0997 - reconstruction_loss: 15.7161 - golden_loss: 3.3837\n",
      "Epoch 602/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.0597 - reconstruction_loss: 15.6160 - golden_loss: 3.4437\n",
      "Epoch 603/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.0883 - reconstruction_loss: 15.5461 - golden_loss: 3.5422\n",
      "Epoch 604/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.0970 - reconstruction_loss: 15.7615 - golden_loss: 3.3354\n",
      "Epoch 605/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.0511 - reconstruction_loss: 15.5635 - golden_loss: 3.4875\n",
      "Epoch 606/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.0264 - reconstruction_loss: 15.5785 - golden_loss: 3.4480\n",
      "Epoch 607/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19.0444 - reconstruction_loss: 15.7047 - golden_loss: 3.3397\n",
      "Epoch 608/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.0418 - reconstruction_loss: 15.5566 - golden_loss: 3.4852\n",
      "Epoch 609/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.0072 - reconstruction_loss: 15.6386 - golden_loss: 3.3686\n",
      "Epoch 610/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.9931 - reconstruction_loss: 15.6282 - golden_loss: 3.3649\n",
      "Epoch 611/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.0039 - reconstruction_loss: 15.5591 - golden_loss: 3.4449\n",
      "Epoch 612/2000\n",
      "1/1 [==============================] - 0s 326us/step - loss: 18.9950 - reconstruction_loss: 15.6757 - golden_loss: 3.3193\n",
      "Epoch 613/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.9678 - reconstruction_loss: 15.5809 - golden_loss: 3.3870\n",
      "Epoch 614/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.9603 - reconstruction_loss: 15.5772 - golden_loss: 3.3830\n",
      "Epoch 615/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.9652 - reconstruction_loss: 15.6635 - golden_loss: 3.3017\n",
      "Epoch 616/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.9527 - reconstruction_loss: 15.5640 - golden_loss: 3.3887\n",
      "Epoch 617/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.9326 - reconstruction_loss: 15.6134 - golden_loss: 3.3192\n",
      "Epoch 618/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.9272 - reconstruction_loss: 15.6202 - golden_loss: 3.3070\n",
      "Epoch 619/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.9268 - reconstruction_loss: 15.5643 - golden_loss: 3.3625\n",
      "Epoch 620/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.9152 - reconstruction_loss: 15.6436 - golden_loss: 3.2716\n",
      "Epoch 621/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.8997 - reconstruction_loss: 15.5814 - golden_loss: 3.3183\n",
      "Epoch 622/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.8933 - reconstruction_loss: 15.5794 - golden_loss: 3.3138\n",
      "Epoch 623/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8904 - reconstruction_loss: 15.6406 - golden_loss: 3.2499\n",
      "Epoch 624/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8806 - reconstruction_loss: 15.5642 - golden_loss: 3.3165\n",
      "Epoch 625/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8673 - reconstruction_loss: 15.6083 - golden_loss: 3.2590\n",
      "Epoch 626/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.8597 - reconstruction_loss: 15.6093 - golden_loss: 3.2504\n",
      "Epoch 627/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.8557 - reconstruction_loss: 15.5659 - golden_loss: 3.2898\n",
      "Epoch 628/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.8474 - reconstruction_loss: 15.6290 - golden_loss: 3.2184\n",
      "Epoch 629/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.8358 - reconstruction_loss: 15.5797 - golden_loss: 3.2560\n",
      "Epoch 630/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.8272 - reconstruction_loss: 15.5841 - golden_loss: 3.2432\n",
      "Epoch 631/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.8219 - reconstruction_loss: 15.6192 - golden_loss: 3.2027\n",
      "Epoch 632/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.8149 - reconstruction_loss: 15.5692 - golden_loss: 3.2457\n",
      "Epoch 633/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8051 - reconstruction_loss: 15.6088 - golden_loss: 3.1963\n",
      "Epoch 634/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.7958 - reconstruction_loss: 15.5919 - golden_loss: 3.2039\n",
      "Epoch 635/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.7890 - reconstruction_loss: 15.5779 - golden_loss: 3.2111\n",
      "Epoch 636/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7826 - reconstruction_loss: 15.6129 - golden_loss: 3.1698\n",
      "Epoch 637/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7747 - reconstruction_loss: 15.5756 - golden_loss: 3.1991\n",
      "Epoch 638/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.7656 - reconstruction_loss: 15.5987 - golden_loss: 3.1669\n",
      "Epoch 639/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.7575 - reconstruction_loss: 15.5927 - golden_loss: 3.1648\n",
      "Epoch 640/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.7507 - reconstruction_loss: 15.5794 - golden_loss: 3.1713\n",
      "Epoch 641/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7439 - reconstruction_loss: 15.6059 - golden_loss: 3.1381\n",
      "Epoch 642/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.7360 - reconstruction_loss: 15.5769 - golden_loss: 3.1591\n",
      "Epoch 643/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.7276 - reconstruction_loss: 15.5969 - golden_loss: 3.1307\n",
      "Epoch 644/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7199 - reconstruction_loss: 15.5888 - golden_loss: 3.1311\n",
      "Epoch 645/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.7129 - reconstruction_loss: 15.5813 - golden_loss: 3.1316\n",
      "Epoch 646/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.7059 - reconstruction_loss: 15.6012 - golden_loss: 3.1047\n",
      "Epoch 647/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6985 - reconstruction_loss: 15.5759 - golden_loss: 3.1226\n",
      "Epoch 648/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6907 - reconstruction_loss: 15.5974 - golden_loss: 3.0933\n",
      "Epoch 649/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6830 - reconstruction_loss: 15.5841 - golden_loss: 3.0988\n",
      "Epoch 650/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6757 - reconstruction_loss: 15.5837 - golden_loss: 3.0920\n",
      "Epoch 651/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6688 - reconstruction_loss: 15.5958 - golden_loss: 3.0730\n",
      "Epoch 652/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6617 - reconstruction_loss: 15.5764 - golden_loss: 3.0854\n",
      "Epoch 653/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6544 - reconstruction_loss: 15.5969 - golden_loss: 3.0576\n",
      "Epoch 654/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.6470 - reconstruction_loss: 15.5796 - golden_loss: 3.0674\n",
      "Epoch 655/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6396 - reconstruction_loss: 15.5883 - golden_loss: 3.0513\n",
      "Epoch 656/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.6324 - reconstruction_loss: 15.5875 - golden_loss: 3.0450\n",
      "Epoch 657/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6255 - reconstruction_loss: 15.5804 - golden_loss: 3.0450\n",
      "Epoch 658/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.6185 - reconstruction_loss: 15.5923 - golden_loss: 3.0262\n",
      "Epoch 659/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6116 - reconstruction_loss: 15.5779 - golden_loss: 3.0337\n",
      "Epoch 660/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.6045 - reconstruction_loss: 15.5918 - golden_loss: 3.0127\n",
      "Epoch 661/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.5974 - reconstruction_loss: 15.5791 - golden_loss: 3.0182\n",
      "Epoch 662/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5903 - reconstruction_loss: 15.5880 - golden_loss: 3.0023\n",
      "Epoch 663/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5832 - reconstruction_loss: 15.5823 - golden_loss: 3.0009\n",
      "Epoch 664/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.5763 - reconstruction_loss: 15.5833 - golden_loss: 2.9930\n",
      "Epoch 665/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.5694 - reconstruction_loss: 15.5860 - golden_loss: 2.9834\n",
      "Epoch 666/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18.5626 - reconstruction_loss: 15.5791 - golden_loss: 2.9835\n",
      "Epoch 667/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5559 - reconstruction_loss: 15.5888 - golden_loss: 2.9671\n",
      "Epoch 668/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.5491 - reconstruction_loss: 15.5767 - golden_loss: 2.9723\n",
      "Epoch 669/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.5423 - reconstruction_loss: 15.5894 - golden_loss: 2.9529\n",
      "Epoch 670/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.5355 - reconstruction_loss: 15.5762 - golden_loss: 2.9593\n",
      "Epoch 671/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5287 - reconstruction_loss: 15.5883 - golden_loss: 2.9404\n",
      "Epoch 672/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.5220 - reconstruction_loss: 15.5766 - golden_loss: 2.9454\n",
      "Epoch 673/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.5153 - reconstruction_loss: 15.5870 - golden_loss: 2.9283\n",
      "Epoch 674/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5086 - reconstruction_loss: 15.5767 - golden_loss: 2.9319\n",
      "Epoch 675/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.5019 - reconstruction_loss: 15.5864 - golden_loss: 2.9155\n",
      "Epoch 676/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4953 - reconstruction_loss: 15.5760 - golden_loss: 2.9193\n",
      "Epoch 677/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.4887 - reconstruction_loss: 15.5867 - golden_loss: 2.9020\n",
      "Epoch 678/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.4822 - reconstruction_loss: 15.5745 - golden_loss: 2.9077\n",
      "Epoch 679/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.4757 - reconstruction_loss: 15.5881 - golden_loss: 2.8877\n",
      "Epoch 680/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.4693 - reconstruction_loss: 15.5720 - golden_loss: 2.8974\n",
      "Epoch 681/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.4631 - reconstruction_loss: 15.5914 - golden_loss: 2.8717\n",
      "Epoch 682/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.4571 - reconstruction_loss: 15.5674 - golden_loss: 2.8897\n",
      "Epoch 683/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.4516 - reconstruction_loss: 15.5995 - golden_loss: 2.8520\n",
      "Epoch 684/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.4468 - reconstruction_loss: 15.5592 - golden_loss: 2.8876\n",
      "Epoch 685/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4438 - reconstruction_loss: 15.6191 - golden_loss: 2.8247\n",
      "Epoch 686/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.4440 - reconstruction_loss: 15.5471 - golden_loss: 2.8969\n",
      "Epoch 687/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.4509 - reconstruction_loss: 15.6690 - golden_loss: 2.7819\n",
      "Epoch 688/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.4699 - reconstruction_loss: 15.5420 - golden_loss: 2.9279\n",
      "Epoch 689/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5088 - reconstruction_loss: 15.7946 - golden_loss: 2.7143\n",
      "Epoch 690/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5675 - reconstruction_loss: 15.5849 - golden_loss: 2.9826\n",
      "Epoch 691/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.6183 - reconstruction_loss: 15.9706 - golden_loss: 2.6477\n",
      "Epoch 692/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.5932 - reconstruction_loss: 15.6117 - golden_loss: 2.9816\n",
      "Epoch 693/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.4826 - reconstruction_loss: 15.7787 - golden_loss: 2.7039\n",
      "Epoch 694/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.3892 - reconstruction_loss: 15.5689 - golden_loss: 2.8203\n",
      "Epoch 695/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.4031 - reconstruction_loss: 15.5373 - golden_loss: 2.8658\n",
      "Epoch 696/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4672 - reconstruction_loss: 15.7903 - golden_loss: 2.6769\n",
      "Epoch 697/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4697 - reconstruction_loss: 15.5713 - golden_loss: 2.8985\n",
      "Epoch 698/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4010 - reconstruction_loss: 15.6791 - golden_loss: 2.7220\n",
      "Epoch 699/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.3553 - reconstruction_loss: 15.5945 - golden_loss: 2.7608\n",
      "Epoch 700/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.3800 - reconstruction_loss: 15.5396 - golden_loss: 2.8404\n",
      "Epoch 701/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.4092 - reconstruction_loss: 15.7333 - golden_loss: 2.6759\n",
      "Epoch 702/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.3817 - reconstruction_loss: 15.5614 - golden_loss: 2.8203\n",
      "Epoch 703/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.3357 - reconstruction_loss: 15.5936 - golden_loss: 2.7422\n",
      "Epoch 704/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.3328 - reconstruction_loss: 15.6258 - golden_loss: 2.7070\n",
      "Epoch 705/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.3565 - reconstruction_loss: 15.5500 - golden_loss: 2.8065\n",
      "Epoch 706/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.3511 - reconstruction_loss: 15.6720 - golden_loss: 2.6791\n",
      "Epoch 707/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.3163 - reconstruction_loss: 15.5631 - golden_loss: 2.7532\n",
      "Epoch 708/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.3014 - reconstruction_loss: 15.5595 - golden_loss: 2.7419\n",
      "Epoch 709/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.3151 - reconstruction_loss: 15.6406 - golden_loss: 2.6745\n",
      "Epoch 710/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.3181 - reconstruction_loss: 15.5551 - golden_loss: 2.7630\n",
      "Epoch 711/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.2956 - reconstruction_loss: 15.6181 - golden_loss: 2.6775\n",
      "Epoch 712/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.2770 - reconstruction_loss: 15.5733 - golden_loss: 2.7037\n",
      "Epoch 713/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.2807 - reconstruction_loss: 15.5567 - golden_loss: 2.7239\n",
      "Epoch 714/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.2859 - reconstruction_loss: 15.6334 - golden_loss: 2.6524\n",
      "Epoch 715/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.2736 - reconstruction_loss: 15.5522 - golden_loss: 2.7214\n",
      "Epoch 716/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.2565 - reconstruction_loss: 15.5906 - golden_loss: 2.6659\n",
      "Epoch 717/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.2519 - reconstruction_loss: 15.5848 - golden_loss: 2.6671\n",
      "Epoch 718/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.2545 - reconstruction_loss: 15.5564 - golden_loss: 2.6981\n",
      "Epoch 719/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.2498 - reconstruction_loss: 15.6179 - golden_loss: 2.6320\n",
      "Epoch 720/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.2376 - reconstruction_loss: 15.5522 - golden_loss: 2.6854\n",
      "Epoch 721/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.2283 - reconstruction_loss: 15.5813 - golden_loss: 2.6471\n",
      "Epoch 722/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.2257 - reconstruction_loss: 15.5882 - golden_loss: 2.6375\n",
      "Epoch 723/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.2236 - reconstruction_loss: 15.5538 - golden_loss: 2.6698\n",
      "Epoch 724/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.2173 - reconstruction_loss: 15.6068 - golden_loss: 2.6105\n",
      "Epoch 725/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.2085 - reconstruction_loss: 15.5545 - golden_loss: 2.6540\n",
      "Epoch 726/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.2015 - reconstruction_loss: 15.5779 - golden_loss: 2.6235\n",
      "Epoch 727/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.1973 - reconstruction_loss: 15.5852 - golden_loss: 2.6121\n",
      "Epoch 728/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.1938 - reconstruction_loss: 15.5533 - golden_loss: 2.6404\n",
      "Epoch 729/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.1886 - reconstruction_loss: 15.6002 - golden_loss: 2.5884\n",
      "Epoch 730/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.1815 - reconstruction_loss: 15.5553 - golden_loss: 2.6261\n",
      "Epoch 731/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.1745 - reconstruction_loss: 15.5779 - golden_loss: 2.5966\n",
      "Epoch 732/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.1692 - reconstruction_loss: 15.5789 - golden_loss: 2.5903\n",
      "Epoch 733/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.1654 - reconstruction_loss: 15.5557 - golden_loss: 2.6097\n",
      "Epoch 734/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.1611 - reconstruction_loss: 15.5946 - golden_loss: 2.5665\n",
      "Epoch 735/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.1551 - reconstruction_loss: 15.5548 - golden_loss: 2.6003\n",
      "Epoch 736/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.1483 - reconstruction_loss: 15.5808 - golden_loss: 2.5675\n",
      "Epoch 737/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.1424 - reconstruction_loss: 15.5707 - golden_loss: 2.5717\n",
      "Epoch 738/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.1379 - reconstruction_loss: 15.5610 - golden_loss: 2.5769\n",
      "Epoch 739/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.1338 - reconstruction_loss: 15.5869 - golden_loss: 2.5469\n",
      "Epoch 740/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.1289 - reconstruction_loss: 15.5552 - golden_loss: 2.5737\n",
      "Epoch 741/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.1231 - reconstruction_loss: 15.5842 - golden_loss: 2.5389\n",
      "Epoch 742/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.1171 - reconstruction_loss: 15.5625 - golden_loss: 2.5546\n",
      "Epoch 743/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.1117 - reconstruction_loss: 15.5698 - golden_loss: 2.5419\n",
      "Epoch 744/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.1069 - reconstruction_loss: 15.5752 - golden_loss: 2.5316\n",
      "Epoch 745/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.1022 - reconstruction_loss: 15.5598 - golden_loss: 2.5425\n",
      "Epoch 746/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.0975 - reconstruction_loss: 15.5817 - golden_loss: 2.5158\n",
      "Epoch 747/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0924 - reconstruction_loss: 15.5585 - golden_loss: 2.5339\n",
      "Epoch 748/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.0871 - reconstruction_loss: 15.5782 - golden_loss: 2.5089\n",
      "Epoch 749/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.0818 - reconstruction_loss: 15.5634 - golden_loss: 2.5184\n",
      "Epoch 750/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.0766 - reconstruction_loss: 15.5703 - golden_loss: 2.5063\n",
      "Epoch 751/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.0715 - reconstruction_loss: 15.5699 - golden_loss: 2.5017\n",
      "Epoch 752/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.0666 - reconstruction_loss: 15.5639 - golden_loss: 2.5027\n",
      "Epoch 753/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0619 - reconstruction_loss: 15.5745 - golden_loss: 2.4874\n",
      "Epoch 754/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.0572 - reconstruction_loss: 15.5610 - golden_loss: 2.4962\n",
      "Epoch 755/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.0524 - reconstruction_loss: 15.5761 - golden_loss: 2.4763\n",
      "Epoch 756/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.0475 - reconstruction_loss: 15.5605 - golden_loss: 2.4870\n",
      "Epoch 757/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0425 - reconstruction_loss: 15.5751 - golden_loss: 2.4674\n",
      "Epoch 758/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.0375 - reconstruction_loss: 15.5612 - golden_loss: 2.4763\n",
      "Epoch 759/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.0325 - reconstruction_loss: 15.5729 - golden_loss: 2.4596\n",
      "Epoch 760/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.0276 - reconstruction_loss: 15.5627 - golden_loss: 2.4649\n",
      "Epoch 761/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.0227 - reconstruction_loss: 15.5703 - golden_loss: 2.4524\n",
      "Epoch 762/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.0179 - reconstruction_loss: 15.5645 - golden_loss: 2.4534\n",
      "Epoch 763/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0131 - reconstruction_loss: 15.5678 - golden_loss: 2.4453\n",
      "Epoch 764/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.0083 - reconstruction_loss: 15.5664 - golden_loss: 2.4419\n",
      "Epoch 765/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0035 - reconstruction_loss: 15.5654 - golden_loss: 2.4381\n",
      "Epoch 766/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.9988 - reconstruction_loss: 15.5682 - golden_loss: 2.4306\n",
      "Epoch 767/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.9941 - reconstruction_loss: 15.5632 - golden_loss: 2.4309\n",
      "Epoch 768/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.9895 - reconstruction_loss: 15.5701 - golden_loss: 2.4194\n",
      "Epoch 769/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.9849 - reconstruction_loss: 15.5609 - golden_loss: 2.4239\n",
      "Epoch 770/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.9803 - reconstruction_loss: 15.5725 - golden_loss: 2.4078\n",
      "Epoch 771/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.9758 - reconstruction_loss: 15.5580 - golden_loss: 2.4178\n",
      "Epoch 772/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9715 - reconstruction_loss: 15.5766 - golden_loss: 2.3949\n",
      "Epoch 773/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.9674 - reconstruction_loss: 15.5535 - golden_loss: 2.4139\n",
      "Epoch 774/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.9639 - reconstruction_loss: 15.5850 - golden_loss: 2.3789\n",
      "Epoch 775/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.9612 - reconstruction_loss: 15.5464 - golden_loss: 2.4148\n",
      "Epoch 776/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9605 - reconstruction_loss: 15.6044 - golden_loss: 2.3560\n",
      "Epoch 777/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.9633 - reconstruction_loss: 15.5375 - golden_loss: 2.4259\n",
      "Epoch 778/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.9733 - reconstruction_loss: 15.6540 - golden_loss: 2.3193\n",
      "Epoch 779/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.9967 - reconstruction_loss: 15.5400 - golden_loss: 2.4567\n",
      "Epoch 780/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.0422 - reconstruction_loss: 15.7829 - golden_loss: 2.2593\n",
      "Epoch 781/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.1141 - reconstruction_loss: 15.6018 - golden_loss: 2.5123\n",
      "Epoch 782/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.1892 - reconstruction_loss: 15.9969 - golden_loss: 2.1924\n",
      "Epoch 783/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.1961 - reconstruction_loss: 15.6648 - golden_loss: 2.5313\n",
      "Epoch 784/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.0919 - reconstruction_loss: 15.8650 - golden_loss: 2.2269\n",
      "Epoch 785/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9685 - reconstruction_loss: 15.5762 - golden_loss: 2.3923\n",
      "Epoch 786/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.9555 - reconstruction_loss: 15.5640 - golden_loss: 2.3915\n",
      "Epoch 787/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 18.0171 - reconstruction_loss: 15.7854 - golden_loss: 2.2316\n",
      "Epoch 788/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0246 - reconstruction_loss: 15.5661 - golden_loss: 2.4585\n",
      "Epoch 789/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.9500 - reconstruction_loss: 15.6945 - golden_loss: 2.2555\n",
      "Epoch 790/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.9097 - reconstruction_loss: 15.5805 - golden_loss: 2.3292\n",
      "Epoch 791/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.9526 - reconstruction_loss: 15.5624 - golden_loss: 2.3902\n",
      "Epoch 792/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.9791 - reconstruction_loss: 15.7514 - golden_loss: 2.2277\n",
      "Epoch 793/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.9279 - reconstruction_loss: 15.5415 - golden_loss: 2.3863\n",
      "Epoch 794/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.8760 - reconstruction_loss: 15.5774 - golden_loss: 2.2986\n",
      "Epoch 795/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.8964 - reconstruction_loss: 15.6336 - golden_loss: 2.2628\n",
      "Epoch 796/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.9310 - reconstruction_loss: 15.5536 - golden_loss: 2.3774\n",
      "Epoch 797/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.9077 - reconstruction_loss: 15.6668 - golden_loss: 2.2410\n",
      "Epoch 798/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.8645 - reconstruction_loss: 15.5547 - golden_loss: 2.3098\n",
      "Epoch 799/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.8644 - reconstruction_loss: 15.5383 - golden_loss: 2.3262\n",
      "Epoch 800/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.8863 - reconstruction_loss: 15.6589 - golden_loss: 2.2274\n",
      "Epoch 801/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.8781 - reconstruction_loss: 15.5418 - golden_loss: 2.3363\n",
      "Epoch 802/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.8504 - reconstruction_loss: 15.5874 - golden_loss: 2.2630\n",
      "Epoch 803/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.8452 - reconstruction_loss: 15.5946 - golden_loss: 2.2506\n",
      "Epoch 804/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.8569 - reconstruction_loss: 15.5340 - golden_loss: 2.3229\n",
      "Epoch 805/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.8517 - reconstruction_loss: 15.6323 - golden_loss: 2.2194\n",
      "Epoch 806/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.8315 - reconstruction_loss: 15.5453 - golden_loss: 2.2862\n",
      "Epoch 807/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.8244 - reconstruction_loss: 15.5512 - golden_loss: 2.2732\n",
      "Epoch 808/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.8322 - reconstruction_loss: 15.6153 - golden_loss: 2.2169\n",
      "Epoch 809/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.8317 - reconstruction_loss: 15.5351 - golden_loss: 2.2966\n",
      "Epoch 810/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.8167 - reconstruction_loss: 15.5964 - golden_loss: 2.2204\n",
      "Epoch 811/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.8055 - reconstruction_loss: 15.5610 - golden_loss: 2.2445\n",
      "Epoch 812/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.8071 - reconstruction_loss: 15.5419 - golden_loss: 2.2652\n",
      "Epoch 813/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.8094 - reconstruction_loss: 15.6085 - golden_loss: 2.2009\n",
      "Epoch 814/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.8021 - reconstruction_loss: 15.5396 - golden_loss: 2.2624\n",
      "Epoch 815/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7916 - reconstruction_loss: 15.5740 - golden_loss: 2.2176\n",
      "Epoch 816/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7878 - reconstruction_loss: 15.5726 - golden_loss: 2.2151\n",
      "Epoch 817/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7881 - reconstruction_loss: 15.5430 - golden_loss: 2.2452\n",
      "Epoch 818/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.7845 - reconstruction_loss: 15.5932 - golden_loss: 2.1914\n",
      "Epoch 819/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.7764 - reconstruction_loss: 15.5463 - golden_loss: 2.2302\n",
      "Epoch 820/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.7702 - reconstruction_loss: 15.5620 - golden_loss: 2.2082\n",
      "Epoch 821/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7686 - reconstruction_loss: 15.5753 - golden_loss: 2.1933\n",
      "Epoch 822/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7674 - reconstruction_loss: 15.5456 - golden_loss: 2.2218\n",
      "Epoch 823/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7626 - reconstruction_loss: 15.5823 - golden_loss: 2.1803\n",
      "Epoch 824/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.7558 - reconstruction_loss: 15.5524 - golden_loss: 2.2034\n",
      "Epoch 825/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.7507 - reconstruction_loss: 15.5572 - golden_loss: 2.1935\n",
      "Epoch 826/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.7481 - reconstruction_loss: 15.5738 - golden_loss: 2.1743\n",
      "Epoch 827/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.7457 - reconstruction_loss: 15.5455 - golden_loss: 2.2002\n",
      "Epoch 828/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.7414 - reconstruction_loss: 15.5768 - golden_loss: 2.1645\n",
      "Epoch 829/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7360 - reconstruction_loss: 15.5525 - golden_loss: 2.1835\n",
      "Epoch 830/2000\n",
      "1/1 [==============================] - 0s 497us/step - loss: 17.7315 - reconstruction_loss: 15.5582 - golden_loss: 2.1733\n",
      "Epoch 831/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7285 - reconstruction_loss: 15.5698 - golden_loss: 2.1588\n",
      "Epoch 832/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.7257 - reconstruction_loss: 15.5472 - golden_loss: 2.1786\n",
      "Epoch 833/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.7220 - reconstruction_loss: 15.5753 - golden_loss: 2.1467\n",
      "Epoch 834/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.7173 - reconstruction_loss: 15.5499 - golden_loss: 2.1674\n",
      "Epoch 835/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.7127 - reconstruction_loss: 15.5634 - golden_loss: 2.1494\n",
      "Epoch 836/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.7089 - reconstruction_loss: 15.5615 - golden_loss: 2.1474\n",
      "Epoch 837/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.7057 - reconstruction_loss: 15.5523 - golden_loss: 2.1534\n",
      "Epoch 838/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.7023 - reconstruction_loss: 15.5694 - golden_loss: 2.1330\n",
      "Epoch 839/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6984 - reconstruction_loss: 15.5507 - golden_loss: 2.1478\n",
      "Epoch 840/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6942 - reconstruction_loss: 15.5650 - golden_loss: 2.1291\n",
      "Epoch 841/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.6901 - reconstruction_loss: 15.5566 - golden_loss: 2.1335\n",
      "Epoch 842/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6863 - reconstruction_loss: 15.5559 - golden_loss: 2.1304\n",
      "Epoch 843/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.6829 - reconstruction_loss: 15.5645 - golden_loss: 2.1184\n",
      "Epoch 844/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.6795 - reconstruction_loss: 15.5508 - golden_loss: 2.1287\n",
      "Epoch 845/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6759 - reconstruction_loss: 15.5670 - golden_loss: 2.1089\n",
      "Epoch 846/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.6721 - reconstruction_loss: 15.5513 - golden_loss: 2.1208\n",
      "Epoch 847/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.6682 - reconstruction_loss: 15.5631 - golden_loss: 2.1051\n",
      "Epoch 848/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6645 - reconstruction_loss: 15.5556 - golden_loss: 2.1089\n",
      "Epoch 849/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.6610 - reconstruction_loss: 15.5578 - golden_loss: 2.1031\n",
      "Epoch 850/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6577 - reconstruction_loss: 15.5604 - golden_loss: 2.0973\n",
      "Epoch 851/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6546 - reconstruction_loss: 15.5554 - golden_loss: 2.0992\n",
      "Epoch 852/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.6518 - reconstruction_loss: 15.5628 - golden_loss: 2.0890\n",
      "Epoch 853/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.6495 - reconstruction_loss: 15.5582 - golden_loss: 2.0913\n",
      "Epoch 854/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.6484 - reconstruction_loss: 15.5635 - golden_loss: 2.0849\n",
      "Epoch 855/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6497 - reconstruction_loss: 15.5701 - golden_loss: 2.0795\n",
      "Epoch 856/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.6555 - reconstruction_loss: 15.5707 - golden_loss: 2.0848\n",
      "Epoch 857/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6698 - reconstruction_loss: 15.6063 - golden_loss: 2.0636\n",
      "Epoch 858/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.6976 - reconstruction_loss: 15.6077 - golden_loss: 2.0899\n",
      "Epoch 859/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.7430 - reconstruction_loss: 15.7015 - golden_loss: 2.0415\n",
      "Epoch 860/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.7927 - reconstruction_loss: 15.6890 - golden_loss: 2.1037\n",
      "Epoch 861/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.8170 - reconstruction_loss: 15.8073 - golden_loss: 2.0097\n",
      "Epoch 862/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.7786 - reconstruction_loss: 15.6522 - golden_loss: 2.1264\n",
      "Epoch 863/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7148 - reconstruction_loss: 15.7383 - golden_loss: 1.9765\n",
      "Epoch 864/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6841 - reconstruction_loss: 15.5485 - golden_loss: 2.1356\n",
      "Epoch 865/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6903 - reconstruction_loss: 15.7138 - golden_loss: 1.9764\n",
      "Epoch 866/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.6837 - reconstruction_loss: 15.5877 - golden_loss: 2.0960\n",
      "Epoch 867/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.6414 - reconstruction_loss: 15.6144 - golden_loss: 2.0270\n",
      "Epoch 868/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.6086 - reconstruction_loss: 15.5903 - golden_loss: 2.0183\n",
      "Epoch 869/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.6248 - reconstruction_loss: 15.5359 - golden_loss: 2.0889\n",
      "Epoch 870/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.6619 - reconstruction_loss: 15.6979 - golden_loss: 1.9640\n",
      "Epoch 871/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.6641 - reconstruction_loss: 15.5627 - golden_loss: 2.1014\n",
      "Epoch 872/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6227 - reconstruction_loss: 15.6488 - golden_loss: 1.9739\n",
      "Epoch 873/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5876 - reconstruction_loss: 15.5379 - golden_loss: 2.0497\n",
      "Epoch 874/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.5890 - reconstruction_loss: 15.5633 - golden_loss: 2.0257\n",
      "Epoch 875/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6045 - reconstruction_loss: 15.6151 - golden_loss: 1.9894\n",
      "Epoch 876/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6035 - reconstruction_loss: 15.5467 - golden_loss: 2.0568\n",
      "Epoch 877/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.5890 - reconstruction_loss: 15.6194 - golden_loss: 1.9695\n",
      "Epoch 878/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.5828 - reconstruction_loss: 15.5395 - golden_loss: 2.0434\n",
      "Epoch 879/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.5864 - reconstruction_loss: 15.6024 - golden_loss: 1.9840\n",
      "Epoch 880/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.5822 - reconstruction_loss: 15.5701 - golden_loss: 2.0121\n",
      "Epoch 881/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.5659 - reconstruction_loss: 15.5656 - golden_loss: 2.0003\n",
      "Epoch 882/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5528 - reconstruction_loss: 15.5632 - golden_loss: 1.9896\n",
      "Epoch 883/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5548 - reconstruction_loss: 15.5497 - golden_loss: 2.0051\n",
      "Epoch 884/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.5630 - reconstruction_loss: 15.5871 - golden_loss: 1.9759\n",
      "Epoch 885/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.5625 - reconstruction_loss: 15.5566 - golden_loss: 2.0059\n",
      "Epoch 886/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.5523 - reconstruction_loss: 15.5886 - golden_loss: 1.9637\n",
      "Epoch 887/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5430 - reconstruction_loss: 15.5388 - golden_loss: 2.0042\n",
      "Epoch 888/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.5403 - reconstruction_loss: 15.5826 - golden_loss: 1.9576\n",
      "Epoch 889/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5392 - reconstruction_loss: 15.5470 - golden_loss: 1.9922\n",
      "Epoch 890/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.5339 - reconstruction_loss: 15.5697 - golden_loss: 1.9641\n",
      "Epoch 891/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.5264 - reconstruction_loss: 15.5576 - golden_loss: 1.9689\n",
      "Epoch 892/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.5226 - reconstruction_loss: 15.5454 - golden_loss: 1.9772\n",
      "Epoch 893/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.5233 - reconstruction_loss: 15.5772 - golden_loss: 1.9461\n",
      "Epoch 894/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5239 - reconstruction_loss: 15.5405 - golden_loss: 1.9833\n",
      "Epoch 895/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.5208 - reconstruction_loss: 15.5862 - golden_loss: 1.9346\n",
      "Epoch 896/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.5153 - reconstruction_loss: 15.5384 - golden_loss: 1.9768\n",
      "Epoch 897/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.5107 - reconstruction_loss: 15.5768 - golden_loss: 1.9339\n",
      "Epoch 898/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.5082 - reconstruction_loss: 15.5446 - golden_loss: 1.9636\n",
      "Epoch 899/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5060 - reconstruction_loss: 15.5708 - golden_loss: 1.9352\n",
      "Epoch 900/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.5021 - reconstruction_loss: 15.5498 - golden_loss: 1.9523\n",
      "Epoch 901/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.4969 - reconstruction_loss: 15.5643 - golden_loss: 1.9326\n",
      "Epoch 902/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4923 - reconstruction_loss: 15.5472 - golden_loss: 1.9451\n",
      "Epoch 903/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.4892 - reconstruction_loss: 15.5619 - golden_loss: 1.9273\n",
      "Epoch 904/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.4871 - reconstruction_loss: 15.5485 - golden_loss: 1.9386\n",
      "Epoch 905/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.4844 - reconstruction_loss: 15.5612 - golden_loss: 1.9233\n",
      "Epoch 906/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.4809 - reconstruction_loss: 15.5511 - golden_loss: 1.9298\n",
      "Epoch 907/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.4770 - reconstruction_loss: 15.5554 - golden_loss: 1.9217\n",
      "Epoch 908/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.4737 - reconstruction_loss: 15.5545 - golden_loss: 1.9193\n",
      "Epoch 909/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.4712 - reconstruction_loss: 15.5505 - golden_loss: 1.9207\n",
      "Epoch 910/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.4689 - reconstruction_loss: 15.5594 - golden_loss: 1.9095\n",
      "Epoch 911/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4663 - reconstruction_loss: 15.5481 - golden_loss: 1.9181\n",
      "Epoch 912/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4633 - reconstruction_loss: 15.5618 - golden_loss: 1.9015\n",
      "Epoch 913/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4602 - reconstruction_loss: 15.5458 - golden_loss: 1.9144\n",
      "Epoch 914/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.4575 - reconstruction_loss: 15.5639 - golden_loss: 1.8936\n",
      "Epoch 915/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.4556 - reconstruction_loss: 15.5435 - golden_loss: 1.9120\n",
      "Epoch 916/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.4545 - reconstruction_loss: 15.5718 - golden_loss: 1.8827\n",
      "Epoch 917/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.4546 - reconstruction_loss: 15.5398 - golden_loss: 1.9148\n",
      "Epoch 918/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4569 - reconstruction_loss: 15.5923 - golden_loss: 1.8646\n",
      "Epoch 919/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.4637 - reconstruction_loss: 15.5361 - golden_loss: 1.9275\n",
      "Epoch 920/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4792 - reconstruction_loss: 15.6455 - golden_loss: 1.8337\n",
      "Epoch 921/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.5107 - reconstruction_loss: 15.5532 - golden_loss: 1.9575\n",
      "Epoch 922/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.5685 - reconstruction_loss: 15.7851 - golden_loss: 1.7833\n",
      "Epoch 923/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.6578 - reconstruction_loss: 15.6493 - golden_loss: 2.0084\n",
      "Epoch 924/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.7567 - reconstruction_loss: 16.0311 - golden_loss: 1.7256\n",
      "Epoch 925/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.7875 - reconstruction_loss: 15.7528 - golden_loss: 2.0348\n",
      "Epoch 926/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6818 - reconstruction_loss: 15.9380 - golden_loss: 1.7439\n",
      "Epoch 927/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.5111 - reconstruction_loss: 15.5800 - golden_loss: 1.9311\n",
      "Epoch 928/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.4473 - reconstruction_loss: 15.5651 - golden_loss: 1.8822\n",
      "Epoch 929/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.5115 - reconstruction_loss: 15.7292 - golden_loss: 1.7823\n",
      "Epoch 930/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.5686 - reconstruction_loss: 15.5991 - golden_loss: 1.9695\n",
      "Epoch 931/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.5238 - reconstruction_loss: 15.7535 - golden_loss: 1.7703\n",
      "Epoch 932/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.4509 - reconstruction_loss: 15.5624 - golden_loss: 1.8885\n",
      "Epoch 933/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.4568 - reconstruction_loss: 15.5748 - golden_loss: 1.8820\n",
      "Epoch 934/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.5017 - reconstruction_loss: 15.7219 - golden_loss: 1.7798\n",
      "Epoch 935/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4868 - reconstruction_loss: 15.5635 - golden_loss: 1.9233\n",
      "Epoch 936/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4220 - reconstruction_loss: 15.6198 - golden_loss: 1.8021\n",
      "Epoch 937/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.4051 - reconstruction_loss: 15.5686 - golden_loss: 1.8365\n",
      "Epoch 938/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.4482 - reconstruction_loss: 15.5618 - golden_loss: 1.8864\n",
      "Epoch 939/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.4662 - reconstruction_loss: 15.6872 - golden_loss: 1.7790\n",
      "Epoch 940/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.4248 - reconstruction_loss: 15.5485 - golden_loss: 1.8763\n",
      "Epoch 941/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.3855 - reconstruction_loss: 15.5575 - golden_loss: 1.8280\n",
      "Epoch 942/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3975 - reconstruction_loss: 15.5988 - golden_loss: 1.7987\n",
      "Epoch 943/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.4236 - reconstruction_loss: 15.5477 - golden_loss: 1.8760\n",
      "Epoch 944/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4145 - reconstruction_loss: 15.6292 - golden_loss: 1.7853\n",
      "Epoch 945/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3859 - reconstruction_loss: 15.5512 - golden_loss: 1.8347\n",
      "Epoch 946/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.3786 - reconstruction_loss: 15.5394 - golden_loss: 1.8392\n",
      "Epoch 947/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.3909 - reconstruction_loss: 15.6130 - golden_loss: 1.7778\n",
      "Epoch 948/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.3914 - reconstruction_loss: 15.5362 - golden_loss: 1.8552\n",
      "Epoch 949/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3749 - reconstruction_loss: 15.5845 - golden_loss: 1.7905\n",
      "Epoch 950/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3652 - reconstruction_loss: 15.5605 - golden_loss: 1.8048\n",
      "Epoch 951/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.3714 - reconstruction_loss: 15.5360 - golden_loss: 1.8354\n",
      "Epoch 952/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.3759 - reconstruction_loss: 15.6079 - golden_loss: 1.7680\n",
      "Epoch 953/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3659 - reconstruction_loss: 15.5338 - golden_loss: 1.8321\n",
      "Epoch 954/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.3524 - reconstruction_loss: 15.5629 - golden_loss: 1.7895\n",
      "Epoch 955/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.3503 - reconstruction_loss: 15.5643 - golden_loss: 1.7861\n",
      "Epoch 956/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.3562 - reconstruction_loss: 15.5348 - golden_loss: 1.8214\n",
      "Epoch 957/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.3564 - reconstruction_loss: 15.5934 - golden_loss: 1.7630\n",
      "Epoch 958/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.3478 - reconstruction_loss: 15.5371 - golden_loss: 1.8107\n",
      "Epoch 959/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.3396 - reconstruction_loss: 15.5570 - golden_loss: 1.7825\n",
      "Epoch 960/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.3382 - reconstruction_loss: 15.5639 - golden_loss: 1.7743\n",
      "Epoch 961/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.3396 - reconstruction_loss: 15.5366 - golden_loss: 1.8030\n",
      "Epoch 962/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3371 - reconstruction_loss: 15.5780 - golden_loss: 1.7591\n",
      "Epoch 963/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.3311 - reconstruction_loss: 15.5396 - golden_loss: 1.7914\n",
      "Epoch 964/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.3267 - reconstruction_loss: 15.5539 - golden_loss: 1.7728\n",
      "Epoch 965/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3260 - reconstruction_loss: 15.5616 - golden_loss: 1.7644\n",
      "Epoch 966/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.3258 - reconstruction_loss: 15.5410 - golden_loss: 1.7848\n",
      "Epoch 967/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.3228 - reconstruction_loss: 15.5694 - golden_loss: 1.7534\n",
      "Epoch 968/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.3175 - reconstruction_loss: 15.5430 - golden_loss: 1.7745\n",
      "Epoch 969/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.3132 - reconstruction_loss: 15.5512 - golden_loss: 1.7620\n",
      "Epoch 970/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.3114 - reconstruction_loss: 15.5577 - golden_loss: 1.7537\n",
      "Epoch 971/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3106 - reconstruction_loss: 15.5409 - golden_loss: 1.7697\n",
      "Epoch 972/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3086 - reconstruction_loss: 15.5650 - golden_loss: 1.7437\n",
      "Epoch 973/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3052 - reconstruction_loss: 15.5434 - golden_loss: 1.7617\n",
      "Epoch 974/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3016 - reconstruction_loss: 15.5532 - golden_loss: 1.7484\n",
      "Epoch 975/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2991 - reconstruction_loss: 15.5547 - golden_loss: 1.7444\n",
      "Epoch 976/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.2974 - reconstruction_loss: 15.5423 - golden_loss: 1.7551\n",
      "Epoch 977/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.2955 - reconstruction_loss: 15.5632 - golden_loss: 1.7324\n",
      "Epoch 978/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2928 - reconstruction_loss: 15.5410 - golden_loss: 1.7518\n",
      "Epoch 979/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.2895 - reconstruction_loss: 15.5579 - golden_loss: 1.7316\n",
      "Epoch 980/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2863 - reconstruction_loss: 15.5472 - golden_loss: 1.7391\n",
      "Epoch 981/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2839 - reconstruction_loss: 15.5478 - golden_loss: 1.7361\n",
      "Epoch 982/2000\n",
      "1/1 [==============================] - 0s 719us/step - loss: 17.2819 - reconstruction_loss: 15.5557 - golden_loss: 1.7262\n",
      "Epoch 983/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.2798 - reconstruction_loss: 15.5431 - golden_loss: 1.7367\n",
      "Epoch 984/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.2773 - reconstruction_loss: 15.5576 - golden_loss: 1.7197\n",
      "Epoch 985/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.2745 - reconstruction_loss: 15.5443 - golden_loss: 1.7302\n",
      "Epoch 986/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2718 - reconstruction_loss: 15.5523 - golden_loss: 1.7194\n",
      "Epoch 987/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.2693 - reconstruction_loss: 15.5495 - golden_loss: 1.7198\n",
      "Epoch 988/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.2671 - reconstruction_loss: 15.5468 - golden_loss: 1.7203\n",
      "Epoch 989/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.2650 - reconstruction_loss: 15.5542 - golden_loss: 1.7108\n",
      "Epoch 990/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2628 - reconstruction_loss: 15.5448 - golden_loss: 1.7180\n",
      "Epoch 991/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.2604 - reconstruction_loss: 15.5544 - golden_loss: 1.7060\n",
      "Epoch 992/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2580 - reconstruction_loss: 15.5465 - golden_loss: 1.7115\n",
      "Epoch 993/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.2556 - reconstruction_loss: 15.5509 - golden_loss: 1.7046\n",
      "Epoch 994/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.2534 - reconstruction_loss: 15.5507 - golden_loss: 1.7027\n",
      "Epoch 995/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.2515 - reconstruction_loss: 15.5471 - golden_loss: 1.7045\n",
      "Epoch 996/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.2501 - reconstruction_loss: 15.5563 - golden_loss: 1.6938\n",
      "Epoch 997/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.2493 - reconstruction_loss: 15.5457 - golden_loss: 1.7036\n",
      "Epoch 998/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.2495 - reconstruction_loss: 15.5634 - golden_loss: 1.6861\n",
      "Epoch 999/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2517 - reconstruction_loss: 15.5499 - golden_loss: 1.7018\n",
      "Epoch 1000/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.2576 - reconstruction_loss: 15.5788 - golden_loss: 1.6788\n",
      "Epoch 1001/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.2702 - reconstruction_loss: 15.5697 - golden_loss: 1.7005\n",
      "Epoch 1002/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2948 - reconstruction_loss: 15.6249 - golden_loss: 1.6698\n",
      "Epoch 1003/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.3372 - reconstruction_loss: 15.6342 - golden_loss: 1.7030\n",
      "Epoch 1004/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.4032 - reconstruction_loss: 15.7476 - golden_loss: 1.6555\n",
      "Epoch 1005/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.4765 - reconstruction_loss: 15.7630 - golden_loss: 1.7135\n",
      "Epoch 1006/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.5216 - reconstruction_loss: 15.8893 - golden_loss: 1.6323\n",
      "Epoch 1007/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.4794 - reconstruction_loss: 15.7470 - golden_loss: 1.7325\n",
      "Epoch 1008/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.3803 - reconstruction_loss: 15.7743 - golden_loss: 1.6060\n",
      "Epoch 1009/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.3069 - reconstruction_loss: 15.5650 - golden_loss: 1.7420\n",
      "Epoch 1010/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3052 - reconstruction_loss: 15.7002 - golden_loss: 1.6050\n",
      "Epoch 1011/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3245 - reconstruction_loss: 15.6116 - golden_loss: 1.7129\n",
      "Epoch 1012/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3017 - reconstruction_loss: 15.6552 - golden_loss: 1.6466\n",
      "Epoch 1013/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.2531 - reconstruction_loss: 15.6042 - golden_loss: 1.6488\n",
      "Epoch 1014/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2411 - reconstruction_loss: 15.5379 - golden_loss: 1.7032\n",
      "Epoch 1015/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.2804 - reconstruction_loss: 15.6828 - golden_loss: 1.5976\n",
      "Epoch 1016/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.3114 - reconstruction_loss: 15.5880 - golden_loss: 1.7234\n",
      "Epoch 1017/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.2821 - reconstruction_loss: 15.6818 - golden_loss: 1.6003\n",
      "Epoch 1018/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2236 - reconstruction_loss: 15.5400 - golden_loss: 1.6836\n",
      "Epoch 1019/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1998 - reconstruction_loss: 15.5510 - golden_loss: 1.6488\n",
      "Epoch 1020/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.2232 - reconstruction_loss: 15.5989 - golden_loss: 1.6243\n",
      "Epoch 1021/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.2486 - reconstruction_loss: 15.5606 - golden_loss: 1.6880\n",
      "Epoch 1022/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2410 - reconstruction_loss: 15.6413 - golden_loss: 1.5996\n",
      "Epoch 1023/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2162 - reconstruction_loss: 15.5350 - golden_loss: 1.6812\n",
      "Epoch 1024/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2052 - reconstruction_loss: 15.5882 - golden_loss: 1.6169\n",
      "Epoch 1025/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.2103 - reconstruction_loss: 15.5643 - golden_loss: 1.6460\n",
      "Epoch 1026/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.2108 - reconstruction_loss: 15.5672 - golden_loss: 1.6436\n",
      "Epoch 1027/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.1979 - reconstruction_loss: 15.5786 - golden_loss: 1.6193\n",
      "Epoch 1028/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1869 - reconstruction_loss: 15.5351 - golden_loss: 1.6517\n",
      "Epoch 1029/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1905 - reconstruction_loss: 15.5779 - golden_loss: 1.6126\n",
      "Epoch 1030/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2002 - reconstruction_loss: 15.5555 - golden_loss: 1.6447\n",
      "Epoch 1031/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1996 - reconstruction_loss: 15.5857 - golden_loss: 1.6139\n",
      "Epoch 1032/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.1861 - reconstruction_loss: 15.5503 - golden_loss: 1.6358\n",
      "Epoch 1033/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1730 - reconstruction_loss: 15.5588 - golden_loss: 1.6143\n",
      "Epoch 1034/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1707 - reconstruction_loss: 15.5436 - golden_loss: 1.6271\n",
      "Epoch 1035/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1750 - reconstruction_loss: 15.5582 - golden_loss: 1.6169\n",
      "Epoch 1036/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1762 - reconstruction_loss: 15.5621 - golden_loss: 1.6141\n",
      "Epoch 1037/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.1713 - reconstruction_loss: 15.5471 - golden_loss: 1.6242\n",
      "Epoch 1038/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1659 - reconstruction_loss: 15.5673 - golden_loss: 1.5986\n",
      "Epoch 1039/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1647 - reconstruction_loss: 15.5349 - golden_loss: 1.6298\n",
      "Epoch 1040/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1658 - reconstruction_loss: 15.5762 - golden_loss: 1.5895\n",
      "Epoch 1041/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1641 - reconstruction_loss: 15.5385 - golden_loss: 1.6256\n",
      "Epoch 1042/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1583 - reconstruction_loss: 15.5668 - golden_loss: 1.5915\n",
      "Epoch 1043/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1521 - reconstruction_loss: 15.5406 - golden_loss: 1.6114\n",
      "Epoch 1044/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.1489 - reconstruction_loss: 15.5490 - golden_loss: 1.5999\n",
      "Epoch 1045/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.1487 - reconstruction_loss: 15.5531 - golden_loss: 1.5956\n",
      "Epoch 1046/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1487 - reconstruction_loss: 15.5430 - golden_loss: 1.6056\n",
      "Epoch 1047/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.1467 - reconstruction_loss: 15.5613 - golden_loss: 1.5854\n",
      "Epoch 1048/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1435 - reconstruction_loss: 15.5387 - golden_loss: 1.6048\n",
      "Epoch 1049/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1409 - reconstruction_loss: 15.5597 - golden_loss: 1.5811\n",
      "Epoch 1050/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.1398 - reconstruction_loss: 15.5399 - golden_loss: 1.6000\n",
      "Epoch 1051/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.1394 - reconstruction_loss: 15.5610 - golden_loss: 1.5784\n",
      "Epoch 1052/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1383 - reconstruction_loss: 15.5425 - golden_loss: 1.5958\n",
      "Epoch 1053/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1360 - reconstruction_loss: 15.5623 - golden_loss: 1.5737\n",
      "Epoch 1054/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.1331 - reconstruction_loss: 15.5390 - golden_loss: 1.5941\n",
      "Epoch 1055/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.1308 - reconstruction_loss: 15.5640 - golden_loss: 1.5668\n",
      "Epoch 1056/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1294 - reconstruction_loss: 15.5357 - golden_loss: 1.5937\n",
      "Epoch 1057/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1286 - reconstruction_loss: 15.5688 - golden_loss: 1.5598\n",
      "Epoch 1058/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1276 - reconstruction_loss: 15.5348 - golden_loss: 1.5928\n",
      "Epoch 1059/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.1264 - reconstruction_loss: 15.5730 - golden_loss: 1.5535\n",
      "Epoch 1060/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1254 - reconstruction_loss: 15.5339 - golden_loss: 1.5915\n",
      "Epoch 1061/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1251 - reconstruction_loss: 15.5782 - golden_loss: 1.5469\n",
      "Epoch 1062/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1262 - reconstruction_loss: 15.5345 - golden_loss: 1.5917\n",
      "Epoch 1063/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1291 - reconstruction_loss: 15.5917 - golden_loss: 1.5374\n",
      "Epoch 1064/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.1344 - reconstruction_loss: 15.5382 - golden_loss: 1.5962\n",
      "Epoch 1065/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.1428 - reconstruction_loss: 15.6202 - golden_loss: 1.5226\n",
      "Epoch 1066/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1557 - reconstruction_loss: 15.5484 - golden_loss: 1.6073\n",
      "Epoch 1067/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1750 - reconstruction_loss: 15.6741 - golden_loss: 1.5010\n",
      "Epoch 1068/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.2014 - reconstruction_loss: 15.5763 - golden_loss: 1.6252\n",
      "Epoch 1069/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.2337 - reconstruction_loss: 15.7584 - golden_loss: 1.4753\n",
      "Epoch 1070/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.2639 - reconstruction_loss: 15.6215 - golden_loss: 1.6424\n",
      "Epoch 1071/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.2785 - reconstruction_loss: 15.8192 - golden_loss: 1.4593\n",
      "Epoch 1072/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.2611 - reconstruction_loss: 15.6239 - golden_loss: 1.6373\n",
      "Epoch 1073/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.2118 - reconstruction_loss: 15.7353 - golden_loss: 1.4765\n",
      "Epoch 1074/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1501 - reconstruction_loss: 15.5588 - golden_loss: 1.5913\n",
      "Epoch 1075/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1073 - reconstruction_loss: 15.5793 - golden_loss: 1.5280\n",
      "Epoch 1076/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0980 - reconstruction_loss: 15.5700 - golden_loss: 1.5280\n",
      "Epoch 1077/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.1138 - reconstruction_loss: 15.5368 - golden_loss: 1.5770\n",
      "Epoch 1078/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.1346 - reconstruction_loss: 15.6465 - golden_loss: 1.4881\n",
      "Epoch 1079/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.1440 - reconstruction_loss: 15.5535 - golden_loss: 1.5905\n",
      "Epoch 1080/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1375 - reconstruction_loss: 15.6492 - golden_loss: 1.4883\n",
      "Epoch 1081/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1217 - reconstruction_loss: 15.5564 - golden_loss: 1.5652\n",
      "Epoch 1082/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1074 - reconstruction_loss: 15.5898 - golden_loss: 1.5176\n",
      "Epoch 1083/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0992 - reconstruction_loss: 15.5741 - golden_loss: 1.5251\n",
      "Epoch 1084/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0952 - reconstruction_loss: 15.5488 - golden_loss: 1.5464\n",
      "Epoch 1085/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.0914 - reconstruction_loss: 15.5922 - golden_loss: 1.4992\n",
      "Epoch 1086/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0868 - reconstruction_loss: 15.5336 - golden_loss: 1.5532\n",
      "Epoch 1087/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0831 - reconstruction_loss: 15.5857 - golden_loss: 1.4974\n",
      "Epoch 1088/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0824 - reconstruction_loss: 15.5439 - golden_loss: 1.5385\n",
      "Epoch 1089/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0845 - reconstruction_loss: 15.5742 - golden_loss: 1.5103\n",
      "Epoch 1090/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.0862 - reconstruction_loss: 15.5687 - golden_loss: 1.5175\n",
      "Epoch 1091/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0841 - reconstruction_loss: 15.5622 - golden_loss: 1.5219\n",
      "Epoch 1092/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0770 - reconstruction_loss: 15.5731 - golden_loss: 1.5039\n",
      "Epoch 1093/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0673 - reconstruction_loss: 15.5445 - golden_loss: 1.5228\n",
      "Epoch 1094/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.0589 - reconstruction_loss: 15.5577 - golden_loss: 1.5013\n",
      "Epoch 1095/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0549 - reconstruction_loss: 15.5403 - golden_loss: 1.5146\n",
      "Epoch 1096/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0556 - reconstruction_loss: 15.5513 - golden_loss: 1.5043\n",
      "Epoch 1097/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0586 - reconstruction_loss: 15.5538 - golden_loss: 1.5048\n",
      "Epoch 1098/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0613 - reconstruction_loss: 15.5556 - golden_loss: 1.5057\n",
      "Epoch 1099/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.0613 - reconstruction_loss: 15.5623 - golden_loss: 1.4990\n",
      "Epoch 1100/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.0582 - reconstruction_loss: 15.5564 - golden_loss: 1.5019\n",
      "Epoch 1101/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0530 - reconstruction_loss: 15.5546 - golden_loss: 1.4983\n",
      "Epoch 1102/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.0473 - reconstruction_loss: 15.5533 - golden_loss: 1.4940\n",
      "Epoch 1103/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0427 - reconstruction_loss: 15.5425 - golden_loss: 1.5002\n",
      "Epoch 1104/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0399 - reconstruction_loss: 15.5544 - golden_loss: 1.4854\n",
      "Epoch 1105/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0385 - reconstruction_loss: 15.5376 - golden_loss: 1.5009\n",
      "Epoch 1106/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0379 - reconstruction_loss: 15.5585 - golden_loss: 1.4794\n",
      "Epoch 1107/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0372 - reconstruction_loss: 15.5389 - golden_loss: 1.4983\n",
      "Epoch 1108/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0359 - reconstruction_loss: 15.5589 - golden_loss: 1.4770\n",
      "Epoch 1109/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.0340 - reconstruction_loss: 15.5417 - golden_loss: 1.4922\n",
      "Epoch 1110/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0315 - reconstruction_loss: 15.5539 - golden_loss: 1.4776\n",
      "Epoch 1111/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0289 - reconstruction_loss: 15.5451 - golden_loss: 1.4838\n",
      "Epoch 1112/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0265 - reconstruction_loss: 15.5465 - golden_loss: 1.4799\n",
      "Epoch 1113/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0244 - reconstruction_loss: 15.5500 - golden_loss: 1.4744\n",
      "Epoch 1114/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.0229 - reconstruction_loss: 15.5403 - golden_loss: 1.4826\n",
      "Epoch 1115/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0219 - reconstruction_loss: 15.5568 - golden_loss: 1.4651\n",
      "Epoch 1116/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0214 - reconstruction_loss: 15.5363 - golden_loss: 1.4851\n",
      "Epoch 1117/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.0213 - reconstruction_loss: 15.5654 - golden_loss: 1.4560\n",
      "Epoch 1118/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.0219 - reconstruction_loss: 15.5342 - golden_loss: 1.4877\n",
      "Epoch 1119/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0233 - reconstruction_loss: 15.5770 - golden_loss: 1.4463\n",
      "Epoch 1120/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.0260 - reconstruction_loss: 15.5346 - golden_loss: 1.4914\n",
      "Epoch 1121/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.0307 - reconstruction_loss: 15.5958 - golden_loss: 1.4349\n",
      "Epoch 1122/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.0387 - reconstruction_loss: 15.5408 - golden_loss: 1.4979\n",
      "Epoch 1123/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.0518 - reconstruction_loss: 15.6316 - golden_loss: 1.4201\n",
      "Epoch 1124/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0722 - reconstruction_loss: 15.5635 - golden_loss: 1.5087\n",
      "Epoch 1125/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.1037 - reconstruction_loss: 15.7029 - golden_loss: 1.4008\n",
      "Epoch 1126/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.1479 - reconstruction_loss: 15.6237 - golden_loss: 1.5241\n",
      "Epoch 1127/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.2066 - reconstruction_loss: 15.8271 - golden_loss: 1.3796\n",
      "Epoch 1128/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.2683 - reconstruction_loss: 15.7314 - golden_loss: 1.5369\n",
      "Epoch 1129/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.3181 - reconstruction_loss: 15.9486 - golden_loss: 1.3696\n",
      "Epoch 1130/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.3166 - reconstruction_loss: 15.7899 - golden_loss: 1.5267\n",
      "Epoch 1131/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.2536 - reconstruction_loss: 15.8620 - golden_loss: 1.3917\n",
      "Epoch 1132/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.1382 - reconstruction_loss: 15.6588 - golden_loss: 1.4794\n",
      "Epoch 1133/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0367 - reconstruction_loss: 15.5939 - golden_loss: 1.4428\n",
      "Epoch 1134/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0032 - reconstruction_loss: 15.5826 - golden_loss: 1.4206\n",
      "Epoch 1135/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0419 - reconstruction_loss: 15.5557 - golden_loss: 1.4862\n",
      "Epoch 1136/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1048 - reconstruction_loss: 15.7158 - golden_loss: 1.3890\n",
      "Epoch 1137/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.1313 - reconstruction_loss: 15.6396 - golden_loss: 1.4917\n",
      "Epoch 1138/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.0988 - reconstruction_loss: 15.6997 - golden_loss: 1.3991\n",
      "Epoch 1139/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.0318 - reconstruction_loss: 15.5743 - golden_loss: 1.4575\n",
      "Epoch 1140/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9860 - reconstruction_loss: 15.5494 - golden_loss: 1.4366\n",
      "Epoch 1141/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9904 - reconstruction_loss: 15.5768 - golden_loss: 1.4136\n",
      "Epoch 1142/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.0270 - reconstruction_loss: 15.5606 - golden_loss: 1.4664\n",
      "Epoch 1143/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.0546 - reconstruction_loss: 15.6618 - golden_loss: 1.3928\n",
      "Epoch 1144/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0453 - reconstruction_loss: 15.5804 - golden_loss: 1.4649\n",
      "Epoch 1145/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0090 - reconstruction_loss: 15.6049 - golden_loss: 1.4040\n",
      "Epoch 1146/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.9766 - reconstruction_loss: 15.5405 - golden_loss: 1.4362\n",
      "Epoch 1147/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9714 - reconstruction_loss: 15.5403 - golden_loss: 1.4312\n",
      "Epoch 1148/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9890 - reconstruction_loss: 15.5836 - golden_loss: 1.4054\n",
      "Epoch 1149/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0068 - reconstruction_loss: 15.5582 - golden_loss: 1.4486\n",
      "Epoch 1150/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0073 - reconstruction_loss: 15.6141 - golden_loss: 1.3933\n",
      "Epoch 1151/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9902 - reconstruction_loss: 15.5468 - golden_loss: 1.4434\n",
      "Epoch 1152/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9703 - reconstruction_loss: 15.5681 - golden_loss: 1.4023\n",
      "Epoch 1153/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.9615 - reconstruction_loss: 15.5395 - golden_loss: 1.4220\n",
      "Epoch 1154/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9658 - reconstruction_loss: 15.5462 - golden_loss: 1.4197\n",
      "Epoch 1155/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9748 - reconstruction_loss: 15.5739 - golden_loss: 1.4009\n",
      "Epoch 1156/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9783 - reconstruction_loss: 15.5484 - golden_loss: 1.4299\n",
      "Epoch 1157/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9732 - reconstruction_loss: 15.5816 - golden_loss: 1.3916\n",
      "Epoch 1158/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9633 - reconstruction_loss: 15.5368 - golden_loss: 1.4265\n",
      "Epoch 1159/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9554 - reconstruction_loss: 15.5606 - golden_loss: 1.3949\n",
      "Epoch 1160/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9530 - reconstruction_loss: 15.5397 - golden_loss: 1.4133\n",
      "Epoch 1161/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9547 - reconstruction_loss: 15.5509 - golden_loss: 1.4038\n",
      "Epoch 1162/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.9566 - reconstruction_loss: 15.5577 - golden_loss: 1.3989\n",
      "Epoch 1163/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9558 - reconstruction_loss: 15.5454 - golden_loss: 1.4104\n",
      "Epoch 1164/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9520 - reconstruction_loss: 15.5625 - golden_loss: 1.3895\n",
      "Epoch 1165/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9473 - reconstruction_loss: 15.5367 - golden_loss: 1.4106\n",
      "Epoch 1166/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.9440 - reconstruction_loss: 15.5575 - golden_loss: 1.3865\n",
      "Epoch 1167/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16.9428 - reconstruction_loss: 15.5374 - golden_loss: 1.4053\n",
      "Epoch 1168/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9428 - reconstruction_loss: 15.5551 - golden_loss: 1.3877\n",
      "Epoch 1169/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.9425 - reconstruction_loss: 15.5450 - golden_loss: 1.3975\n",
      "Epoch 1170/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.9410 - reconstruction_loss: 15.5512 - golden_loss: 1.3898\n",
      "Epoch 1171/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.9381 - reconstruction_loss: 15.5481 - golden_loss: 1.3900\n",
      "Epoch 1172/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9346 - reconstruction_loss: 15.5438 - golden_loss: 1.3908\n",
      "Epoch 1173/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9317 - reconstruction_loss: 15.5477 - golden_loss: 1.3840\n",
      "Epoch 1174/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.9298 - reconstruction_loss: 15.5396 - golden_loss: 1.3901\n",
      "Epoch 1175/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9290 - reconstruction_loss: 15.5494 - golden_loss: 1.3795\n",
      "Epoch 1176/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9287 - reconstruction_loss: 15.5404 - golden_loss: 1.3883\n",
      "Epoch 1177/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9284 - reconstruction_loss: 15.5524 - golden_loss: 1.3760\n",
      "Epoch 1178/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9275 - reconstruction_loss: 15.5416 - golden_loss: 1.3860\n",
      "Epoch 1179/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.9260 - reconstruction_loss: 15.5534 - golden_loss: 1.3726\n",
      "Epoch 1180/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9240 - reconstruction_loss: 15.5404 - golden_loss: 1.3836\n",
      "Epoch 1181/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9217 - reconstruction_loss: 15.5525 - golden_loss: 1.3692\n",
      "Epoch 1182/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9196 - reconstruction_loss: 15.5383 - golden_loss: 1.3813\n",
      "Epoch 1183/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9177 - reconstruction_loss: 15.5521 - golden_loss: 1.3656\n",
      "Epoch 1184/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9162 - reconstruction_loss: 15.5370 - golden_loss: 1.3793\n",
      "Epoch 1185/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9151 - reconstruction_loss: 15.5532 - golden_loss: 1.3618\n",
      "Epoch 1186/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.9141 - reconstruction_loss: 15.5365 - golden_loss: 1.3776\n",
      "Epoch 1187/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.9132 - reconstruction_loss: 15.5556 - golden_loss: 1.3576\n",
      "Epoch 1188/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9125 - reconstruction_loss: 15.5361 - golden_loss: 1.3764\n",
      "Epoch 1189/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9117 - reconstruction_loss: 15.5590 - golden_loss: 1.3527\n",
      "Epoch 1190/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9112 - reconstruction_loss: 15.5349 - golden_loss: 1.3763\n",
      "Epoch 1191/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.9110 - reconstruction_loss: 15.5646 - golden_loss: 1.3464\n",
      "Epoch 1192/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9115 - reconstruction_loss: 15.5336 - golden_loss: 1.3780\n",
      "Epoch 1193/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.9132 - reconstruction_loss: 15.5755 - golden_loss: 1.3377\n",
      "Epoch 1194/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9168 - reconstruction_loss: 15.5339 - golden_loss: 1.3829\n",
      "Epoch 1195/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.9233 - reconstruction_loss: 15.5983 - golden_loss: 1.3251\n",
      "Epoch 1196/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.9348 - reconstruction_loss: 15.5417 - golden_loss: 1.3931\n",
      "Epoch 1197/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.9535 - reconstruction_loss: 15.6472 - golden_loss: 1.3063\n",
      "Epoch 1198/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9830 - reconstruction_loss: 15.5721 - golden_loss: 1.4108\n",
      "Epoch 1199/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0252 - reconstruction_loss: 15.7449 - golden_loss: 1.2803\n",
      "Epoch 1200/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0797 - reconstruction_loss: 15.6449 - golden_loss: 1.4348\n",
      "Epoch 1201/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1323 - reconstruction_loss: 15.8781 - golden_loss: 1.2542\n",
      "Epoch 1202/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.1594 - reconstruction_loss: 15.7115 - golden_loss: 1.4480\n",
      "Epoch 1203/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1278 - reconstruction_loss: 15.8734 - golden_loss: 1.2545\n",
      "Epoch 1204/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.0440 - reconstruction_loss: 15.6281 - golden_loss: 1.4159\n",
      "Epoch 1205/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9535 - reconstruction_loss: 15.6486 - golden_loss: 1.3049\n",
      "Epoch 1206/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9164 - reconstruction_loss: 15.5749 - golden_loss: 1.3415\n",
      "Epoch 1207/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9443 - reconstruction_loss: 15.5699 - golden_loss: 1.3744\n",
      "Epoch 1208/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9983 - reconstruction_loss: 15.7171 - golden_loss: 1.2812\n",
      "Epoch 1209/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0230 - reconstruction_loss: 15.6172 - golden_loss: 1.4058\n",
      "Epoch 1210/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.9934 - reconstruction_loss: 15.7169 - golden_loss: 1.2766\n",
      "Epoch 1211/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9314 - reconstruction_loss: 15.5573 - golden_loss: 1.3741\n",
      "Epoch 1212/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8880 - reconstruction_loss: 15.5640 - golden_loss: 1.3240\n",
      "Epoch 1213/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.8895 - reconstruction_loss: 15.5761 - golden_loss: 1.3134\n",
      "Epoch 1214/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9181 - reconstruction_loss: 15.5466 - golden_loss: 1.3715\n",
      "Epoch 1215/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9358 - reconstruction_loss: 15.6545 - golden_loss: 1.2814\n",
      "Epoch 1216/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.9228 - reconstruction_loss: 15.5496 - golden_loss: 1.3732\n",
      "Epoch 1217/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8917 - reconstruction_loss: 15.5927 - golden_loss: 1.2990\n",
      "Epoch 1218/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8713 - reconstruction_loss: 15.5386 - golden_loss: 1.3327\n",
      "Epoch 1219/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8760 - reconstruction_loss: 15.5366 - golden_loss: 1.3394\n",
      "Epoch 1220/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.8947 - reconstruction_loss: 15.6011 - golden_loss: 1.2936\n",
      "Epoch 1221/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9064 - reconstruction_loss: 15.5477 - golden_loss: 1.3587\n",
      "Epoch 1222/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9003 - reconstruction_loss: 15.6119 - golden_loss: 1.2884\n",
      "Epoch 1223/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8842 - reconstruction_loss: 15.5434 - golden_loss: 1.3409\n",
      "Epoch 1224/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8734 - reconstruction_loss: 15.5605 - golden_loss: 1.3129\n",
      "Epoch 1225/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8760 - reconstruction_loss: 15.5692 - golden_loss: 1.3068\n",
      "Epoch 1226/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8866 - reconstruction_loss: 15.5490 - golden_loss: 1.3377\n",
      "Epoch 1227/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8948 - reconstruction_loss: 15.6074 - golden_loss: 1.2874\n",
      "Epoch 1228/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8939 - reconstruction_loss: 15.5551 - golden_loss: 1.3389\n",
      "Epoch 1229/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8873 - reconstruction_loss: 15.5935 - golden_loss: 1.2938\n",
      "Epoch 1230/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8823 - reconstruction_loss: 15.5643 - golden_loss: 1.3180\n",
      "Epoch 1231/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8844 - reconstruction_loss: 15.5710 - golden_loss: 1.3134\n",
      "Epoch 1232/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8921 - reconstruction_loss: 15.5972 - golden_loss: 1.2948\n",
      "Epoch 1233/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9003 - reconstruction_loss: 15.5747 - golden_loss: 1.3256\n",
      "Epoch 1234/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9036 - reconstruction_loss: 15.6172 - golden_loss: 1.2864\n",
      "Epoch 1235/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.9016 - reconstruction_loss: 15.5817 - golden_loss: 1.3199\n",
      "Epoch 1236/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8960 - reconstruction_loss: 15.6014 - golden_loss: 1.2946\n",
      "Epoch 1237/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.8906 - reconstruction_loss: 15.5887 - golden_loss: 1.3019\n",
      "Epoch 1238/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8859 - reconstruction_loss: 15.5775 - golden_loss: 1.3084\n",
      "Epoch 1239/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8814 - reconstruction_loss: 15.5961 - golden_loss: 1.2853\n",
      "Epoch 1240/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8746 - reconstruction_loss: 15.5593 - golden_loss: 1.3153\n",
      "Epoch 1241/2000\n",
      "1/1 [==============================] - 0s 543us/step - loss: 16.8653 - reconstruction_loss: 15.5857 - golden_loss: 1.2796\n",
      "Epoch 1242/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8543 - reconstruction_loss: 15.5444 - golden_loss: 1.3099\n",
      "Epoch 1243/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8443 - reconstruction_loss: 15.5595 - golden_loss: 1.2848\n",
      "Epoch 1244/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8374 - reconstruction_loss: 15.5409 - golden_loss: 1.2964\n",
      "Epoch 1245/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8342 - reconstruction_loss: 15.5401 - golden_loss: 1.2941\n",
      "Epoch 1246/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.8341 - reconstruction_loss: 15.5508 - golden_loss: 1.2833\n",
      "Epoch 1247/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8354 - reconstruction_loss: 15.5357 - golden_loss: 1.2997\n",
      "Epoch 1248/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8369 - reconstruction_loss: 15.5607 - golden_loss: 1.2762\n",
      "Epoch 1249/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8379 - reconstruction_loss: 15.5396 - golden_loss: 1.2983\n",
      "Epoch 1250/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.8384 - reconstruction_loss: 15.5625 - golden_loss: 1.2759\n",
      "Epoch 1251/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8390 - reconstruction_loss: 15.5479 - golden_loss: 1.2912\n",
      "Epoch 1252/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.8403 - reconstruction_loss: 15.5609 - golden_loss: 1.2794\n",
      "Epoch 1253/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.8423 - reconstruction_loss: 15.5600 - golden_loss: 1.2824\n",
      "Epoch 1254/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.8452 - reconstruction_loss: 15.5624 - golden_loss: 1.2827\n",
      "Epoch 1255/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.8483 - reconstruction_loss: 15.5729 - golden_loss: 1.2754\n",
      "Epoch 1256/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8516 - reconstruction_loss: 15.5685 - golden_loss: 1.2831\n",
      "Epoch 1257/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8545 - reconstruction_loss: 15.5824 - golden_loss: 1.2721\n",
      "Epoch 1258/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8570 - reconstruction_loss: 15.5774 - golden_loss: 1.2797\n",
      "Epoch 1259/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8587 - reconstruction_loss: 15.5864 - golden_loss: 1.2722\n",
      "Epoch 1260/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8596 - reconstruction_loss: 15.5862 - golden_loss: 1.2734\n",
      "Epoch 1261/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8591 - reconstruction_loss: 15.5845 - golden_loss: 1.2746\n",
      "Epoch 1262/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.8575 - reconstruction_loss: 15.5918 - golden_loss: 1.2657\n",
      "Epoch 1263/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.8542 - reconstruction_loss: 15.5765 - golden_loss: 1.2776\n",
      "Epoch 1264/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8496 - reconstruction_loss: 15.5915 - golden_loss: 1.2581\n",
      "Epoch 1265/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.8437 - reconstruction_loss: 15.5637 - golden_loss: 1.2799\n",
      "Epoch 1266/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.8373 - reconstruction_loss: 15.5856 - golden_loss: 1.2517\n",
      "Epoch 1267/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8307 - reconstruction_loss: 15.5501 - golden_loss: 1.2806\n",
      "Epoch 1268/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8245 - reconstruction_loss: 15.5773 - golden_loss: 1.2473\n",
      "Epoch 1269/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.8190 - reconstruction_loss: 15.5398 - golden_loss: 1.2792\n",
      "Epoch 1270/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8144 - reconstruction_loss: 15.5695 - golden_loss: 1.2449\n",
      "Epoch 1271/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8105 - reconstruction_loss: 15.5346 - golden_loss: 1.2760\n",
      "Epoch 1272/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8074 - reconstruction_loss: 15.5632 - golden_loss: 1.2441\n",
      "Epoch 1273/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8047 - reconstruction_loss: 15.5334 - golden_loss: 1.2713\n",
      "Epoch 1274/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8025 - reconstruction_loss: 15.5580 - golden_loss: 1.2445\n",
      "Epoch 1275/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.8006 - reconstruction_loss: 15.5346 - golden_loss: 1.2660\n",
      "Epoch 1276/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7989 - reconstruction_loss: 15.5537 - golden_loss: 1.2452\n",
      "Epoch 1277/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.7974 - reconstruction_loss: 15.5369 - golden_loss: 1.2605\n",
      "Epoch 1278/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7961 - reconstruction_loss: 15.5503 - golden_loss: 1.2458\n",
      "Epoch 1279/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7951 - reconstruction_loss: 15.5398 - golden_loss: 1.2552\n",
      "Epoch 1280/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7942 - reconstruction_loss: 15.5480 - golden_loss: 1.2463\n",
      "Epoch 1281/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7937 - reconstruction_loss: 15.5435 - golden_loss: 1.2502\n",
      "Epoch 1282/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.7935 - reconstruction_loss: 15.5469 - golden_loss: 1.2465\n",
      "Epoch 1283/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7938 - reconstruction_loss: 15.5486 - golden_loss: 1.2452\n",
      "Epoch 1284/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7950 - reconstruction_loss: 15.5480 - golden_loss: 1.2470\n",
      "Epoch 1285/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7974 - reconstruction_loss: 15.5577 - golden_loss: 1.2398\n",
      "Epoch 1286/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8017 - reconstruction_loss: 15.5534 - golden_loss: 1.2483\n",
      "Epoch 1287/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8089 - reconstruction_loss: 15.5758 - golden_loss: 1.2331\n",
      "Epoch 1288/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8205 - reconstruction_loss: 15.5691 - golden_loss: 1.2514\n",
      "Epoch 1289/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.8391 - reconstruction_loss: 15.6153 - golden_loss: 1.2238\n",
      "Epoch 1290/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8671 - reconstruction_loss: 15.6087 - golden_loss: 1.2584\n",
      "Epoch 1291/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9089 - reconstruction_loss: 15.6991 - golden_loss: 1.2098\n",
      "Epoch 1292/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.9644 - reconstruction_loss: 15.6924 - golden_loss: 1.2720\n",
      "Epoch 1293/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0345 - reconstruction_loss: 15.8463 - golden_loss: 1.1882\n",
      "Epoch 1294/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1019 - reconstruction_loss: 15.8073 - golden_loss: 1.2945\n",
      "Epoch 1295/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.1547 - reconstruction_loss: 15.9952 - golden_loss: 1.1595\n",
      "Epoch 1296/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.1605 - reconstruction_loss: 15.8406 - golden_loss: 1.3198\n",
      "Epoch 1297/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.1205 - reconstruction_loss: 15.9822 - golden_loss: 1.1384\n",
      "Epoch 1298/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0350 - reconstruction_loss: 15.7139 - golden_loss: 1.3211\n",
      "Epoch 1299/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9376 - reconstruction_loss: 15.7815 - golden_loss: 1.1562\n",
      "Epoch 1300/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8715 - reconstruction_loss: 15.5988 - golden_loss: 1.2727\n",
      "Epoch 1301/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8620 - reconstruction_loss: 15.6459 - golden_loss: 1.2161\n",
      "Epoch 1302/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8929 - reconstruction_loss: 15.6892 - golden_loss: 1.2037\n",
      "Epoch 1303/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16.9153 - reconstruction_loss: 15.6440 - golden_loss: 1.2713\n",
      "Epoch 1304/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9023 - reconstruction_loss: 15.7360 - golden_loss: 1.1663\n",
      "Epoch 1305/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8598 - reconstruction_loss: 15.5816 - golden_loss: 1.2782\n",
      "Epoch 1306/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8214 - reconstruction_loss: 15.6390 - golden_loss: 1.1824\n",
      "Epoch 1307/2000\n",
      "1/1 [==============================] - 0s 406us/step - loss: 16.8125 - reconstruction_loss: 15.5757 - golden_loss: 1.2368\n",
      "Epoch 1308/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8280 - reconstruction_loss: 15.5997 - golden_loss: 1.2283\n",
      "Epoch 1309/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8415 - reconstruction_loss: 15.6510 - golden_loss: 1.1905\n",
      "Epoch 1310/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8322 - reconstruction_loss: 15.5755 - golden_loss: 1.2567\n",
      "Epoch 1311/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8069 - reconstruction_loss: 15.6285 - golden_loss: 1.1784\n",
      "Epoch 1312/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7862 - reconstruction_loss: 15.5418 - golden_loss: 1.2444\n",
      "Epoch 1313/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7836 - reconstruction_loss: 15.5817 - golden_loss: 1.2020\n",
      "Epoch 1314/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7941 - reconstruction_loss: 15.5848 - golden_loss: 1.2093\n",
      "Epoch 1315/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8004 - reconstruction_loss: 15.5693 - golden_loss: 1.2311\n",
      "Epoch 1316/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7933 - reconstruction_loss: 15.6078 - golden_loss: 1.1855\n",
      "Epoch 1317/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7773 - reconstruction_loss: 15.5398 - golden_loss: 1.2376\n",
      "Epoch 1318/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7656 - reconstruction_loss: 15.5768 - golden_loss: 1.1887\n",
      "Epoch 1319/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7648 - reconstruction_loss: 15.5454 - golden_loss: 1.2194\n",
      "Epoch 1320/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.7709 - reconstruction_loss: 15.5627 - golden_loss: 1.2082\n",
      "Epoch 1321/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7744 - reconstruction_loss: 15.5783 - golden_loss: 1.1961\n",
      "Epoch 1322/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7698 - reconstruction_loss: 15.5475 - golden_loss: 1.2223\n",
      "Epoch 1323/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7602 - reconstruction_loss: 15.5742 - golden_loss: 1.1860\n",
      "Epoch 1324/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7525 - reconstruction_loss: 15.5330 - golden_loss: 1.2195\n",
      "Epoch 1325/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7510 - reconstruction_loss: 15.5590 - golden_loss: 1.1920\n",
      "Epoch 1326/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7539 - reconstruction_loss: 15.5490 - golden_loss: 1.2048\n",
      "Epoch 1327/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7562 - reconstruction_loss: 15.5525 - golden_loss: 1.2038\n",
      "Epoch 1328/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7545 - reconstruction_loss: 15.5638 - golden_loss: 1.1907\n",
      "Epoch 1329/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7491 - reconstruction_loss: 15.5392 - golden_loss: 1.2098\n",
      "Epoch 1330/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7434 - reconstruction_loss: 15.5579 - golden_loss: 1.1855\n",
      "Epoch 1331/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7405 - reconstruction_loss: 15.5343 - golden_loss: 1.2062\n",
      "Epoch 1332/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7408 - reconstruction_loss: 15.5521 - golden_loss: 1.1887\n",
      "Epoch 1333/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7423 - reconstruction_loss: 15.5457 - golden_loss: 1.1966\n",
      "Epoch 1334/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7425 - reconstruction_loss: 15.5479 - golden_loss: 1.1946\n",
      "Epoch 1335/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7404 - reconstruction_loss: 15.5529 - golden_loss: 1.1875\n",
      "Epoch 1336/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7367 - reconstruction_loss: 15.5391 - golden_loss: 1.1976\n",
      "Epoch 1337/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7331 - reconstruction_loss: 15.5502 - golden_loss: 1.1829\n",
      "Epoch 1338/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7311 - reconstruction_loss: 15.5354 - golden_loss: 1.1956\n",
      "Epoch 1339/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.7308 - reconstruction_loss: 15.5481 - golden_loss: 1.1827\n",
      "Epoch 1340/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7312 - reconstruction_loss: 15.5409 - golden_loss: 1.1904\n",
      "Epoch 1341/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7313 - reconstruction_loss: 15.5468 - golden_loss: 1.1845\n",
      "Epoch 1342/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.7302 - reconstruction_loss: 15.5457 - golden_loss: 1.1845\n",
      "Epoch 1343/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7280 - reconstruction_loss: 15.5423 - golden_loss: 1.1857\n",
      "Epoch 1344/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7254 - reconstruction_loss: 15.5455 - golden_loss: 1.1799\n",
      "Epoch 1345/2000\n",
      "1/1 [==============================] - 0s 111us/step - loss: 16.7231 - reconstruction_loss: 15.5379 - golden_loss: 1.1852\n",
      "Epoch 1346/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7217 - reconstruction_loss: 15.5444 - golden_loss: 1.1772\n",
      "Epoch 1347/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7210 - reconstruction_loss: 15.5380 - golden_loss: 1.1830\n",
      "Epoch 1348/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.7207 - reconstruction_loss: 15.5448 - golden_loss: 1.1759\n",
      "Epoch 1349/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7205 - reconstruction_loss: 15.5406 - golden_loss: 1.1799\n",
      "Epoch 1350/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7198 - reconstruction_loss: 15.5447 - golden_loss: 1.1751\n",
      "Epoch 1351/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7186 - reconstruction_loss: 15.5420 - golden_loss: 1.1767\n",
      "Epoch 1352/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7170 - reconstruction_loss: 15.5430 - golden_loss: 1.1740\n",
      "Epoch 1353/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.7153 - reconstruction_loss: 15.5415 - golden_loss: 1.1738\n",
      "Epoch 1354/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7136 - reconstruction_loss: 15.5410 - golden_loss: 1.1726\n",
      "Epoch 1355/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7121 - reconstruction_loss: 15.5408 - golden_loss: 1.1713\n",
      "Epoch 1356/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7109 - reconstruction_loss: 15.5400 - golden_loss: 1.1709\n",
      "Epoch 1357/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7100 - reconstruction_loss: 15.5409 - golden_loss: 1.1690\n",
      "Epoch 1358/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7092 - reconstruction_loss: 15.5401 - golden_loss: 1.1691\n",
      "Epoch 1359/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7085 - reconstruction_loss: 15.5417 - golden_loss: 1.1668\n",
      "Epoch 1360/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7078 - reconstruction_loss: 15.5405 - golden_loss: 1.1673\n",
      "Epoch 1361/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7070 - reconstruction_loss: 15.5426 - golden_loss: 1.1644\n",
      "Epoch 1362/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7061 - reconstruction_loss: 15.5403 - golden_loss: 1.1657\n",
      "Epoch 1363/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7051 - reconstruction_loss: 15.5433 - golden_loss: 1.1618\n",
      "Epoch 1364/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7040 - reconstruction_loss: 15.5397 - golden_loss: 1.1643\n",
      "Epoch 1365/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7030 - reconstruction_loss: 15.5439 - golden_loss: 1.1590\n",
      "Epoch 1366/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7019 - reconstruction_loss: 15.5387 - golden_loss: 1.1632\n",
      "Epoch 1367/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7009 - reconstruction_loss: 15.5449 - golden_loss: 1.1560\n",
      "Epoch 1368/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6999 - reconstruction_loss: 15.5375 - golden_loss: 1.1624\n",
      "Epoch 1369/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6991 - reconstruction_loss: 15.5465 - golden_loss: 1.1526\n",
      "Epoch 1370/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6983 - reconstruction_loss: 15.5362 - golden_loss: 1.1622\n",
      "Epoch 1371/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6978 - reconstruction_loss: 15.5494 - golden_loss: 1.1484\n",
      "Epoch 1372/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6977 - reconstruction_loss: 15.5348 - golden_loss: 1.1628\n",
      "Epoch 1373/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6980 - reconstruction_loss: 15.5549 - golden_loss: 1.1431\n",
      "Epoch 1374/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.6990 - reconstruction_loss: 15.5339 - golden_loss: 1.1651\n",
      "Epoch 1375/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7014 - reconstruction_loss: 15.5657 - golden_loss: 1.1357\n",
      "Epoch 1376/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.7058 - reconstruction_loss: 15.5356 - golden_loss: 1.1702\n",
      "Epoch 1377/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7136 - reconstruction_loss: 15.5889 - golden_loss: 1.1247\n",
      "Epoch 1378/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7271 - reconstruction_loss: 15.5470 - golden_loss: 1.1801\n",
      "Epoch 1379/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.7495 - reconstruction_loss: 15.6417 - golden_loss: 1.1078\n",
      "Epoch 1380/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7863 - reconstruction_loss: 15.5886 - golden_loss: 1.1976\n",
      "Epoch 1381/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8422 - reconstruction_loss: 15.7591 - golden_loss: 1.0831\n",
      "Epoch 1382/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9217 - reconstruction_loss: 15.6982 - golden_loss: 1.2234\n",
      "Epoch 1383/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.0124 - reconstruction_loss: 15.9577 - golden_loss: 1.0547\n",
      "Epoch 1384/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.0872 - reconstruction_loss: 15.8430 - golden_loss: 1.2442\n",
      "Epoch 1385/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 17.0853 - reconstruction_loss: 16.0378 - golden_loss: 1.0475\n",
      "Epoch 1386/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.9911 - reconstruction_loss: 15.7695 - golden_loss: 1.2215\n",
      "Epoch 1387/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8486 - reconstruction_loss: 15.7542 - golden_loss: 1.0944\n",
      "Epoch 1388/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7661 - reconstruction_loss: 15.6208 - golden_loss: 1.1453\n",
      "Epoch 1389/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7879 - reconstruction_loss: 15.6160 - golden_loss: 1.1719\n",
      "Epoch 1390/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.8664 - reconstruction_loss: 15.7897 - golden_loss: 1.0768\n",
      "Epoch 1391/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9042 - reconstruction_loss: 15.6928 - golden_loss: 1.2114\n",
      "Epoch 1392/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8485 - reconstruction_loss: 15.7769 - golden_loss: 1.0717\n",
      "Epoch 1393/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7401 - reconstruction_loss: 15.5651 - golden_loss: 1.1751\n",
      "Epoch 1394/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6772 - reconstruction_loss: 15.5480 - golden_loss: 1.1292\n",
      "Epoch 1395/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7007 - reconstruction_loss: 15.5946 - golden_loss: 1.1061\n",
      "Epoch 1396/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7596 - reconstruction_loss: 15.5779 - golden_loss: 1.1816\n",
      "Epoch 1397/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7797 - reconstruction_loss: 15.7003 - golden_loss: 1.0794\n",
      "Epoch 1398/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.7435 - reconstruction_loss: 15.5717 - golden_loss: 1.1718\n",
      "Epoch 1399/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6999 - reconstruction_loss: 15.5866 - golden_loss: 1.1133\n",
      "Epoch 1400/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6970 - reconstruction_loss: 15.5775 - golden_loss: 1.1195\n",
      "Epoch 1401/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7275 - reconstruction_loss: 15.5688 - golden_loss: 1.1587\n",
      "Epoch 1402/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7452 - reconstruction_loss: 15.6561 - golden_loss: 1.0892\n",
      "Epoch 1403/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7256 - reconstruction_loss: 15.5650 - golden_loss: 1.1606\n",
      "Epoch 1404/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6879 - reconstruction_loss: 15.5803 - golden_loss: 1.1076\n",
      "Epoch 1405/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6690 - reconstruction_loss: 15.5462 - golden_loss: 1.1229\n",
      "Epoch 1406/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6786 - reconstruction_loss: 15.5351 - golden_loss: 1.1435\n",
      "Epoch 1407/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.6947 - reconstruction_loss: 15.6008 - golden_loss: 1.0938\n",
      "Epoch 1408/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6941 - reconstruction_loss: 15.5426 - golden_loss: 1.1515\n",
      "Epoch 1409/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.6777 - reconstruction_loss: 15.5762 - golden_loss: 1.1015\n",
      "Epoch 1410/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.6648 - reconstruction_loss: 15.5392 - golden_loss: 1.1255\n",
      "Epoch 1411/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6676 - reconstruction_loss: 15.5384 - golden_loss: 1.1292\n",
      "Epoch 1412/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6797 - reconstruction_loss: 15.5815 - golden_loss: 1.0982\n",
      "Epoch 1413/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6860 - reconstruction_loss: 15.5440 - golden_loss: 1.1420\n",
      "Epoch 1414/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6803 - reconstruction_loss: 15.5840 - golden_loss: 1.0962\n",
      "Epoch 1415/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6694 - reconstruction_loss: 15.5418 - golden_loss: 1.1276\n",
      "Epoch 1416/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6642 - reconstruction_loss: 15.5497 - golden_loss: 1.1145\n",
      "Epoch 1417/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6671 - reconstruction_loss: 15.5625 - golden_loss: 1.1046\n",
      "Epoch 1418/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6719 - reconstruction_loss: 15.5431 - golden_loss: 1.1288\n",
      "Epoch 1419/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6716 - reconstruction_loss: 15.5758 - golden_loss: 1.0958\n",
      "Epoch 1420/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6656 - reconstruction_loss: 15.5416 - golden_loss: 1.1240\n",
      "Epoch 1421/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6589 - reconstruction_loss: 15.5539 - golden_loss: 1.1050\n",
      "Epoch 1422/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6562 - reconstruction_loss: 15.5493 - golden_loss: 1.1069\n",
      "Epoch 1423/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6578 - reconstruction_loss: 15.5397 - golden_loss: 1.1181\n",
      "Epoch 1424/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6600 - reconstruction_loss: 15.5657 - golden_loss: 1.0944\n",
      "Epoch 1425/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6596 - reconstruction_loss: 15.5389 - golden_loss: 1.1207\n",
      "Epoch 1426/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.6566 - reconstruction_loss: 15.5616 - golden_loss: 1.0950\n",
      "Epoch 1427/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6533 - reconstruction_loss: 15.5423 - golden_loss: 1.1110\n",
      "Epoch 1428/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6525 - reconstruction_loss: 15.5486 - golden_loss: 1.1038\n",
      "Epoch 1429/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6543 - reconstruction_loss: 15.5558 - golden_loss: 1.0986\n",
      "Epoch 1430/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6575 - reconstruction_loss: 15.5474 - golden_loss: 1.1102\n",
      "Epoch 1431/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6605 - reconstruction_loss: 15.5676 - golden_loss: 1.0929\n",
      "Epoch 1432/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6632 - reconstruction_loss: 15.5555 - golden_loss: 1.1077\n",
      "Epoch 1433/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6670 - reconstruction_loss: 15.5712 - golden_loss: 1.0958\n",
      "Epoch 1434/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6739 - reconstruction_loss: 15.5754 - golden_loss: 1.0985\n",
      "Epoch 1435/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6850 - reconstruction_loss: 15.5825 - golden_loss: 1.1025\n",
      "Epoch 1436/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7014 - reconstruction_loss: 15.6123 - golden_loss: 1.0890\n",
      "Epoch 1437/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7219 - reconstruction_loss: 15.6152 - golden_loss: 1.1067\n",
      "Epoch 1438/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.7465 - reconstruction_loss: 15.6625 - golden_loss: 1.0840\n",
      "Epoch 1439/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.7711 - reconstruction_loss: 15.6654 - golden_loss: 1.1057\n",
      "Epoch 1440/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7926 - reconstruction_loss: 15.7087 - golden_loss: 1.0839\n",
      "Epoch 1441/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7999 - reconstruction_loss: 15.6986 - golden_loss: 1.1013\n",
      "Epoch 1442/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.7880 - reconstruction_loss: 15.7027 - golden_loss: 1.0854\n",
      "Epoch 1443/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7516 - reconstruction_loss: 15.6548 - golden_loss: 1.0967\n",
      "Epoch 1444/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7024 - reconstruction_loss: 15.6168 - golden_loss: 1.0856\n",
      "Epoch 1445/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6567 - reconstruction_loss: 15.5631 - golden_loss: 1.0936\n",
      "Epoch 1446/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6312 - reconstruction_loss: 15.5463 - golden_loss: 1.0849\n",
      "Epoch 1447/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6303 - reconstruction_loss: 15.5398 - golden_loss: 1.0905\n",
      "Epoch 1448/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6471 - reconstruction_loss: 15.5615 - golden_loss: 1.0856\n",
      "Epoch 1449/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.6688 - reconstruction_loss: 15.5834 - golden_loss: 1.0854\n",
      "Epoch 1450/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6832 - reconstruction_loss: 15.5945 - golden_loss: 1.0887\n",
      "Epoch 1451/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6842 - reconstruction_loss: 15.6058 - golden_loss: 1.0784\n",
      "Epoch 1452/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6716 - reconstruction_loss: 15.5792 - golden_loss: 1.0924\n",
      "Epoch 1453/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6528 - reconstruction_loss: 15.5807 - golden_loss: 1.0721\n",
      "Epoch 1454/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6357 - reconstruction_loss: 15.5419 - golden_loss: 1.0938\n",
      "Epoch 1455/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6262 - reconstruction_loss: 15.5566 - golden_loss: 1.0696\n",
      "Epoch 1456/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6251 - reconstruction_loss: 15.5349 - golden_loss: 1.0902\n",
      "Epoch 1457/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6292 - reconstruction_loss: 15.5568 - golden_loss: 1.0724\n",
      "Epoch 1458/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6344 - reconstruction_loss: 15.5524 - golden_loss: 1.0820\n",
      "Epoch 1459/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6375 - reconstruction_loss: 15.5587 - golden_loss: 1.0788\n",
      "Epoch 1460/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6374 - reconstruction_loss: 15.5657 - golden_loss: 1.0717\n",
      "Epoch 1461/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6345 - reconstruction_loss: 15.5491 - golden_loss: 1.0854\n",
      "Epoch 1462/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6304 - reconstruction_loss: 15.5674 - golden_loss: 1.0630\n",
      "Epoch 1463/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6264 - reconstruction_loss: 15.5374 - golden_loss: 1.0890\n",
      "Epoch 1464/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6232 - reconstruction_loss: 15.5647 - golden_loss: 1.0585\n",
      "Epoch 1465/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6208 - reconstruction_loss: 15.5332 - golden_loss: 1.0876\n",
      "Epoch 1466/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6187 - reconstruction_loss: 15.5597 - golden_loss: 1.0590\n",
      "Epoch 1467/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6166 - reconstruction_loss: 15.5350 - golden_loss: 1.0816\n",
      "Epoch 1468/2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.6146 - reconstruction_loss: 15.5513 - golden_loss: 1.0633\n",
      "Epoch 1469/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6128 - reconstruction_loss: 15.5399 - golden_loss: 1.0728\n",
      "Epoch 1470/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6114 - reconstruction_loss: 15.5422 - golden_loss: 1.0692\n",
      "Epoch 1471/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6107 - reconstruction_loss: 15.5470 - golden_loss: 1.0637\n",
      "Epoch 1472/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6107 - reconstruction_loss: 15.5362 - golden_loss: 1.0745\n",
      "Epoch 1473/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6111 - reconstruction_loss: 15.5551 - golden_loss: 1.0560\n",
      "Epoch 1474/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6117 - reconstruction_loss: 15.5340 - golden_loss: 1.0778\n",
      "Epoch 1475/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6122 - reconstruction_loss: 15.5617 - golden_loss: 1.0506\n",
      "Epoch 1476/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6124 - reconstruction_loss: 15.5336 - golden_loss: 1.0787\n",
      "Epoch 1477/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6120 - reconstruction_loss: 15.5646 - golden_loss: 1.0474\n",
      "Epoch 1478/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.6112 - reconstruction_loss: 15.5336 - golden_loss: 1.0776\n",
      "Epoch 1479/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6101 - reconstruction_loss: 15.5640 - golden_loss: 1.0460\n",
      "Epoch 1480/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6087 - reconstruction_loss: 15.5336 - golden_loss: 1.0751\n",
      "Epoch 1481/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6073 - reconstruction_loss: 15.5616 - golden_loss: 1.0456\n",
      "Epoch 1482/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6059 - reconstruction_loss: 15.5340 - golden_loss: 1.0720\n",
      "Epoch 1483/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6049 - reconstruction_loss: 15.5595 - golden_loss: 1.0454\n",
      "Epoch 1484/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.6042 - reconstruction_loss: 15.5351 - golden_loss: 1.0691\n",
      "Epoch 1485/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6040 - reconstruction_loss: 15.5593 - golden_loss: 1.0446\n",
      "Epoch 1486/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6043 - reconstruction_loss: 15.5373 - golden_loss: 1.0670\n",
      "Epoch 1487/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6053 - reconstruction_loss: 15.5625 - golden_loss: 1.0429\n",
      "Epoch 1488/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.6073 - reconstruction_loss: 15.5411 - golden_loss: 1.0662\n",
      "Epoch 1489/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6106 - reconstruction_loss: 15.5710 - golden_loss: 1.0396\n",
      "Epoch 1490/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6156 - reconstruction_loss: 15.5483 - golden_loss: 1.0672\n",
      "Epoch 1491/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6232 - reconstruction_loss: 15.5889 - golden_loss: 1.0343\n",
      "Epoch 1492/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.6343 - reconstruction_loss: 15.5636 - golden_loss: 1.0707\n",
      "Epoch 1493/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6509 - reconstruction_loss: 15.6247 - golden_loss: 1.0262\n",
      "Epoch 1494/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6742 - reconstruction_loss: 15.5967 - golden_loss: 1.0775\n",
      "Epoch 1495/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7076 - reconstruction_loss: 15.6930 - golden_loss: 1.0146\n",
      "Epoch 1496/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7512 - reconstruction_loss: 15.6628 - golden_loss: 1.0884\n",
      "Epoch 1497/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8073 - reconstruction_loss: 15.8078 - golden_loss: 0.9995\n",
      "Epoch 1498/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8665 - reconstruction_loss: 15.7644 - golden_loss: 1.1020\n",
      "Epoch 1499/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9207 - reconstruction_loss: 15.9361 - golden_loss: 0.9846\n",
      "Epoch 1500/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.9400 - reconstruction_loss: 15.8291 - golden_loss: 1.1109\n",
      "Epoch 1501/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.9112 - reconstruction_loss: 15.9306 - golden_loss: 0.9806\n",
      "Epoch 1502/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.8225 - reconstruction_loss: 15.7219 - golden_loss: 1.1006\n",
      "Epoch 1503/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7091 - reconstruction_loss: 15.7093 - golden_loss: 0.9998\n",
      "Epoch 1504/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6160 - reconstruction_loss: 15.5498 - golden_loss: 1.0662\n",
      "Epoch 1505/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5810 - reconstruction_loss: 15.5443 - golden_loss: 1.0367\n",
      "Epoch 1506/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6053 - reconstruction_loss: 15.5795 - golden_loss: 1.0258\n",
      "Epoch 1507/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6599 - reconstruction_loss: 15.5909 - golden_loss: 1.0690\n",
      "Epoch 1508/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7069 - reconstruction_loss: 15.7059 - golden_loss: 1.0010\n",
      "Epoch 1509/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.7165 - reconstruction_loss: 15.6373 - golden_loss: 1.0792\n",
      "Epoch 1510/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6858 - reconstruction_loss: 15.6843 - golden_loss: 1.0015\n",
      "Epoch 1511/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6327 - reconstruction_loss: 15.5694 - golden_loss: 1.0633\n",
      "Epoch 1512/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5888 - reconstruction_loss: 15.5657 - golden_loss: 1.0230\n",
      "Epoch 1513/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5741 - reconstruction_loss: 15.5400 - golden_loss: 1.0341\n",
      "Epoch 1514/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5885 - reconstruction_loss: 15.5401 - golden_loss: 1.0485\n",
      "Epoch 1515/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6155 - reconstruction_loss: 15.6045 - golden_loss: 1.0111\n",
      "Epoch 1516/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6349 - reconstruction_loss: 15.5740 - golden_loss: 1.0609\n",
      "Epoch 1517/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6352 - reconstruction_loss: 15.6298 - golden_loss: 1.0054\n",
      "Epoch 1518/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6170 - reconstruction_loss: 15.5626 - golden_loss: 1.0544\n",
      "Epoch 1519/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5923 - reconstruction_loss: 15.5759 - golden_loss: 1.0164\n",
      "Epoch 1520/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5739 - reconstruction_loss: 15.5384 - golden_loss: 1.0355\n",
      "Epoch 1521/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5690 - reconstruction_loss: 15.5352 - golden_loss: 1.0338\n",
      "Epoch 1522/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5760 - reconstruction_loss: 15.5594 - golden_loss: 1.0167\n",
      "Epoch 1523/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5875 - reconstruction_loss: 15.5417 - golden_loss: 1.0458\n",
      "Epoch 1524/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.5954 - reconstruction_loss: 15.5880 - golden_loss: 1.0074\n",
      "Epoch 1525/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.5953 - reconstruction_loss: 15.5492 - golden_loss: 1.0461\n",
      "Epoch 1526/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.5879 - reconstruction_loss: 15.5780 - golden_loss: 1.0099\n",
      "Epoch 1527/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5771 - reconstruction_loss: 15.5411 - golden_loss: 1.0361\n",
      "Epoch 1528/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5679 - reconstruction_loss: 15.5481 - golden_loss: 1.0198\n",
      "Epoch 1529/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5634 - reconstruction_loss: 15.5414 - golden_loss: 1.0220\n",
      "Epoch 1530/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5639 - reconstruction_loss: 15.5336 - golden_loss: 1.0302\n",
      "Epoch 1531/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5673 - reconstruction_loss: 15.5567 - golden_loss: 1.0106\n",
      "Epoch 1532/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5711 - reconstruction_loss: 15.5354 - golden_loss: 1.0357\n",
      "Epoch 1533/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5729 - reconstruction_loss: 15.5672 - golden_loss: 1.0056\n",
      "Epoch 1534/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5719 - reconstruction_loss: 15.5375 - golden_loss: 1.0344\n",
      "Epoch 1535/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.5685 - reconstruction_loss: 15.5615 - golden_loss: 1.0070\n",
      "Epoch 1536/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5640 - reconstruction_loss: 15.5364 - golden_loss: 1.0276\n",
      "Epoch 1537/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5598 - reconstruction_loss: 15.5474 - golden_loss: 1.0124\n",
      "Epoch 1538/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5568 - reconstruction_loss: 15.5384 - golden_loss: 1.0184\n",
      "Epoch 1539/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5555 - reconstruction_loss: 15.5369 - golden_loss: 1.0185\n",
      "Epoch 1540/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5555 - reconstruction_loss: 15.5456 - golden_loss: 1.0099\n",
      "Epoch 1541/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5563 - reconstruction_loss: 15.5333 - golden_loss: 1.0230\n",
      "Epoch 1542/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5572 - reconstruction_loss: 15.5534 - golden_loss: 1.0039\n",
      "Epoch 1543/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5578 - reconstruction_loss: 15.5331 - golden_loss: 1.0246\n",
      "Epoch 1544/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5576 - reconstruction_loss: 15.5569 - golden_loss: 1.0007\n",
      "Epoch 1545/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5568 - reconstruction_loss: 15.5333 - golden_loss: 1.0235\n",
      "Epoch 1546/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5554 - reconstruction_loss: 15.5554 - golden_loss: 0.9999\n",
      "Epoch 1547/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5536 - reconstruction_loss: 15.5332 - golden_loss: 1.0204\n",
      "Epoch 1548/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5516 - reconstruction_loss: 15.5510 - golden_loss: 1.0007\n",
      "Epoch 1549/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5498 - reconstruction_loss: 15.5335 - golden_loss: 1.0163\n",
      "Epoch 1550/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5481 - reconstruction_loss: 15.5461 - golden_loss: 1.0020\n",
      "Epoch 1551/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.5467 - reconstruction_loss: 15.5347 - golden_loss: 1.0120\n",
      "Epoch 1552/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5456 - reconstruction_loss: 15.5424 - golden_loss: 1.0032\n",
      "Epoch 1553/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5447 - reconstruction_loss: 15.5366 - golden_loss: 1.0081\n",
      "Epoch 1554/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5441 - reconstruction_loss: 15.5403 - golden_loss: 1.0038\n",
      "Epoch 1555/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5436 - reconstruction_loss: 15.5388 - golden_loss: 1.0048\n",
      "Epoch 1556/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5433 - reconstruction_loss: 15.5397 - golden_loss: 1.0037\n",
      "Epoch 1557/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5433 - reconstruction_loss: 15.5409 - golden_loss: 1.0023\n",
      "Epoch 1558/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5435 - reconstruction_loss: 15.5406 - golden_loss: 1.0029\n",
      "Epoch 1559/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.5441 - reconstruction_loss: 15.5435 - golden_loss: 1.0006\n",
      "Epoch 1560/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5453 - reconstruction_loss: 15.5440 - golden_loss: 1.0013\n",
      "Epoch 1561/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5476 - reconstruction_loss: 15.5479 - golden_loss: 0.9997\n",
      "Epoch 1562/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5514 - reconstruction_loss: 15.5527 - golden_loss: 0.9988\n",
      "Epoch 1563/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.5580 - reconstruction_loss: 15.5581 - golden_loss: 0.9999\n",
      "Epoch 1564/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5689 - reconstruction_loss: 15.5739 - golden_loss: 0.9949\n",
      "Epoch 1565/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.5868 - reconstruction_loss: 15.5849 - golden_loss: 1.0020\n",
      "Epoch 1566/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6154 - reconstruction_loss: 15.6266 - golden_loss: 0.9887\n",
      "Epoch 1567/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6603 - reconstruction_loss: 15.6530 - golden_loss: 1.0074\n",
      "Epoch 1568/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.7246 - reconstruction_loss: 15.7460 - golden_loss: 0.9786\n",
      "Epoch 1569/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.8106 - reconstruction_loss: 15.7926 - golden_loss: 1.0180\n",
      "Epoch 1570/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.8973 - reconstruction_loss: 15.9342 - golden_loss: 0.9631\n",
      "Epoch 1571/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9577 - reconstruction_loss: 15.9233 - golden_loss: 1.0345\n",
      "Epoch 1572/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9394 - reconstruction_loss: 15.9959 - golden_loss: 0.9435\n",
      "Epoch 1573/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.8576 - reconstruction_loss: 15.8060 - golden_loss: 1.0517\n",
      "Epoch 1574/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7700 - reconstruction_loss: 15.8435 - golden_loss: 0.9266\n",
      "Epoch 1575/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7619 - reconstruction_loss: 15.7006 - golden_loss: 1.0613\n",
      "Epoch 1576/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.8343 - reconstruction_loss: 15.9129 - golden_loss: 0.9214\n",
      "Epoch 1577/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9043 - reconstruction_loss: 15.8490 - golden_loss: 1.0553\n",
      "Epoch 1578/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.8849 - reconstruction_loss: 15.9488 - golden_loss: 0.9361\n",
      "Epoch 1579/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.7476 - reconstruction_loss: 15.7215 - golden_loss: 1.0261\n",
      "Epoch 1580/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5901 - reconstruction_loss: 15.6197 - golden_loss: 0.9703\n",
      "Epoch 1581/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5257 - reconstruction_loss: 15.5413 - golden_loss: 0.9843\n",
      "Epoch 1582/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5812 - reconstruction_loss: 15.5740 - golden_loss: 1.0072\n",
      "Epoch 1583/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6784 - reconstruction_loss: 15.7256 - golden_loss: 0.9528\n",
      "Epoch 1584/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.7170 - reconstruction_loss: 15.6905 - golden_loss: 1.0265\n",
      "Epoch 1585/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.6709 - reconstruction_loss: 15.7261 - golden_loss: 0.9448\n",
      "Epoch 1586/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5902 - reconstruction_loss: 15.5719 - golden_loss: 1.0183\n",
      "Epoch 1587/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5469 - reconstruction_loss: 15.5847 - golden_loss: 0.9622\n",
      "Epoch 1588/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5575 - reconstruction_loss: 15.5676 - golden_loss: 0.9899\n",
      "Epoch 1589/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.5851 - reconstruction_loss: 15.5944 - golden_loss: 0.9907\n",
      "Epoch 1590/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5927 - reconstruction_loss: 15.6309 - golden_loss: 0.9618\n",
      "Epoch 1591/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5775 - reconstruction_loss: 15.5681 - golden_loss: 1.0094\n",
      "Epoch 1592/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5628 - reconstruction_loss: 15.6119 - golden_loss: 0.9509\n",
      "Epoch 1593/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5609 - reconstruction_loss: 15.5540 - golden_loss: 1.0069\n",
      "Epoch 1594/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5619 - reconstruction_loss: 15.6009 - golden_loss: 0.9610\n",
      "Epoch 1595/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5530 - reconstruction_loss: 15.5660 - golden_loss: 0.9870\n",
      "Epoch 1596/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.5363 - reconstruction_loss: 15.5549 - golden_loss: 0.9814\n",
      "Epoch 1597/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5273 - reconstruction_loss: 15.5624 - golden_loss: 0.9649\n",
      "Epoch 1598/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5342 - reconstruction_loss: 15.5377 - golden_loss: 0.9965\n",
      "Epoch 1599/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5481 - reconstruction_loss: 15.5937 - golden_loss: 0.9544\n",
      "Epoch 1600/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5526 - reconstruction_loss: 15.5559 - golden_loss: 0.9967\n",
      "Epoch 1601/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5409 - reconstruction_loss: 15.5818 - golden_loss: 0.9591\n",
      "Epoch 1602/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5226 - reconstruction_loss: 15.5390 - golden_loss: 0.9836\n",
      "Epoch 1603/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5121 - reconstruction_loss: 15.5396 - golden_loss: 0.9725\n",
      "Epoch 1604/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5152 - reconstruction_loss: 15.5479 - golden_loss: 0.9673\n",
      "Epoch 1605/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5250 - reconstruction_loss: 15.5409 - golden_loss: 0.9841\n",
      "Epoch 1606/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5309 - reconstruction_loss: 15.5737 - golden_loss: 0.9572\n",
      "Epoch 1607/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5281 - reconstruction_loss: 15.5413 - golden_loss: 0.9868\n",
      "Epoch 1608/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5200 - reconstruction_loss: 15.5632 - golden_loss: 0.9569\n",
      "Epoch 1609/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5133 - reconstruction_loss: 15.5329 - golden_loss: 0.9804\n",
      "Epoch 1610/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.5113 - reconstruction_loss: 15.5479 - golden_loss: 0.9634\n",
      "Epoch 1611/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5123 - reconstruction_loss: 15.5423 - golden_loss: 0.9700\n",
      "Epoch 1612/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5129 - reconstruction_loss: 15.5419 - golden_loss: 0.9710\n",
      "Epoch 1613/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.5116 - reconstruction_loss: 15.5505 - golden_loss: 0.9611\n",
      "Epoch 1614/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5096 - reconstruction_loss: 15.5343 - golden_loss: 0.9753\n",
      "Epoch 1615/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5086 - reconstruction_loss: 15.5520 - golden_loss: 0.9566\n",
      "Epoch 1616/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5089 - reconstruction_loss: 15.5340 - golden_loss: 0.9749\n",
      "Epoch 1617/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5095 - reconstruction_loss: 15.5531 - golden_loss: 0.9563\n",
      "Epoch 1618/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5085 - reconstruction_loss: 15.5376 - golden_loss: 0.9710\n",
      "Epoch 1619/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.5059 - reconstruction_loss: 15.5473 - golden_loss: 0.9586\n",
      "Epoch 1620/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.5026 - reconstruction_loss: 15.5371 - golden_loss: 0.9655\n",
      "Epoch 1621/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5003 - reconstruction_loss: 15.5388 - golden_loss: 0.9615\n",
      "Epoch 1622/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.4996 - reconstruction_loss: 15.5394 - golden_loss: 0.9602\n",
      "Epoch 1623/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5002 - reconstruction_loss: 15.5364 - golden_loss: 0.9638\n",
      "Epoch 1624/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5009 - reconstruction_loss: 15.5450 - golden_loss: 0.9560\n",
      "Epoch 1625/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.5010 - reconstruction_loss: 15.5362 - golden_loss: 0.9648\n",
      "Epoch 1626/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5001 - reconstruction_loss: 15.5471 - golden_loss: 0.9530\n",
      "Epoch 1627/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4988 - reconstruction_loss: 15.5344 - golden_loss: 0.9644\n",
      "Epoch 1628/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4975 - reconstruction_loss: 15.5461 - golden_loss: 0.9514\n",
      "Epoch 1629/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4966 - reconstruction_loss: 15.5337 - golden_loss: 0.9629\n",
      "Epoch 1630/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4960 - reconstruction_loss: 15.5452 - golden_loss: 0.9508\n",
      "Epoch 1631/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4954 - reconstruction_loss: 15.5349 - golden_loss: 0.9605\n",
      "Epoch 1632/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4946 - reconstruction_loss: 15.5437 - golden_loss: 0.9509\n",
      "Epoch 1633/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4934 - reconstruction_loss: 15.5358 - golden_loss: 0.9576\n",
      "Epoch 1634/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4922 - reconstruction_loss: 15.5409 - golden_loss: 0.9512\n",
      "Epoch 1635/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4911 - reconstruction_loss: 15.5365 - golden_loss: 0.9546\n",
      "Epoch 1636/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4902 - reconstruction_loss: 15.5386 - golden_loss: 0.9516\n",
      "Epoch 1637/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4896 - reconstruction_loss: 15.5378 - golden_loss: 0.9518\n",
      "Epoch 1638/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4891 - reconstruction_loss: 15.5375 - golden_loss: 0.9516\n",
      "Epoch 1639/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4887 - reconstruction_loss: 15.5394 - golden_loss: 0.9493\n",
      "Epoch 1640/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4881 - reconstruction_loss: 15.5368 - golden_loss: 0.9513\n",
      "Epoch 1641/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4875 - reconstruction_loss: 15.5404 - golden_loss: 0.9471\n",
      "Epoch 1642/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4868 - reconstruction_loss: 15.5359 - golden_loss: 0.9509\n",
      "Epoch 1643/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4861 - reconstruction_loss: 15.5410 - golden_loss: 0.9450\n",
      "Epoch 1644/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4855 - reconstruction_loss: 15.5351 - golden_loss: 0.9504\n",
      "Epoch 1645/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4850 - reconstruction_loss: 15.5422 - golden_loss: 0.9428\n",
      "Epoch 1646/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4847 - reconstruction_loss: 15.5345 - golden_loss: 0.9502\n",
      "Epoch 1647/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4845 - reconstruction_loss: 15.5443 - golden_loss: 0.9402\n",
      "Epoch 1648/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4844 - reconstruction_loss: 15.5339 - golden_loss: 0.9505\n",
      "Epoch 1649/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4846 - reconstruction_loss: 15.5478 - golden_loss: 0.9368\n",
      "Epoch 1650/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4852 - reconstruction_loss: 15.5333 - golden_loss: 0.9519\n",
      "Epoch 1651/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4864 - reconstruction_loss: 15.5542 - golden_loss: 0.9322\n",
      "Epoch 1652/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4887 - reconstruction_loss: 15.5338 - golden_loss: 0.9549\n",
      "Epoch 1653/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4927 - reconstruction_loss: 15.5672 - golden_loss: 0.9255\n",
      "Epoch 1654/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4995 - reconstruction_loss: 15.5387 - golden_loss: 0.9608\n",
      "Epoch 1655/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5109 - reconstruction_loss: 15.5957 - golden_loss: 0.9153\n",
      "Epoch 1656/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5296 - reconstruction_loss: 15.5584 - golden_loss: 0.9712\n",
      "Epoch 1657/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.5597 - reconstruction_loss: 15.6600 - golden_loss: 0.8996\n",
      "Epoch 1658/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6063 - reconstruction_loss: 15.6178 - golden_loss: 0.9884\n",
      "Epoch 1659/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6740 - reconstruction_loss: 15.7966 - golden_loss: 0.8774\n",
      "Epoch 1660/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.7620 - reconstruction_loss: 15.7501 - golden_loss: 1.0119\n",
      "Epoch 1661/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8523 - reconstruction_loss: 15.9983 - golden_loss: 0.8541\n",
      "Epoch 1662/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.9032 - reconstruction_loss: 15.8755 - golden_loss: 1.0277\n",
      "Epoch 1663/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.8616 - reconstruction_loss: 16.0094 - golden_loss: 0.8521\n",
      "Epoch 1664/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7205 - reconstruction_loss: 15.7168 - golden_loss: 1.0037\n",
      "Epoch 1665/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5570 - reconstruction_loss: 15.6613 - golden_loss: 0.8957\n",
      "Epoch 1666/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.4767 - reconstruction_loss: 15.5382 - golden_loss: 0.9386\n",
      "Epoch 1667/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5135 - reconstruction_loss: 15.5532 - golden_loss: 0.9603\n",
      "Epoch 1668/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6058 - reconstruction_loss: 15.7222 - golden_loss: 0.8836\n",
      "Epoch 1669/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6601 - reconstruction_loss: 15.6679 - golden_loss: 0.9922\n",
      "Epoch 1670/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.6249 - reconstruction_loss: 15.7461 - golden_loss: 0.8788\n",
      "Epoch 1671/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.5354 - reconstruction_loss: 15.5691 - golden_loss: 0.9663\n",
      "Epoch 1672/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4730 - reconstruction_loss: 15.5514 - golden_loss: 0.9216\n",
      "Epoch 1673/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4830 - reconstruction_loss: 15.5699 - golden_loss: 0.9132\n",
      "Epoch 1674/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5353 - reconstruction_loss: 15.5700 - golden_loss: 0.9653\n",
      "Epoch 1675/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5665 - reconstruction_loss: 15.6802 - golden_loss: 0.8863\n",
      "Epoch 1676/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5447 - reconstruction_loss: 15.5778 - golden_loss: 0.9668\n",
      "Epoch 1677/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4946 - reconstruction_loss: 15.5900 - golden_loss: 0.9046\n",
      "Epoch 1678/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4655 - reconstruction_loss: 15.5351 - golden_loss: 0.9305\n",
      "Epoch 1679/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4776 - reconstruction_loss: 15.5354 - golden_loss: 0.9421\n",
      "Epoch 1680/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5074 - reconstruction_loss: 15.6094 - golden_loss: 0.8980\n",
      "Epoch 1681/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.5193 - reconstruction_loss: 15.5617 - golden_loss: 0.9577\n",
      "Epoch 1682/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5019 - reconstruction_loss: 15.6034 - golden_loss: 0.8984\n",
      "Epoch 1683/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4744 - reconstruction_loss: 15.5356 - golden_loss: 0.9388\n",
      "Epoch 1684/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4627 - reconstruction_loss: 15.5386 - golden_loss: 0.9241\n",
      "Epoch 1685/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4728 - reconstruction_loss: 15.5633 - golden_loss: 0.9094\n",
      "Epoch 1686/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4889 - reconstruction_loss: 15.5442 - golden_loss: 0.9447\n",
      "Epoch 1687/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4929 - reconstruction_loss: 15.5944 - golden_loss: 0.8985\n",
      "Epoch 1688/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4820 - reconstruction_loss: 15.5417 - golden_loss: 0.9403\n",
      "Epoch 1689/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4680 - reconstruction_loss: 15.5568 - golden_loss: 0.9112\n",
      "Epoch 1690/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4639 - reconstruction_loss: 15.5449 - golden_loss: 0.9189\n",
      "Epoch 1691/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4715 - reconstruction_loss: 15.5412 - golden_loss: 0.9303\n",
      "Epoch 1692/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4826 - reconstruction_loss: 15.5801 - golden_loss: 0.9026\n",
      "Epoch 1693/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.4885 - reconstruction_loss: 15.5525 - golden_loss: 0.9361\n",
      "Epoch 1694/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4886 - reconstruction_loss: 15.5851 - golden_loss: 0.9036\n",
      "Epoch 1695/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4895 - reconstruction_loss: 15.5645 - golden_loss: 0.9251\n",
      "Epoch 1696/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4996 - reconstruction_loss: 15.5830 - golden_loss: 0.9166\n",
      "Epoch 1697/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5218 - reconstruction_loss: 15.6126 - golden_loss: 0.9092\n",
      "Epoch 1698/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5550 - reconstruction_loss: 15.6279 - golden_loss: 0.9272\n",
      "Epoch 1699/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5946 - reconstruction_loss: 15.6925 - golden_loss: 0.9021\n",
      "Epoch 1700/2000\n",
      "1/1 [==============================] - 0s 271us/step - loss: 16.6398 - reconstruction_loss: 15.7140 - golden_loss: 0.9258\n",
      "Epoch 1701/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6831 - reconstruction_loss: 15.7756 - golden_loss: 0.9075\n",
      "Epoch 1702/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.7180 - reconstruction_loss: 15.8039 - golden_loss: 0.9142\n",
      "Epoch 1703/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7208 - reconstruction_loss: 15.8020 - golden_loss: 0.9188\n",
      "Epoch 1704/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6828 - reconstruction_loss: 15.7813 - golden_loss: 0.9014\n",
      "Epoch 1705/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6034 - reconstruction_loss: 15.6774 - golden_loss: 0.9260\n",
      "Epoch 1706/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5181 - reconstruction_loss: 15.6214 - golden_loss: 0.8967\n",
      "Epoch 1707/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4626 - reconstruction_loss: 15.5400 - golden_loss: 0.9226\n",
      "Epoch 1708/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4559 - reconstruction_loss: 15.5532 - golden_loss: 0.9026\n",
      "Epoch 1709/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4876 - reconstruction_loss: 15.5766 - golden_loss: 0.9110\n",
      "Epoch 1710/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.5295 - reconstruction_loss: 15.6158 - golden_loss: 0.9136\n",
      "Epoch 1711/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5537 - reconstruction_loss: 15.6547 - golden_loss: 0.8990\n",
      "Epoch 1712/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5445 - reconstruction_loss: 15.6237 - golden_loss: 0.9208\n",
      "Epoch 1713/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5099 - reconstruction_loss: 15.6160 - golden_loss: 0.8939\n",
      "Epoch 1714/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4706 - reconstruction_loss: 15.5517 - golden_loss: 0.9189\n",
      "Epoch 1715/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4483 - reconstruction_loss: 15.5505 - golden_loss: 0.8978\n",
      "Epoch 1716/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4501 - reconstruction_loss: 15.5406 - golden_loss: 0.9095\n",
      "Epoch 1717/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4677 - reconstruction_loss: 15.5610 - golden_loss: 0.9067\n",
      "Epoch 1718/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.4858 - reconstruction_loss: 15.5872 - golden_loss: 0.8986\n",
      "Epoch 1719/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4917 - reconstruction_loss: 15.5779 - golden_loss: 0.9137\n",
      "Epoch 1720/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4828 - reconstruction_loss: 15.5905 - golden_loss: 0.8923\n",
      "Epoch 1721/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.4650 - reconstruction_loss: 15.5507 - golden_loss: 0.9144\n",
      "Epoch 1722/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4489 - reconstruction_loss: 15.5560 - golden_loss: 0.8930\n",
      "Epoch 1723/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4416 - reconstruction_loss: 15.5333 - golden_loss: 0.9083\n",
      "Epoch 1724/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.4440 - reconstruction_loss: 15.5452 - golden_loss: 0.8988\n",
      "Epoch 1725/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4516 - reconstruction_loss: 15.5522 - golden_loss: 0.8994\n",
      "Epoch 1726/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4583 - reconstruction_loss: 15.5529 - golden_loss: 0.9053\n",
      "Epoch 1727/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4600 - reconstruction_loss: 15.5680 - golden_loss: 0.8919\n",
      "Epoch 1728/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4559 - reconstruction_loss: 15.5474 - golden_loss: 0.9085\n",
      "Epoch 1729/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4486 - reconstruction_loss: 15.5595 - golden_loss: 0.8891\n",
      "Epoch 1730/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4415 - reconstruction_loss: 15.5349 - golden_loss: 0.9066\n",
      "Epoch 1731/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4371 - reconstruction_loss: 15.5462 - golden_loss: 0.8909\n",
      "Epoch 1732/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4363 - reconstruction_loss: 15.5355 - golden_loss: 0.9007\n",
      "Epoch 1733/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.4379 - reconstruction_loss: 15.5424 - golden_loss: 0.8955\n",
      "Epoch 1734/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.4403 - reconstruction_loss: 15.5465 - golden_loss: 0.8937\n",
      "Epoch 1735/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.4418 - reconstruction_loss: 15.5420 - golden_loss: 0.8998\n",
      "Epoch 1736/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4416 - reconstruction_loss: 15.5534 - golden_loss: 0.8882\n",
      "Epoch 1737/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4398 - reconstruction_loss: 15.5382 - golden_loss: 0.9017\n",
      "Epoch 1738/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4371 - reconstruction_loss: 15.5514 - golden_loss: 0.8857\n",
      "Epoch 1739/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4343 - reconstruction_loss: 15.5339 - golden_loss: 0.9004\n",
      "Epoch 1740/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4320 - reconstruction_loss: 15.5459 - golden_loss: 0.8861\n",
      "Epoch 1741/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4305 - reconstruction_loss: 15.5339 - golden_loss: 0.8965\n",
      "Epoch 1742/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4298 - reconstruction_loss: 15.5413 - golden_loss: 0.8884\n",
      "Epoch 1743/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4296 - reconstruction_loss: 15.5381 - golden_loss: 0.8915\n",
      "Epoch 1744/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4297 - reconstruction_loss: 15.5385 - golden_loss: 0.8912\n",
      "Epoch 1745/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4298 - reconstruction_loss: 15.5430 - golden_loss: 0.8868\n",
      "Epoch 1746/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4297 - reconstruction_loss: 15.5364 - golden_loss: 0.8933\n",
      "Epoch 1747/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4293 - reconstruction_loss: 15.5462 - golden_loss: 0.8831\n",
      "Epoch 1748/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4287 - reconstruction_loss: 15.5347 - golden_loss: 0.8939\n",
      "Epoch 1749/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4278 - reconstruction_loss: 15.5468 - golden_loss: 0.8809\n",
      "Epoch 1750/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.4268 - reconstruction_loss: 15.5336 - golden_loss: 0.8931\n",
      "Epoch 1751/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4257 - reconstruction_loss: 15.5456 - golden_loss: 0.8801\n",
      "Epoch 1752/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4246 - reconstruction_loss: 15.5334 - golden_loss: 0.8912\n",
      "Epoch 1753/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4236 - reconstruction_loss: 15.5433 - golden_loss: 0.8802\n",
      "Epoch 1754/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4226 - reconstruction_loss: 15.5341 - golden_loss: 0.8885\n",
      "Epoch 1755/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4217 - reconstruction_loss: 15.5409 - golden_loss: 0.8808\n",
      "Epoch 1756/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4210 - reconstruction_loss: 15.5354 - golden_loss: 0.8856\n",
      "Epoch 1757/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4203 - reconstruction_loss: 15.5388 - golden_loss: 0.8815\n",
      "Epoch 1758/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4197 - reconstruction_loss: 15.5370 - golden_loss: 0.8827\n",
      "Epoch 1759/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4191 - reconstruction_loss: 15.5371 - golden_loss: 0.8820\n",
      "Epoch 1760/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4187 - reconstruction_loss: 15.5386 - golden_loss: 0.8800\n",
      "Epoch 1761/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4182 - reconstruction_loss: 15.5359 - golden_loss: 0.8824\n",
      "Epoch 1762/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4179 - reconstruction_loss: 15.5403 - golden_loss: 0.8775\n",
      "Epoch 1763/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4175 - reconstruction_loss: 15.5350 - golden_loss: 0.8825\n",
      "Epoch 1764/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4173 - reconstruction_loss: 15.5421 - golden_loss: 0.8752\n",
      "Epoch 1765/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4171 - reconstruction_loss: 15.5344 - golden_loss: 0.8827\n",
      "Epoch 1766/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4170 - reconstruction_loss: 15.5442 - golden_loss: 0.8727\n",
      "Epoch 1767/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4171 - reconstruction_loss: 15.5340 - golden_loss: 0.8830\n",
      "Epoch 1768/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4174 - reconstruction_loss: 15.5474 - golden_loss: 0.8700\n",
      "Epoch 1769/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4180 - reconstruction_loss: 15.5341 - golden_loss: 0.8839\n",
      "Epoch 1770/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4192 - reconstruction_loss: 15.5526 - golden_loss: 0.8666\n",
      "Epoch 1771/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4211 - reconstruction_loss: 15.5355 - golden_loss: 0.8856\n",
      "Epoch 1772/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4242 - reconstruction_loss: 15.5623 - golden_loss: 0.8620\n",
      "Epoch 1773/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4292 - reconstruction_loss: 15.5403 - golden_loss: 0.8889\n",
      "Epoch 1774/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4369 - reconstruction_loss: 15.5814 - golden_loss: 0.8555\n",
      "Epoch 1775/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4490 - reconstruction_loss: 15.5544 - golden_loss: 0.8946\n",
      "Epoch 1776/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4678 - reconstruction_loss: 15.6216 - golden_loss: 0.8461\n",
      "Epoch 1777/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4963 - reconstruction_loss: 15.5923 - golden_loss: 0.9040\n",
      "Epoch 1778/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.5396 - reconstruction_loss: 15.7068 - golden_loss: 0.8328\n",
      "Epoch 1779/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6014 - reconstruction_loss: 15.6834 - golden_loss: 0.9180\n",
      "Epoch 1780/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.6872 - reconstruction_loss: 15.8714 - golden_loss: 0.8158\n",
      "Epoch 1781/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.7898 - reconstruction_loss: 15.8555 - golden_loss: 0.9343\n",
      "Epoch 1782/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.8978 - reconstruction_loss: 16.0963 - golden_loss: 0.8015\n",
      "Epoch 1783/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.9651 - reconstruction_loss: 16.0245 - golden_loss: 0.9406\n",
      "Epoch 1784/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.9629 - reconstruction_loss: 16.1568 - golden_loss: 0.8062\n",
      "Epoch 1785/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.8590 - reconstruction_loss: 15.9418 - golden_loss: 0.9172\n",
      "Epoch 1786/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7054 - reconstruction_loss: 15.8631 - golden_loss: 0.8423\n",
      "Epoch 1787/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16.5650 - reconstruction_loss: 15.6979 - golden_loss: 0.8671\n",
      "Epoch 1788/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5031 - reconstruction_loss: 15.6117 - golden_loss: 0.8914\n",
      "Epoch 1789/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5224 - reconstruction_loss: 15.6984 - golden_loss: 0.8241\n",
      "Epoch 1790/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5756 - reconstruction_loss: 15.6573 - golden_loss: 0.9183\n",
      "Epoch 1791/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5998 - reconstruction_loss: 15.7833 - golden_loss: 0.8164\n",
      "Epoch 1792/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5676 - reconstruction_loss: 15.6648 - golden_loss: 0.9028\n",
      "Epoch 1793/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5098 - reconstruction_loss: 15.6623 - golden_loss: 0.8475\n",
      "Epoch 1794/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4718 - reconstruction_loss: 15.6127 - golden_loss: 0.8592\n",
      "Epoch 1795/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4749 - reconstruction_loss: 15.5859 - golden_loss: 0.8890\n",
      "Epoch 1796/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4976 - reconstruction_loss: 15.6715 - golden_loss: 0.8260\n",
      "Epoch 1797/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5054 - reconstruction_loss: 15.6009 - golden_loss: 0.9045\n",
      "Epoch 1798/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4818 - reconstruction_loss: 15.6535 - golden_loss: 0.8283\n",
      "Epoch 1799/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4444 - reconstruction_loss: 15.5619 - golden_loss: 0.8825\n",
      "Epoch 1800/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4251 - reconstruction_loss: 15.5658 - golden_loss: 0.8593\n",
      "Epoch 1801/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.4356 - reconstruction_loss: 15.5891 - golden_loss: 0.8465\n",
      "Epoch 1802/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4594 - reconstruction_loss: 15.5714 - golden_loss: 0.8880\n",
      "Epoch 1803/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4685 - reconstruction_loss: 15.6399 - golden_loss: 0.8285\n",
      "Epoch 1804/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4514 - reconstruction_loss: 15.5622 - golden_loss: 0.8892\n",
      "Epoch 1805/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4206 - reconstruction_loss: 15.5808 - golden_loss: 0.8398\n",
      "Epoch 1806/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4004 - reconstruction_loss: 15.5352 - golden_loss: 0.8652\n",
      "Epoch 1807/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4036 - reconstruction_loss: 15.5379 - golden_loss: 0.8657\n",
      "Epoch 1808/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4220 - reconstruction_loss: 15.5819 - golden_loss: 0.8401\n",
      "Epoch 1809/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4367 - reconstruction_loss: 15.5555 - golden_loss: 0.8812\n",
      "Epoch 1810/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4344 - reconstruction_loss: 15.6005 - golden_loss: 0.8338\n",
      "Epoch 1811/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.4178 - reconstruction_loss: 15.5432 - golden_loss: 0.8745\n",
      "Epoch 1812/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4000 - reconstruction_loss: 15.5530 - golden_loss: 0.8469\n",
      "Epoch 1813/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3928 - reconstruction_loss: 15.5382 - golden_loss: 0.8547\n",
      "Epoch 1814/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.3977 - reconstruction_loss: 15.5331 - golden_loss: 0.8646\n",
      "Epoch 1815/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4069 - reconstruction_loss: 15.5676 - golden_loss: 0.8393\n",
      "Epoch 1816/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4116 - reconstruction_loss: 15.5402 - golden_loss: 0.8714\n",
      "Epoch 1817/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4085 - reconstruction_loss: 15.5702 - golden_loss: 0.8383\n",
      "Epoch 1818/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4010 - reconstruction_loss: 15.5374 - golden_loss: 0.8636\n",
      "Epoch 1819/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3947 - reconstruction_loss: 15.5462 - golden_loss: 0.8485\n",
      "Epoch 1820/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3929 - reconstruction_loss: 15.5433 - golden_loss: 0.8496\n",
      "Epoch 1821/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3946 - reconstruction_loss: 15.5353 - golden_loss: 0.8593\n",
      "Epoch 1822/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3965 - reconstruction_loss: 15.5562 - golden_loss: 0.8403\n",
      "Epoch 1823/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3960 - reconstruction_loss: 15.5340 - golden_loss: 0.8621\n",
      "Epoch 1824/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3931 - reconstruction_loss: 15.5528 - golden_loss: 0.8403\n",
      "Epoch 1825/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3896 - reconstruction_loss: 15.5335 - golden_loss: 0.8561\n",
      "Epoch 1826/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3877 - reconstruction_loss: 15.5410 - golden_loss: 0.8467\n",
      "Epoch 1827/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3880 - reconstruction_loss: 15.5411 - golden_loss: 0.8469\n",
      "Epoch 1828/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.3896 - reconstruction_loss: 15.5366 - golden_loss: 0.8530\n",
      "Epoch 1829/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3907 - reconstruction_loss: 15.5500 - golden_loss: 0.8407\n",
      "Epoch 1830/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3903 - reconstruction_loss: 15.5358 - golden_loss: 0.8545\n",
      "Epoch 1831/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3882 - reconstruction_loss: 15.5483 - golden_loss: 0.8400\n",
      "Epoch 1832/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3855 - reconstruction_loss: 15.5348 - golden_loss: 0.8507\n",
      "Epoch 1833/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3831 - reconstruction_loss: 15.5398 - golden_loss: 0.8433\n",
      "Epoch 1834/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3819 - reconstruction_loss: 15.5373 - golden_loss: 0.8446\n",
      "Epoch 1835/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3817 - reconstruction_loss: 15.5345 - golden_loss: 0.8473\n",
      "Epoch 1836/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.3821 - reconstruction_loss: 15.5426 - golden_loss: 0.8396\n",
      "Epoch 1837/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3824 - reconstruction_loss: 15.5335 - golden_loss: 0.8489\n",
      "Epoch 1838/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.3822 - reconstruction_loss: 15.5446 - golden_loss: 0.8376\n",
      "Epoch 1839/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.3814 - reconstruction_loss: 15.5342 - golden_loss: 0.8472\n",
      "Epoch 1840/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3804 - reconstruction_loss: 15.5418 - golden_loss: 0.8386\n",
      "Epoch 1841/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3794 - reconstruction_loss: 15.5361 - golden_loss: 0.8433\n",
      "Epoch 1842/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3787 - reconstruction_loss: 15.5378 - golden_loss: 0.8409\n",
      "Epoch 1843/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3783 - reconstruction_loss: 15.5394 - golden_loss: 0.8389\n",
      "Epoch 1844/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3782 - reconstruction_loss: 15.5353 - golden_loss: 0.8429\n",
      "Epoch 1845/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3781 - reconstruction_loss: 15.5426 - golden_loss: 0.8355\n",
      "Epoch 1846/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3780 - reconstruction_loss: 15.5345 - golden_loss: 0.8435\n",
      "Epoch 1847/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.3777 - reconstruction_loss: 15.5438 - golden_loss: 0.8338\n",
      "Epoch 1848/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.3772 - reconstruction_loss: 15.5348 - golden_loss: 0.8424\n",
      "Epoch 1849/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3766 - reconstruction_loss: 15.5431 - golden_loss: 0.8335\n",
      "Epoch 1850/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3761 - reconstruction_loss: 15.5359 - golden_loss: 0.8402\n",
      "Epoch 1851/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3758 - reconstruction_loss: 15.5418 - golden_loss: 0.8340\n",
      "Epoch 1852/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3756 - reconstruction_loss: 15.5380 - golden_loss: 0.8377\n",
      "Epoch 1853/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3759 - reconstruction_loss: 15.5414 - golden_loss: 0.8345\n",
      "Epoch 1854/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3765 - reconstruction_loss: 15.5411 - golden_loss: 0.8354\n",
      "Epoch 1855/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3776 - reconstruction_loss: 15.5432 - golden_loss: 0.8344\n",
      "Epoch 1856/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3794 - reconstruction_loss: 15.5456 - golden_loss: 0.8338\n",
      "Epoch 1857/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3821 - reconstruction_loss: 15.5485 - golden_loss: 0.8336\n",
      "Epoch 1858/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.3864 - reconstruction_loss: 15.5533 - golden_loss: 0.8331\n",
      "Epoch 1859/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3928 - reconstruction_loss: 15.5609 - golden_loss: 0.8319\n",
      "Epoch 1860/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4026 - reconstruction_loss: 15.5693 - golden_loss: 0.8334\n",
      "Epoch 1861/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4173 - reconstruction_loss: 15.5881 - golden_loss: 0.8292\n",
      "Epoch 1862/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4393 - reconstruction_loss: 15.6046 - golden_loss: 0.8347\n",
      "Epoch 1863/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4705 - reconstruction_loss: 15.6450 - golden_loss: 0.8255\n",
      "Epoch 1864/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5145 - reconstruction_loss: 15.6773 - golden_loss: 0.8372\n",
      "Epoch 1865/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.5690 - reconstruction_loss: 15.7481 - golden_loss: 0.8209\n",
      "Epoch 1866/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6314 - reconstruction_loss: 15.7906 - golden_loss: 0.8409\n",
      "Epoch 1867/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6808 - reconstruction_loss: 15.8652 - golden_loss: 0.8156\n",
      "Epoch 1868/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6988 - reconstruction_loss: 15.8542 - golden_loss: 0.8445\n",
      "Epoch 1869/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6553 - reconstruction_loss: 15.8442 - golden_loss: 0.8111\n",
      "Epoch 1870/2000\n",
      "1/1 [==============================] - 0s 312us/step - loss: 16.5629 - reconstruction_loss: 15.7171 - golden_loss: 0.8458\n",
      "Epoch 1871/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4563 - reconstruction_loss: 15.6471 - golden_loss: 0.8092\n",
      "Epoch 1872/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3905 - reconstruction_loss: 15.5466 - golden_loss: 0.8439\n",
      "Epoch 1873/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3891 - reconstruction_loss: 15.5789 - golden_loss: 0.8102\n",
      "Epoch 1874/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4352 - reconstruction_loss: 15.5946 - golden_loss: 0.8407\n",
      "Epoch 1875/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4883 - reconstruction_loss: 15.6764 - golden_loss: 0.8119\n",
      "Epoch 1876/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5083 - reconstruction_loss: 15.6705 - golden_loss: 0.8379\n",
      "Epoch 1877/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4835 - reconstruction_loss: 15.6709 - golden_loss: 0.8126\n",
      "Epoch 1878/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4294 - reconstruction_loss: 15.5935 - golden_loss: 0.8359\n",
      "Epoch 1879/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3829 - reconstruction_loss: 15.5707 - golden_loss: 0.8123\n",
      "Epoch 1880/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.3688 - reconstruction_loss: 15.5343 - golden_loss: 0.8345\n",
      "Epoch 1881/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3861 - reconstruction_loss: 15.5741 - golden_loss: 0.8120\n",
      "Epoch 1882/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4133 - reconstruction_loss: 15.5804 - golden_loss: 0.8329\n",
      "Epoch 1883/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4265 - reconstruction_loss: 15.6141 - golden_loss: 0.8124\n",
      "Epoch 1884/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4163 - reconstruction_loss: 15.5859 - golden_loss: 0.8303\n",
      "Epoch 1885/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3902 - reconstruction_loss: 15.5765 - golden_loss: 0.8137\n",
      "Epoch 1886/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3666 - reconstruction_loss: 15.5397 - golden_loss: 0.8270\n",
      "Epoch 1887/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3587 - reconstruction_loss: 15.5436 - golden_loss: 0.8151\n",
      "Epoch 1888/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3667 - reconstruction_loss: 15.5427 - golden_loss: 0.8240\n",
      "Epoch 1889/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.3805 - reconstruction_loss: 15.5646 - golden_loss: 0.8159\n",
      "Epoch 1890/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3883 - reconstruction_loss: 15.5661 - golden_loss: 0.8222\n",
      "Epoch 1891/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3848 - reconstruction_loss: 15.5696 - golden_loss: 0.8153\n",
      "Epoch 1892/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.3730 - reconstruction_loss: 15.5513 - golden_loss: 0.8217\n",
      "Epoch 1893/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3611 - reconstruction_loss: 15.5478 - golden_loss: 0.8133\n",
      "Epoch 1894/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3556 - reconstruction_loss: 15.5333 - golden_loss: 0.8223\n",
      "Epoch 1895/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3581 - reconstruction_loss: 15.5476 - golden_loss: 0.8105\n",
      "Epoch 1896/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.3650 - reconstruction_loss: 15.5414 - golden_loss: 0.8236\n",
      "Epoch 1897/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3711 - reconstruction_loss: 15.5638 - golden_loss: 0.8073\n",
      "Epoch 1898/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.3731 - reconstruction_loss: 15.5477 - golden_loss: 0.8254\n",
      "Epoch 1899/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3712 - reconstruction_loss: 15.5679 - golden_loss: 0.8033\n",
      "Epoch 1900/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3687 - reconstruction_loss: 15.5406 - golden_loss: 0.8281\n",
      "Epoch 1901/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3696 - reconstruction_loss: 15.5717 - golden_loss: 0.7979\n",
      "Epoch 1902/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3769 - reconstruction_loss: 15.5438 - golden_loss: 0.8331\n",
      "Epoch 1903/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3922 - reconstruction_loss: 15.6027 - golden_loss: 0.7895\n",
      "Epoch 1904/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4163 - reconstruction_loss: 15.5742 - golden_loss: 0.8421\n",
      "Epoch 1905/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4510 - reconstruction_loss: 15.6744 - golden_loss: 0.7766\n",
      "Epoch 1906/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4990 - reconstruction_loss: 15.6423 - golden_loss: 0.8567\n",
      "Epoch 1907/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.5644 - reconstruction_loss: 15.8060 - golden_loss: 0.7583\n",
      "Epoch 1908/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.6448 - reconstruction_loss: 15.7687 - golden_loss: 0.8761\n",
      "Epoch 1909/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7267 - reconstruction_loss: 15.9873 - golden_loss: 0.7394\n",
      "Epoch 1910/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7749 - reconstruction_loss: 15.8855 - golden_loss: 0.8894\n",
      "Epoch 1911/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7454 - reconstruction_loss: 16.0089 - golden_loss: 0.7365\n",
      "Epoch 1912/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.6255 - reconstruction_loss: 15.7523 - golden_loss: 0.8733\n",
      "Epoch 1913/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4667 - reconstruction_loss: 15.6985 - golden_loss: 0.7683\n",
      "Epoch 1914/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3604 - reconstruction_loss: 15.5374 - golden_loss: 0.8230\n",
      "Epoch 1915/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3575 - reconstruction_loss: 15.5364 - golden_loss: 0.8210\n",
      "Epoch 1916/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4313 - reconstruction_loss: 15.6577 - golden_loss: 0.7736\n",
      "Epoch 1917/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.5078 - reconstruction_loss: 15.6519 - golden_loss: 0.8559\n",
      "Epoch 1918/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5222 - reconstruction_loss: 15.7641 - golden_loss: 0.7580\n",
      "Epoch 1919/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4642 - reconstruction_loss: 15.6159 - golden_loss: 0.8483\n",
      "Epoch 1920/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3834 - reconstruction_loss: 15.6007 - golden_loss: 0.7828\n",
      "Epoch 1921/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3429 - reconstruction_loss: 15.5342 - golden_loss: 0.8087\n",
      "Epoch 1922/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3624 - reconstruction_loss: 15.5398 - golden_loss: 0.8225\n",
      "Epoch 1923/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4090 - reconstruction_loss: 15.6341 - golden_loss: 0.7749\n",
      "Epoch 1924/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.4343 - reconstruction_loss: 15.5931 - golden_loss: 0.8411\n",
      "Epoch 1925/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4161 - reconstruction_loss: 15.6436 - golden_loss: 0.7725\n",
      "Epoch 1926/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3733 - reconstruction_loss: 15.5480 - golden_loss: 0.8253\n",
      "Epoch 1927/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3432 - reconstruction_loss: 15.5458 - golden_loss: 0.7974\n",
      "Epoch 1928/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3456 - reconstruction_loss: 15.5513 - golden_loss: 0.7943\n",
      "Epoch 1929/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3692 - reconstruction_loss: 15.5460 - golden_loss: 0.8232\n",
      "Epoch 1930/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3870 - reconstruction_loss: 15.6102 - golden_loss: 0.7768\n",
      "Epoch 1931/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.3825 - reconstruction_loss: 15.5557 - golden_loss: 0.8268\n",
      "Epoch 1932/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3611 - reconstruction_loss: 15.5774 - golden_loss: 0.7837\n",
      "Epoch 1933/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3416 - reconstruction_loss: 15.5329 - golden_loss: 0.8087\n",
      "Epoch 1934/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3379 - reconstruction_loss: 15.5338 - golden_loss: 0.8042\n",
      "Epoch 1935/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3483 - reconstruction_loss: 15.5607 - golden_loss: 0.7877\n",
      "Epoch 1936/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3600 - reconstruction_loss: 15.5421 - golden_loss: 0.8179\n",
      "Epoch 1937/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3618 - reconstruction_loss: 15.5811 - golden_loss: 0.7807\n",
      "Epoch 1938/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3528 - reconstruction_loss: 15.5384 - golden_loss: 0.8144\n",
      "Epoch 1939/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3408 - reconstruction_loss: 15.5511 - golden_loss: 0.7897\n",
      "Epoch 1940/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3347 - reconstruction_loss: 15.5355 - golden_loss: 0.7992\n",
      "Epoch 1941/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.3369 - reconstruction_loss: 15.5331 - golden_loss: 0.8038\n",
      "Epoch 1942/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3431 - reconstruction_loss: 15.5573 - golden_loss: 0.7859\n",
      "Epoch 1943/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3470 - reconstruction_loss: 15.5364 - golden_loss: 0.8106\n",
      "Epoch 1944/2000\n",
      "1/1 [==============================] - 0s 534us/step - loss: 16.3451 - reconstruction_loss: 15.5618 - golden_loss: 0.7834\n",
      "Epoch 1945/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3392 - reconstruction_loss: 15.5335 - golden_loss: 0.8057\n",
      "Epoch 1946/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3335 - reconstruction_loss: 15.5430 - golden_loss: 0.7906\n",
      "Epoch 1947/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3313 - reconstruction_loss: 15.5367 - golden_loss: 0.7946\n",
      "Epoch 1948/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3328 - reconstruction_loss: 15.5331 - golden_loss: 0.7997\n",
      "Epoch 1949/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3357 - reconstruction_loss: 15.5500 - golden_loss: 0.7857\n",
      "Epoch 1950/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3372 - reconstruction_loss: 15.5336 - golden_loss: 0.8036\n",
      "Epoch 1951/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3360 - reconstruction_loss: 15.5521 - golden_loss: 0.7839\n",
      "Epoch 1952/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3330 - reconstruction_loss: 15.5329 - golden_loss: 0.8001\n",
      "Epoch 1953/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3299 - reconstruction_loss: 15.5417 - golden_loss: 0.7882\n",
      "Epoch 1954/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3283 - reconstruction_loss: 15.5357 - golden_loss: 0.7925\n",
      "Epoch 1955/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3283 - reconstruction_loss: 15.5342 - golden_loss: 0.7941\n",
      "Epoch 1956/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3294 - reconstruction_loss: 15.5435 - golden_loss: 0.7859\n",
      "Epoch 1957/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3302 - reconstruction_loss: 15.5330 - golden_loss: 0.7973\n",
      "Epoch 1958/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3301 - reconstruction_loss: 15.5469 - golden_loss: 0.7832\n",
      "Epoch 1959/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3290 - reconstruction_loss: 15.5331 - golden_loss: 0.7959\n",
      "Epoch 1960/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3273 - reconstruction_loss: 15.5427 - golden_loss: 0.7847\n",
      "Epoch 1961/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.3259 - reconstruction_loss: 15.5345 - golden_loss: 0.7914\n",
      "Epoch 1962/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3251 - reconstruction_loss: 15.5370 - golden_loss: 0.7880\n",
      "Epoch 1963/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3250 - reconstruction_loss: 15.5388 - golden_loss: 0.7863\n",
      "Epoch 1964/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3255 - reconstruction_loss: 15.5347 - golden_loss: 0.7908\n",
      "Epoch 1965/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.3260 - reconstruction_loss: 15.5433 - golden_loss: 0.7827\n",
      "Epoch 1966/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.3266 - reconstruction_loss: 15.5352 - golden_loss: 0.7913\n",
      "Epoch 1967/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3271 - reconstruction_loss: 15.5455 - golden_loss: 0.7816\n",
      "Epoch 1968/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3279 - reconstruction_loss: 15.5383 - golden_loss: 0.7896\n",
      "Epoch 1969/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3296 - reconstruction_loss: 15.5472 - golden_loss: 0.7824\n",
      "Epoch 1970/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.3332 - reconstruction_loss: 15.5467 - golden_loss: 0.7865\n",
      "Epoch 1971/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3398 - reconstruction_loss: 15.5557 - golden_loss: 0.7841\n",
      "Epoch 1972/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3515 - reconstruction_loss: 15.5683 - golden_loss: 0.7831\n",
      "Epoch 1973/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3713 - reconstruction_loss: 15.5859 - golden_loss: 0.7855\n",
      "Epoch 1974/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4040 - reconstruction_loss: 15.6234 - golden_loss: 0.7806\n",
      "Epoch 1975/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.4573 - reconstruction_loss: 15.6714 - golden_loss: 0.7860\n",
      "Epoch 1976/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5383 - reconstruction_loss: 15.7589 - golden_loss: 0.7794\n",
      "Epoch 1977/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.6549 - reconstruction_loss: 15.8696 - golden_loss: 0.7853\n",
      "Epoch 1978/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.7890 - reconstruction_loss: 16.0089 - golden_loss: 0.7801\n",
      "Epoch 1979/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.9037 - reconstruction_loss: 16.1212 - golden_loss: 0.7825\n",
      "Epoch 1980/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.9010 - reconstruction_loss: 16.1175 - golden_loss: 0.7835\n",
      "Epoch 1981/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.7485 - reconstruction_loss: 15.9727 - golden_loss: 0.7759\n",
      "Epoch 1982/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5041 - reconstruction_loss: 15.7147 - golden_loss: 0.7894\n",
      "Epoch 1983/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.3443 - reconstruction_loss: 15.5770 - golden_loss: 0.7673\n",
      "Epoch 1984/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3614 - reconstruction_loss: 15.5668 - golden_loss: 0.7946\n",
      "Epoch 1985/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4893 - reconstruction_loss: 15.7254 - golden_loss: 0.7639\n",
      "Epoch 1986/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.5816 - reconstruction_loss: 15.7883 - golden_loss: 0.7933\n",
      "Epoch 1987/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5384 - reconstruction_loss: 15.7697 - golden_loss: 0.7687\n",
      "Epoch 1988/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.4083 - reconstruction_loss: 15.6253 - golden_loss: 0.7830\n",
      "Epoch 1989/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16.3191 - reconstruction_loss: 15.5397 - golden_loss: 0.7794\n",
      "Epoch 1990/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3432 - reconstruction_loss: 15.5728 - golden_loss: 0.7703\n",
      "Epoch 1991/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4255 - reconstruction_loss: 15.6368 - golden_loss: 0.7887\n",
      "Epoch 1992/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.4616 - reconstruction_loss: 15.6978 - golden_loss: 0.7638\n",
      "Epoch 1993/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 16.4152 - reconstruction_loss: 15.6256 - golden_loss: 0.7896\n",
      "Epoch 1994/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.3416 - reconstruction_loss: 15.5762 - golden_loss: 0.7654\n",
      "Epoch 1995/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3185 - reconstruction_loss: 15.5350 - golden_loss: 0.7835\n",
      "Epoch 1996/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.3541 - reconstruction_loss: 15.5832 - golden_loss: 0.7709\n",
      "Epoch 1997/2000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 16.3919 - reconstruction_loss: 15.6144 - golden_loss: 0.7774\n",
      "Epoch 1998/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3844 - reconstruction_loss: 15.6104 - golden_loss: 0.7739\n",
      "Epoch 1999/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.3414 - reconstruction_loss: 15.5664 - golden_loss: 0.7750\n",
      "Epoch 2000/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.3115 - reconstruction_loss: 15.5384 - golden_loss: 0.7731\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "hist=autoencoder.fit(X,epochs=2000, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['golden_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['reconstruction loss', 'phi loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for Golden_loss\n",
    "plt.plot(hist.history['golden_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('golden_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['golden'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for Reconstruction_loss\n",
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('reconstruction_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['reconstruction_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Export Encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
       "array([[1.6144309],\n",
       "       [1.6102381],\n",
       "       [1.6264672],\n",
       "       [1.6484202],\n",
       "       [1.6170716],\n",
       "       [1.6610245],\n",
       "       [1.6196862],\n",
       "       [1.6719983],\n",
       "       [1.6238527],\n",
       "       [1.6280454],\n",
       "       [1.6265979],\n",
       "       [1.5125592],\n",
       "       [1.6505401],\n",
       "       [1.5136349],\n",
       "       [1.5845873],\n",
       "       [1.6568317],\n",
       "       [1.6144309],\n",
       "       [1.6657329],\n",
       "       [1.6456287],\n",
       "       [1.6667693],\n",
       "       [1.6061713],\n",
       "       [1.672129 ],\n",
       "       [1.2709494],\n",
       "       [1.5248792],\n",
       "       [1.7086753],\n",
       "       [1.6228163],\n",
       "       [1.6608531],\n",
       "       [1.6102643],\n",
       "       [1.4508833],\n",
       "       [1.5130408],\n",
       "       [1.63066  ],\n",
       "       [1.6746391],\n",
       "       [1.6165037],\n",
       "       [1.6264672],\n",
       "       [1.6196599],\n",
       "       [1.6144309],\n",
       "       [1.6093838],\n",
       "       [1.6568056],\n",
       "       [1.6584097],\n",
       "       [1.6280454],\n",
       "       [1.6155981],\n",
       "       [1.7023745],\n",
       "       [1.6170454],\n",
       "       [1.6641805],\n",
       "       [1.6610245],\n",
       "       [1.6154675],\n",
       "       [1.6557952],\n",
       "       [1.6290817],\n",
       "       [1.6307906],\n",
       "       [1.6516027],\n",
       "       [1.6144309],\n",
       "       [1.626962 ],\n",
       "       [1.4716018],\n",
       "       [1.6186237],\n",
       "       [1.6935035],\n",
       "       [1.4703624],\n",
       "       [1.5109158],\n",
       "       [1.648962 ],\n",
       "       [1.5937055],\n",
       "       [1.5589623],\n",
       "       [1.6531545],\n",
       "       [1.6144309],\n",
       "       [1.6824827],\n",
       "       [1.5626342],\n",
       "       [1.6641805],\n",
       "       [1.654191 ],\n",
       "       [1.6013112],\n",
       "       [1.6369255],\n",
       "       [1.6102381],\n",
       "       [1.6626027],\n",
       "       [1.6824827],\n",
       "       [1.6609983],\n",
       "       [1.6694098],\n",
       "       [1.6248891],\n",
       "       [1.6377902],\n",
       "       [1.6312855],\n",
       "       [1.6960969],\n",
       "       [1.6667953],\n",
       "       [1.6621655],\n",
       "       [1.6661127],\n",
       "       [1.6144309],\n",
       "       [1.635915 ],\n",
       "       [1.6474307],\n",
       "       [1.6578684],\n",
       "       [1.599509 ],\n",
       "       [1.7344308],\n",
       "       [1.6280478],\n",
       "       [1.6594203],\n",
       "       [1.6406289],\n",
       "       [1.6280454],\n",
       "       [1.5929728],\n",
       "       [1.6486473],\n",
       "       [1.6499983],\n",
       "       [1.643027 ],\n",
       "       [1.6680051],\n",
       "       [1.2370465],\n",
       "       [1.1500072],\n",
       "       [1.4088697],\n",
       "       [1.6287665],\n",
       "       [1.6458317]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data=autoencoder.encoder(X)\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(encoded_data).to_csv(\"C:/Users/AMINE/Documents/PhD/AI Phd/Pricing and Golden ratio/encoded_Gold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data=autoencoder.decoder(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09152414e-01,  8.77552554e-02],\n",
       "       [-1.76353380e-02,  8.77552554e-02],\n",
       "       [-2.00669467e-01, -8.37869123e-02],\n",
       "       [-1.09152414e-01, -6.55594110e-01],\n",
       "       [-1.09152414e-01,  3.00027113e-02],\n",
       "       [-3.83703619e-01, -6.56165957e-01],\n",
       "       [-1.09152414e-01, -2.71780118e-02],\n",
       "       [-5.66737771e-01, -7.12774873e-01],\n",
       "       [-2.00669467e-01, -2.66061909e-02],\n",
       "       [-2.92186528e-01, -2.66061909e-02],\n",
       "       [-2.00669467e-01, -8.66459012e-02],\n",
       "       [ 9.89052415e-01,  1.21535921e+00],\n",
       "       [-3.83703619e-01, -4.26871270e-01],\n",
       "       [ 9.52445567e-01,  1.22851074e+00],\n",
       "       [ 2.56915867e-01,  3.73658866e-01],\n",
       "       [-2.92186528e-01, -6.56165957e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [-6.58254802e-01, -4.84051943e-01],\n",
       "       [-9.32806075e-01,  2.30707064e-01],\n",
       "       [-5.66737771e-01, -5.98413408e-01],\n",
       "       [ 7.11361617e-02,  8.77552554e-02],\n",
       "       [-5.66737771e-01, -7.15633869e-01],\n",
       "       [ 4.53533840e+00,  2.94621944e+00],\n",
       "       [ 1.44663775e+00,  4.87448633e-01],\n",
       "       [-1.02432311e+00, -1.05643106e+00],\n",
       "       [-2.92186528e-01,  8.77552554e-02],\n",
       "       [-5.51179826e-01, -4.84623760e-01],\n",
       "       [-1.76353380e-02,  8.71834382e-02],\n",
       "       [ 1.17849267e+00,  2.37441206e+00],\n",
       "       [ 1.64797533e+00,  5.44629335e-01],\n",
       "       [-2.92186528e-01, -8.37869123e-02],\n",
       "       [-5.66737771e-01, -7.70527363e-01],\n",
       "       [ 7.38817304e-02, -1.40967637e-01],\n",
       "       [-2.00669467e-01, -8.37869123e-02],\n",
       "       [-1.09152414e-01, -2.66061909e-02],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [ 1.58333685e-03,  8.71834382e-02],\n",
       "       [-2.92186528e-01, -6.55594110e-01],\n",
       "       [-3.83703619e-01, -5.98985195e-01],\n",
       "       [-2.92186528e-01, -2.66061909e-02],\n",
       "       [-1.76353380e-02, -2.94651836e-02],\n",
       "       [-7.72651196e-01, -1.17079246e+00],\n",
       "       [-1.09152414e-01,  3.05745304e-02],\n",
       "       [-5.66737771e-01, -5.41804492e-01],\n",
       "       [-3.83703619e-01, -6.56165957e-01],\n",
       "       [-1.76353380e-02, -2.66061909e-02],\n",
       "       [-3.83703619e-01, -5.41804492e-01],\n",
       "       [-2.00669467e-01, -1.40967637e-01],\n",
       "       [-2.92186528e-01, -8.66459012e-02],\n",
       "       [-2.92186528e-01, -5.41804492e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [ 7.38817304e-02, -3.69690537e-01],\n",
       "       [ 1.06867230e+00,  2.03132796e+00],\n",
       "       [-2.00669467e-01,  8.77552554e-02],\n",
       "       [-1.20735717e+00, -5.41232705e-01],\n",
       "       [ 1.32400489e+00,  1.80260527e+00],\n",
       "       [ 9.52445567e-01,  1.28797877e+00],\n",
       "       [-2.92186528e-01, -4.84051943e-01],\n",
       "       [ 5.77225626e-01, -1.46685734e-01],\n",
       "       [ 5.31467080e-01,  6.58990800e-01],\n",
       "       [-3.83703619e-01, -4.84051943e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [-5.66737771e-01, -9.42069530e-01],\n",
       "       [ 1.65398791e-01,  9.45466101e-01],\n",
       "       [-5.66737771e-01, -5.41804492e-01],\n",
       "       [-2.92186528e-01, -5.98413408e-01],\n",
       "       [ 3.48432958e-01, -8.37869123e-02],\n",
       "       [-2.00669467e-01, -3.12509805e-01],\n",
       "       [-1.76353380e-02,  8.77552554e-02],\n",
       "       [-4.75220680e-01, -5.98985195e-01],\n",
       "       [-5.66737771e-01, -9.42069530e-01],\n",
       "       [-3.83703619e-01, -6.55594110e-01],\n",
       "       [-5.66737771e-01, -6.56165957e-01],\n",
       "       [-1.09152414e-01, -1.40967637e-01],\n",
       "       [-2.18972862e-01, -3.13081622e-01],\n",
       "       [-1.76353380e-02, -3.72549534e-01],\n",
       "       [-7.49771953e-01, -1.05643106e+00],\n",
       "       [-5.66737771e-01, -5.98985195e-01],\n",
       "       [-2.92186528e-01, -7.72814631e-01],\n",
       "       [-4.37698692e-01, -7.13346660e-01],\n",
       "       [-1.09152414e-01,  8.77552554e-02],\n",
       "       [-2.92186528e-01, -1.98720187e-01],\n",
       "       [-6.58254802e-01, -8.37869123e-02],\n",
       "       [-2.00669467e-01, -7.70527363e-01],\n",
       "       [ 7.38817304e-02,  2.30707064e-01],\n",
       "       [-1.29887426e+00, -1.34462190e+00],\n",
       "       [-6.33938685e-02, -2.55900919e-01],\n",
       "       [-2.92186528e-01, -7.12774873e-01],\n",
       "       [-1.09152414e-01, -4.85195607e-01],\n",
       "       [-2.92186528e-01, -2.66061909e-02],\n",
       "       [ 7.38817304e-02,  3.73658866e-01],\n",
       "       [-6.40866518e-01, -1.27816096e-01],\n",
       "       [-2.00669467e-01, -5.98413408e-01],\n",
       "       [-5.96938372e-01, -4.89066392e-02],\n",
       "       [-5.33791542e-01, -6.58453107e-01],\n",
       "       [ 4.30746126e+00,  3.91600442e+00],\n",
       "       [ 5.74793959e+00,  4.37630939e+00],\n",
       "       [ 4.39950019e-01,  4.03322506e+00],\n",
       "       [-1.33861974e-01, -2.01007351e-01],\n",
       "       [-1.09152414e-01, -5.98985195e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Score: 0.28 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "decoded_data=autoencoder.decoder(encoded_data)\n",
    "trainScore = math.sqrt(mean_squared_error(X, decoded_data))\n",
    "print('Evaluation Score: %.2f RMSE' % (trainScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(AE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\")\n",
    "       \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.reconstruction_loss_tracker,\n",
    "            \n",
    "          \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_sum(tf.reduce_sum(abs(data-reconstruction)**2, axis=1 ))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        grads = tape.gradient(reconstruction_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        \n",
    "       \n",
    "        return {\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Variational AutoEncoder: Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 10)           40          ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 5)            55          ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1)            6           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1)            6           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 1)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder \n",
    "\n",
    "latent_dim = 1\n",
    "\n",
    "encoder_inputs =  keras.Input(shape=(3,))\n",
    "x = layers.Dense(10, activation='linear')(encoder_inputs)\n",
    "x = layers.Dense(5, activation='linear')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 10        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                60        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder \n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(5, activation='linear')(latent_inputs)\n",
    "x = layers.Dense(10, activation='linear')(x)\n",
    "decoder_outputs = layers.Dense(3, activation='linear')(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = z_mean*z_mean-z_mean-1\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. VAE Model Tarining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\AMINE\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\AMINE\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\AMINE\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\AMINE\\AppData\\Local\\Temp/ipykernel_15288/1404194884.py\", line 25, in train_step\n        tf.reduce_sum(\n\n    ValueError: Invalid reduction dimension 1 for input with 1 dimensions. for '{{node Sum}} = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](Mean, Sum/reduction_indices)' with input shapes: [?], [2] and with computed input tensors: input[1] = <1 2>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15288/504512287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\AMINE\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\AMINE\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\AMINE\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\AMINE\\AppData\\Local\\Temp/ipykernel_15288/1404194884.py\", line 25, in train_step\n        tf.reduce_sum(\n\n    ValueError: Invalid reduction dimension 1 for input with 1 dimensions. for '{{node Sum}} = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](Mean, Sum/reduction_indices)' with input shapes: [?], [2] and with computed input tensors: input[1] = <1 2>.\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "history=vae.fit(X,epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
